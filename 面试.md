---
typora-copy-images-to: ..\..\Pictures\Typora
---

# 面试

## 美团面试

### 2021年笔试题

小美是美团的前端工程师，为了防止系统被恶意攻击，小美必须要在用户输入用户名之前做一个合法性检查，一个合法的用户名必须满足以下几个要求：

用户名的首字符必须是大写或者小写字母。
用户名只能包含大小写字母，数字。
用户名需要包含至少一个字母和一个数字。
如果用户名合法，请输出 "Accept"，反之输出 "Wrong"。
格式：


输入：
- 输入第一行包含一个正整数 T，表示需要检验的用户名数量。
- 接下来有 T 行，每行一个字符串 s，表示输入的用户名。
输出：
- 对于每一个输入的用户名 s，请输出一行，即按题目要求输出一个字符串。

```

```

知识点：

1. 正则表达式

   ```JAVA
   ^ 匹配输入字行首
   $ 匹配输入字符尾
   * 匹配前面表达式任意次
   + 匹配前面表达式一次或多次
   ？ 匹配前面表达式零次或一次
   {n} 匹配确定的n次
   {n,} 至少匹配n次
   {n,m} 最少匹配n次，最多匹配m次
   ？ 当该字符跟在任意一个其他限制符后，表示非贪婪匹配
   . 匹配出"\n"和”\r"以外的任意单个字符
   \d \D 匹配数字字符
   \s \S 匹配空格、制表符、换页符
    \t  匹配制表符
   \w \W 匹配数字字母下划线字母
     
   ```

   

2. java中Scanner 类的应用

   nextInt()、next()如果后面有nextLine()，则必须需要再来一个nextLine（）做分割


## 字节面试

### 走迷宫

小红站在一个n行m列的迷宫里。迷宫中1代表墙壁，0代表走道，迷宫的四周也被墙壁包围，题目中的输入没有画出来。
小红有WASD四种操作，其中‘W’代表向上走，‘S’代表向下走，‘A’代表向左走，‘D’代表向右走。
但当小红某一次操作会撞墙的时候，小红会站在原地不动。
已知小红的初始位置在左上角，小红想知道自己的最终位置是多少。



# java基础

## 常识

### 数据结构

数组、链表、栈、队列、集合、树、图、散列表

线性表：数组、链表、队列、栈

非线性表：集合、树、图、散列表

### 三大特性

封装：我的理解主要是将多个方法封装到对象的内部，隐藏内部实现的细节，只提供服务。避免暴露不必要的东西，提高可扩展性

继承：子类继承父类的方法和属性

多态：就是同一个行为具有多个不同的表现形式。实现多态的前提：继承、重写、向上转型。

### 面向对象

面向对象主要是一种编程思想，他把一些功能的实现封装到一个对象当中去，通过该对象来完成功能。

### Object类

wait，hashcode，equals、getclass、notify、toString、clone

先说两个概念：锁池和等待池

锁池:假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。
等待池:假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁后，进入到了该对象的等待池中

然后再来说notify和notifyAll的区别

如果线程调用了对象的 wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。
当有线程调用了对象的 notifyAll()方法（唤醒所有 wait 线程）或 notify()方法（只随机唤醒一个 wait 线程），被唤醒的的线程便会进入该对象的锁池中，锁池中的线程会去竞争该对象锁。也就是说，调用了notify后只要一个线程会由等待池进入锁池，而notifyAll会将该对象等待池内的所有线程移动到锁池中，等待锁竞争
优先级高的线程竞争到对象锁的概率大，假若某线程没有竞争到该对象锁，它还会留在锁池中，唯有线程再次调用 wait()方法，它才会重新回到等待池中。而竞争到对象锁的线程则继续往下执行，直到执行完了 synchronized 代码块，它会释放掉该对象锁，这时锁池中的线程会继续竞争该对象锁。

#### 为什么重写equals方法必须要重写hashcode方法

在java中有个规定：值相同的两个对象，那么hashcode必须相等。但是当我们不重写hashcode方法时，同一个类的两个实例调用equals和hashcode会出现歧义性。

哈希冲突的解决办法

开放定址法：线性探测再散列、二次探测再散列、伪随机探测再散列

二次哈希

链表

公共溢出区

### 权限修饰符和修饰符

public：不同包所有的类都可以使用。可以对方法、类、成员变量使用

protected：该包下或者其他包的子类可以使用。可以对内部类、外部类、方法、成员变量使用

defalut：该包下。可以对外部类、内部类、方法和成员变量、局部变量、代码块使用。

private：只有在该类中可以使用。可以对内部类、方法、成员变量使用。

static ：可以对成员变量、方法、代码块、内部类使用

volatile：可以对成员变量使用

final：可以对成员变量、静态变量、方法、外部类和外部类使用

代码块：普通代码块，和正常的执行顺序没有什么不同，定义在方法内部

​			静态代码块

​			构造代码块：定义在类中

​			同步代码块：synchronized修饰的

### JAVA8新特性

Lanmbda表达式

StreamAPI

Optional类 处理空指针异常

默认方法 在接口中可以有一个已经实现了的方法

### JAVA的异常

#### 分类

![img](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-12/Java%E5%BC%82%E5%B8%B8%E7%B1%BB%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E5%9B%BE2.png)

Exception可以被处理

Error不能被处理

#### try-catch-finally

**不要在 finally 语句块中使用 return!** 当 try 语句和 finally 语句中都有 return 语句时，try 语句块中的 return 语句会被忽略。这是因为 try 语句中的 return 返回值会先被暂存在一个本地变量中，当执行到 finally 语句中的 return 之后，这个本地变量的值就变为了 finally 语句中的 return 返回值。

finally不一定会被执行，当JVM退出，线程死亡，CPU关闭等情况都不会执行finally。

### 序列化

如果我们需要持久化 Java 对象比如将 Java 对象保存在文件中，或者在网络传输 Java 对象，这些场景都需要用到序列化。

实现序列化的过程：将该类实现Serialize接口，用objectInputStream和objectoutputStream进行传输。如果对于不想序列化的字段，用transient修饰，不能用于类和方法。

## String 、StringBuilder、Stringbuffer的区别

String类用final修饰，是不可变的，每次修改字符串都会新建一个String类并将引用指向它。所以不适用于大量操作字符串的情况

```
String类用final修饰，不可被继承，避免了子类继承破坏String可变性的情况
String的底层用byte[]数组，其是final private ,并且没有暴露出修改的方法
```

StringBuilder每次更新操作时，都会在原有的基础上添加，不会新建对象，适用于大量修改操作的情况。没有用final修饰。但是存在线程不安全的问题

Stringbuffer同StringBuilder一样，但是线程安全。

## 排序算法复杂度

![img](F:\Pictures\Typora\sort.png)

## 红黑树

### 为什么用红黑树作为hashmap得结构而不是其他树

首先，为了保障数据得查询速度，我们应该使用树这种结构；平衡二叉树和红黑树都是一种很好得实现方式。但是平衡二叉树是严格平衡得，它的查找速度更快，但是每次插入因为要保持绝对平衡，所以可能涉及到更复杂得旋转，而红黑树只是保证了黑色节点得平衡性，所以虽然查找速度不及AVL树，但是增删速度快。

红黑树是对B树（平衡树、2-3-4树）的一种实现。

### 红黑树的性质

![img](F:\Pictures\Typora\8bfd4b8c159ea084664bd51cceb3e4e5.png)



性质五保证了红黑树的黑色节点完美平衡的。

## 反射

Java中用Class类来代表每一个类。JVM在装在class文件时，会为该类生成一个class实例，通过该实例可以得到类中所有的信息。进而可以产生该类的对象。

获取class对象的三种方法

```
 Class<?> peopleClass = Class.forName("com.lagou.pojo.People");
Class<?> peopleClass = Peolpe.getClass

Person person = new Person();
Class<?> perClazz3 = person.getClass();
通过newInstance方法获取类的实例
```

## java类与接口

浅拷贝和深拷贝

浅拷贝：对基本数据类型进行值传递，对引用数据类型进行内存地址传递，当该内存地址的内容发生改变的时候，拷贝中的对象也会发生改变

深拷贝：对基本数据类型进行值传递，对引用数据类型对开辟一个新的内存空间，复制原有的对象。当原引用数据类型的对象发生改变时，不影响拷贝的对象值。

### 抽象类和接口的区别

抽象类是对于类别的抽象，而接口是用来对于功能的抽象

- 抽象类就可以有构造方法，而接口没有，
- 抽象类中可以有普通成员变量，而接口中没有  只能是 public static final类型的
- 抽象类中可以有普通方法，接口中必须是抽象的 JDK8 以后可以用default修饰非抽象方法

### 抽象的作用

1. 可扩展。当一个接口的实现类需要更改时，只需要重写该实现类即可，不必改变外部的接口调用
2. 规范。通过接口定义了功能。
3. 安全。实现了高内聚低耦合。不必暴露具体的实现细节

### 重载与重写的区别

重写：子类重写父类的方法。方法名、返回类型、传入参数都相同，权限修饰符不小于父类中该方法的权限修饰符

重载：同一个类中，方法名相同，但是传入参数不同，返回结果和权限修饰符可以相同也可以不同。

### 重载的方法能否根据返回类型进行区分

不能。因为方法调用时不一定会显示指定返回类型，无法判断。

其次，JVM里面定义了方法的区别性在于参数类型，参数个数，方法名

## IO/NIO

### IO模型

- 阻塞IO

当用户线程需要进行IO 操作时，内核会去查看数据是否准备就绪，如果没有准备就绪，就需要用户线程挂起进入阻塞状态；当数据准备完毕后，内核会将数据拷贝到用户线程，此时用户线程才能解绑阻塞状态。

- 非阻塞IO

当用户线程需要进行IO 操作时，内核会立马返回一个结果，用户线程不需要阻塞，继续执行下去，但是用户线程会不断的轮询内核；于此同时进行内核会查看数据是否已经准备，如果准备完毕，当用户线程再次请求数据的时候，内核将会将数据拷贝至用户线程。

- 多路复用IO

在正常的用户线程外，还会有一个额外的用户线程，它负责不断轮询socket事件，一旦有socket进行读操作的时候，才会进行阻塞。该轮询是在内核完成的

- 信号驱动IO

在用户线程需要进行IO读写的时候，他不会发生阻塞，而是注册一个信号函数；当内核的数据准备完毕后，会发送一个信号给用户线程，此时才会发生阻塞。

- 异步IO

第一阶段，当用户线程发起IO操作请求后，立即去做其他的事，不会发生阻塞；

内核收到IO请求后，会着手准备数据，并将其拷贝到用户线程

第二阶段，拷贝完成后，内核发送信号给用户线程，用户线程直接使用拷贝过来的数据即可。

两个阶段都是在内核状态完成的

![img](F:\Pictures\Typora\70.png)

字符流和字节流

流是一个抽象的概念。我的理解是把数据想象成一个水流，从一端流入到另一端

字节流：流的基本单位是字节

字符流：流的基本单位是字符

字节流不使用缓存区，字节流使用缓存区

为什么有了字节流还需要字符流

字符流是由 Java 虚拟机将字节转换得到的，问题就出在这个过程比较耗时，并且，如果我们不知道编码类型就很容易出现乱码问题。

### NIO

NIO属于IO得多路复用。 NIO主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector(负责轮询多个socket)。传统IO基于字节流和字符流进行操作，而NIO基于Channel和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector(选择区)用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个线程可以监听多个数据通道。

![img](F:\Pictures\Typora\0f483f2437ce4ecdb180134270a00144tplv-k3u1fbpfcp-watermark.image)

- channel

Channel是双向的，既可以用来进行读操作，又可以用来进行写操作。 
NIO中的Channel的主要实现有：

FileChannel

DatagramChannel

SocketChannel

ServerSocketChannel

- buffer

  

## 泛型

### 为什么不支持基本数据类型

Java 采用**类型擦除（Type erasure generics）**的方式实现泛型。用大白话讲就是这个泛型只存在源码中，编译器将源码编译成字节码之时，就会把泛型『擦除』，所以字节码中并不存在泛型。

泛型参数被擦除之后，强制变成了 Object 类型。这么做对于引用类型来说没有什么问题，毕竟 Object 是所有类型的父类型。但是对于 int/long 等八个基本数据类型说，这就难办了。因为 Java 没办法做到int/long 与 Object 的强制转换。

### 上下界

- 上界通配符

<? extends A>

```
A是超类，存放的是A的子类。java在向集合里面存放元素的时候，会标注一个占位符，但是如果传入一个A的子类过来，占位符不一定能够和该类完全匹配，所以添加不了元素。但是java的多态却可以使A接收它的所有子类，所以可以取。
```

- 下界通配符

<? super A>

```
A是子类，存放的是A的超类。由于A的超类的占位符不大于其子类的占位符，所以可以存。但是如果要取数据，只能用object接收，因为A的终极超类是object。
```



## java中集合

![img](F:\Pictures\Typora\v2-c6cb2b07e05153d75565bc33991878f6_1440w.jpg)

![img](F:\Pictures\Typora\v2-53ad86a4a1a93ea12efa5125a094ff07_1440w.jpg)

### List，Set，Map三者的区别？ 

- `List`：**有序集合**（有序指存入的顺序和取出的顺序相同，不是按照元素的某些特性排序），**可存储重复元素，可存储多个`null`**。
- `Set`：**无序集合**（元素存入和取出顺序不一定相同），**不可存储重复元素，只能存储一个`null`。**
- `Map`：使用键值对的方式对元素进行存储，`key`是无序的，且是唯一的。`value`值不唯一。不同的`key`值可以对应相同的`value`值。

### **常用集合框架底层数据结构**　＊＊＊

- `Lis`t：存储普通的元素
- `ArrayList`：数组
- `LinkedList`：双线链表
- `Set`：使用场景去重
- `HashSet`：底层基于`HashMap`实现，`HashSet`存入读取元素的方式和`HashMap`中的`Key`是一致的。
- `TreeSet`：红黑树。可以自动排序
- `Map`：存储key-value这种类型的数据
- `HashMap`： JDK1.8之前`HashMap`由数组+链表组成的， JDK1.8之后有数组+链表/红黑树组成，当链表长度大于8时，链表转化为红黑树，当长度小于6时，从红黑树转化为链表。这样做的目的是能提高`HashMap`的性能，因为红黑树的查找元素的时间复杂度远小于链表。
- `HashTable`：数组+链表
- `TreeMap`：红黑树

### ArrayList和LinkedArrayList的特点

ArrayList底层使用object数组实现，LinkedArrayList底层使用双向链表实现。

ArrayList增删慢，查找快，线程不安全，对元素必须连续存储

LinkedArrayList增删快，查找慢，对元素的存储可以是不连续的

### ArrayList的扩容机制

再插入元素时，如果没有初始化，就会将初始容量变为10。遵循先扩容后插入的原则，再插入数据前，会计算插入元素后的数组总长度是否大于当前数组长度，如果大于，就会进行1.5倍扩容。

### HashSet的底层

HashSet 的底层是HashMap ，默认构造函数是构建一个初始容量为16，负载因子为0.75 的HashMap 。
HashSet 的值存放于HashMap 的key 上，HashMap 的value 统一为PRESENT 

### HashMap的线程不安全

在JDK1.7的时候，由于采用头插法，多线程情况下扩容时会出现死循环的问题

在JDK1.8的时候，采用尾插法，会发生数据覆盖的问题。

在多个线程同时put的时候，可能出现hash碰撞，导致某一个数据丢失

### HashMap的扩容机制

HashMap是先插入再扩容。当插入后的数组元素个数大于总长度的0.75时，会进行一个1.5倍扩容。除此之外，如果再插入元素的时候Hashmap没有初始化，会将初始容量扩容为16.

### String、Integer这样的包装类适合作为Key？ 

- 这些包装类都是final 修饰，是不可变性的， 保证了key 的不可更改性，不会出现放入和获取时哈希值不同的情况。
- 它们内部已经重写过hashcode() ,equal() 等方法。

### 为什么要将链表中转红黑树的阈值设为8？为什么不一开始直接使用红黑树？

可能有很多人会问，既然红黑树性能这么好，为什么不一开始直接使用红黑树，而是先用链表，链表长度大于8时，才转换为红黑

树。因为红黑树的节点所占的空间是普通链表节点的两倍，但查找的时间复杂度低，所以只有当节点特别多时，红黑树的优点才能体

现出来。至于为什么是8，是通过数据分析统计出来的一个结果，链表长度到达8的概率是很低的，综合链表和红黑树的性能优缺点考

虑将大于8的链表转化为红黑树。链表转化为红黑树除了链表长度大于8，还要HashMap中的数组长度大于64。也就是如果HashMap 

长度小于64，链表长度大于8是不会转化为红黑树的，而是直接扩容。

### HashMap的put()方法过程

- 首先，判断hashmap是否为空，如果为空，进行初始化

- 首先，对key通过hash算法得出数组下标
- 如果数组下标元素为空，则将该key-value封装成Node对象并放入该位置
- 如果数组下标不为空，则会判断当前位置上的TreeNode类型。如是链表，则通过尾插法将该Node对象加入链表末尾，此过程会遍历链表，如果存在相同的key，则会更新value，同时，如果链表的个数大于8，则会将链表转为红黑树结构；如果是红黑树，则将该Node对象添加到树结构当中去，并在此过程中检查key是否存在，如果存在就会更新value。之后再进行扩容判断**.jdk1.7是先进行扩容，再插入。**如果当前容量大于等于总容量的0.75倍时，就会出现2倍扩容。

```
红黑树结构
	红黑树本质上是一颗二叉搜索树，它满足二叉搜索树的基本性质——即树中的任何节点的值大于它的左子节点，且小于它的右子节点。但是二叉搜索树有时候会出现不平衡的情况。因此，AVL和红黑树都是为了解决该问题而提出来的新结构。他在满足二叉搜索树的基础上，还满足了以下条件：

	规则1、根节点必须是黑色。

	规则2、任意从根到叶子的路径不包含连续的红色节点。

	规则3、任意从根到叶子的路径的黑色节点总数相同。
```

### ConcurrentHashMap的put过程

JDK1.7 

ConcurrentHashMap要进行两次定位，先对Segment进行定位，再对其内部的数组下标进行定位。定位之后会采用自旋锁+锁膨胀的机制进行加锁，也就是自旋获取锁，当自旋次数超过64时，会发生膨胀，直接陷入阻塞状态，等待唤醒。并且在整个put操作期间都持有锁。

jdk1.8

并且采用CAS+synchronized的机制。首先判断key-value为null的话直接返回空指针异常。否则判断map是否为空，为空进行初始化。初始化完成后，判断如果对应下标处没有结点，说明没有发生哈希冲突，返回一个null，此时直接通过CAS进行插入，若成功，直接返回。若失败，则进行下一轮循环

如果 非null ，并且 first.hash == -1 ，说明其他线程在扩容，参与一起扩容



如果 非null ，并且 first.hash != -1 ，Synchronized锁住 first节点，判断是链表还是红黑树，遍历插入。再插入的过程中，会通过equals方法进行判断，如果equals相等，则进行更新value

插入后判断是否需要扩容

### ConcurrentHashMap的get过程

1. 根据 key 计算出 hash 值，判断数组是否为空；
2. 如果是首节点，就直接返回；
3. 如果是红黑树结构，就从红黑树里面查询；
4. 如果是链表结构，循环遍历判断。

get 方法不需要加锁。因为 Node 的元素 value 和指针 next 是用 volatile 修饰的，在多线程环境下线程A修改节点的 value 或者新增节点的时候是对线程B可见的。



### HashMap源码中在计算hash值的时候为什么要右移16位

计算某个元素在hashMap中数组的下标为

```
（n-1)&hashcode>>16  hash=hashcode>>16 前提是n必须是2的整数次幂
因为将一个2的整数次幂-1后，高位后面的数全部变成1，与hashcode进行位与操作几乎完全取决于hashcode的值，减少hash冲突
```

降低低16位对计算hash值的影响，使元素在数组中分布更加均匀

### HashMap和ConcurrentHashMap

ConcurrentHashMap在jdk1.7是 **分段的数组+[链表]()** ，j，分段数组里面存放的是HashEntry数组；jdk1.8的时候跟HashMap1.8的时候一样都是基于Node数组+[链表]()/[红黑树]()。

ConcurrentHashMap是线程安全的

（1）在jdk1.7的时候是使用分段所segment，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。

（2）在jdk1.8的时候摒弃了 Segment的概念，而是直接用 Node 数组+[链表]()+[红黑树]()的数据结构来实现，并发控制使用 **synchronized** 和 **CAS** 来操作。synchronized只锁定当前[链表]()或红黑[二叉树]()的首节点。如果CAS不成功，就用synchronized 锁来锁住

> ConcurrentHashMap 不支持 key 或者 value 为 null 的原因？★★★

我们先来说value 为什么不能为 null。因为 ConcurrentHashMap 是用于多线程的 ，如果`ConcurrentHashMap.get(key)`得到了 null ，这就无法判断，是映射的value是 null ，还是没有找到对应的key而为 null ，就有了二义性。

而用于单线程状态的 HashMap 却可以用`containsKey(key)` 去判断到底是否包含了这个 null 

可以用反证法

### HashMap和TreeMap、HashTable的区别

hashmap是基于hash表实现的，而treemap基于红黑树实现的。treemap主要是用来排序。hashmap主要是用来查找替换。

HashTable 的底层数据结构是数组+链表，链表主要是为了解决哈希冲突，并且整个数组都是synchronized 修饰的，所以HashTable 是线程安全的，但锁的粒度太大，锁的竞争非常激烈，效率很低。

![image-20220317094209532](F:\Pictures\Typora\image-20220317094209532.png)

![image-20220317094237488](F:\Pictures\Typora\image-20220317094237488.png)

## java高并发

### 线程与进程之间的区别

进程是操作系统分配最小的资源单位

线程是资源调度的最小分配单位

进程之间很难共享数据，线程之间可以共享数据

进程之间互不影响，线程之间一般会相互影响



### 创建线程的几种方式

1）写一个类继承子Thread类，重写run方法。使用this即可获得当前线程

（2）写一个类重写Runable接口，重写run方法。必须使用Thread.currentThread()获取当前线程

（3）写一个类重写Callable接口，重写call方法

（4）使用线程池

```java
package Thread;

import java.util.concurrent.*;

public class TestThread {
    public static void main(String[] args) throws Exception {
        testExtends();
    }

    public static void testExtends() throws Exception {
        Thread t1 = new MyThreadExtends();
        Thread t2 = new MyThreadExtends();
        t1.start();
        t2.start();
    }
}

class MyThreadExtends extends Thread {
    @Override
    public void run() {
        System.out.println("通过继承Thread，线程号:" + currentThread().getName());
    }
}
```

#### 区别

前两种方式没有返回值，后两种方式有返回值并且可以i抛出异常

线程池返回参数，使用submit方法。而excute方法不会返回结果，因为execute传入的是Runnable接口。可以通过传入callable接口的匿名实现类，得到future对象，在使用get方法。

#### start（）和run（）的区别

- start()方法用来，开启线程，但是线程开启后并没有立即执行，他需要获取cpu的执行权才可以执行
- run()方法是由jvm创建完本地操作系统级线程后回调的方法，不可以手动调用（否则就是普通方法）

### 死锁

多个**进程**竞争系统资源而产生的相互等待的现象。比如说A和B同时在等待对方的锁，在得到新的锁之前而又不释放自己锁持有的锁。

死锁的四个必要条件:

互斥

占有且等待：一个进程在启动的时候就获取到他所有需要的资源

不可抢占：

循环等待

### 线程池

Java通过Excutors类提供四种线程池，分别为：

newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
		newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
		newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
		newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

#### ThreadLocal和线程池参数

线程局部变量。为每一个线程提供一个局部变量副本。这样多个线程在进行某个共享变量的访问时，不会出现冲突。底层实现为hash，key是线程id，value是保存的变量副本

ThreadLocal的内存泄露：ThreadLocalMap中的key是弱引用，而Value是强引用，弱引用在GC时就会被回收，而Value不会，导致了Value无法被使用。

解决办法：threadlocal在每次调用set，remove时都会检查key为null的数据，并将对应的value设为null    

#### Threadlocal的应用

将获取到的连接放connection放到threadlocal中，在其他的地方再获取到该connection，可以保证操作的事务性

#### 线程池参数

通过ThreadPoolExecutor构造器构造

corePoolSize：指的是该线程池中最少的存活线程数。

maximunPoolSize:线程池里面最多可存的线程数

keepAliveTime：线程池里面的一个线程如果处于空闲状态，最大能够存活的时间

unit：keepAliveTime的单位

WorkQueue：当有一个任务进来的需要获取线程的时候，会先进入一个缓存队列。该缓存队列有四种模式

- ArrayBlockingQueue 任务进来后，先存放进数组当中去，当数组满且当前线程池数小于maxPoolSize的时候，会按照先进先出的原则新建一个新的线程，如果大于，就会执行拒绝策略
- LinkedBlockingQueue 近似一个无界的数组 当一个任务进来后，存放在链表中，当核心线程有空闲的时候，才会调用。
- SynchronousQueue 不会被缓存。任务进来的时候，如果线程池数小于maxPoolsize，就会新建一个线程，否则执行拒绝策略
- PriorityQueue 作用跟LinkedBlockingQueue一样，只不过按照任务的优先级进行分配线程，而不是先进先出的原则

ThreadFactory：线程工厂，用来生产线程，并设置线程的名称，是否为守护线程等参数

handler：拒绝策略。当工作队列达到最大，且线程池中的线程数量达到最大的时候，有新任务提交进来，共有四种处理策略。

- callerRunspolicy：直接调用被拒绝任务的run方法
- AbortPolicy：丢弃该任务，并抛出异常
- discardPolicy：丢弃该任务
- discardOldestPolicy：尝试丢弃最先进来的线程，并将该任务加入队列。

通过Excutors工具类创建线程，返回 一个ThreadService类

- fixedThreadPool
- cachedThreadPool
- singleThreadPool
- SchedulThreadPool

#### 线程池异常捕获

- 通过try-catch-finally进行处理
- 通过ThreadFactory中的UncatchExceptionHandler对未捕获的异常进行保底处理

### wait和sleep的区别

使用区域不同：wait是在同步代码块和同步方法中，sleep在任何地方

锁机制处理方式不同：wait会释放锁，而sleep不会释放锁

另外，wait是Object类中的方法，sleep是Thread中的方法

### 用户线程和守护线程

守护线程是为了用户线程而服务的。当最后一个用户线程消亡的时候，守护线程此时已经没有了服务对象，那么守护线程就会消亡，（守护线程拥有自动消亡的特性）系统就会停止工作。

最简单的一个例子就是GC是一个守护线程。

作用就是希望守护线程执行一些后台任务，这样当程序退出时（用户线程关闭后），线程能够自动关闭。

### 线程安全

当多个线程同时调用某一个对象时，不需要考虑先后调用问题和同步，都能获得正确的结果，就说对象时线程安全的。

同步代码块、同步方法、Lock锁。

### 线程同步的几种方式

不可变、绝对线程安全，相对线程安全，线程兼容、线程对立

实现线程同步的几种方式

1. 互斥同步。在多线程访问同一个共享数据时，保证该共享数据同一时刻只被一条（或者是一些。当使用信号量的时候）线程使用。互斥是手段，同步是目的。常见的互斥手段有：临界区、互斥量和信号量。

2. 信号量

   它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。JUC下的semphore、countDownLatch、CycliBarrier

   ```
   CAS:比较并交换。CAS需要三个基本的操作数，内存地址（V),旧的预期值（A),准备设置的新值（B),CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则就不会执行更新。但是不管是否更新了V的值，都会返回V的旧值。 CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。
   CAS无法解决ABA的问题。即一个变量初次读取的是A值，在准备赋值的时候仍然为A值，但是无法保证在这期间他没有被其他线程锁改变。
   如何解决ABA问题：增加版本号，一个数据一个版本。具体可以通过时间作为版本号
   ```

3. 事件 

​		通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。wait、notify

### Synchronized和ReentrantLock的对比

synchronized 有多种锁状态

1. 都是可重入锁

   ```
   一条线程可以反复进入被他自己持有锁的同步块的特性称为可重入。如果持有锁的线程再次获得他，则将计数器的值加一，每次释放锁时计数器的值减一，只有当计数器的值为零时，才能真正的释放锁
   ```

   

2. 都可以用来控制多线程并发的安全问题

3. ReentrantLock具备三个高级特性：

   等待可中断

   ```
   当某个线程长时间持有一个锁时，其他等待的线程将会放弃等待，改为处理其他事情
   ```

   可以实现公平锁

   ```
   公平锁指的是多个线程按照先后顺序来获得锁。对于ReentrantLock来说，设置公平锁将会导致性能急剧下降
   ```
   
   可以绑定多个条件

   ```
   当满足条件时，线程才会执行
   ```

   
   
4. Synchronized是JVM层面的，而ReentrantLock是javaAPI层面的

5. 当出现异常时，synchronize可以自动释放锁，而ReentrantLock必须手动释放锁

   

### 常见的锁

##### 重量锁(互斥锁)

上文已经介绍了传统的synchronzied锁是基于mutex互斥量的，其主要的缺点是是在上锁过程中可能需要挂起线程，涉及用户态和内核态的切换，浪费处理器时间。

##### 轻量级锁：

轻量级锁的轻量级是相对于基于mutex互斥量实现的重量级锁而言。
在我们大部分的程序中，线程间的竞争并不激烈，且线程并不会长时间的持有锁。如果在不存在竞争并且锁将立被释放的情况下，也通过重量级锁去上锁和释放锁，那么对锁的操作浪费的时间可能比代码执行的时间更多。轻量级锁通过CAS设置加自旋等待的方式解决了上述这种场景下重量级锁低效的问题。
在使用轻量级锁时，线程会尝试通过CAS更新锁对象的对象头，如果更新成功，说明成功标记对象。如果更新失败，则说明该对象已经被其他线程持有，线程会进入自旋等待，因为通常一个线程不会长时间的持有锁，因此很可能尝试获取锁的线程只需要几次自旋获取锁。如果一段时间自选后，线程依旧无法获取锁，那么轻量级锁才会被升级成为重量级锁，并且阻塞自己。

##### 偏向锁 

虽然轻量级锁已经极大的提升了锁的效率，但是线程每次上锁和释放锁依然会产生时间的浪费。而一种极端的情况下，一个锁可能都是由某个线程去获取的(也就是其他线程不太会去获取这个锁，也就是不存在竞争的情况)。偏向锁就是出于对上述这种情况而进行的优化，希望将无竞争下的同步过程消除。
偏向锁会偏向第一个获取他的线程，之后就算该线程退出同步方法，偏向锁对该线程的标记依旧在，这样做的好处是该线程之后获取锁和释放锁都不需要进行CAS更新操作。只需要对比偏向锁的标记是否是自己。直到有其他线程获取该锁时，发现该锁标记的对象不是自己，则会要求该锁升级。

##### 锁优化

- 自旋锁：让线程在等待锁的过程中自旋，而不是被挂起，默认值为10次。可以使用参数 -XX:PreBlockSpin来自行更改。
- 锁粗化
- 锁消除   jvm在经过逃逸分析后，发现根本不存在锁竞争的情况

### Synchronized和volatile的对比

valatile可以保证数据的可见性，但不能保证数据的原子性

Synchronized可以保证可见性和原子性

### 内存模型的相关概念

缓存一致性问题：当一个变量被多个线程同时使用时，该变量会被复制到多个缓存当中。有可能造成数据的读取不一致问题。

解决办法：最出名的解决方式称为MESI协议。该协议的基本思想就是当cpu操作一个共享数据时，会通知其他的缓存，将该变量的缓存行置为无效状态。当其他的cpu操作该数据时，会从主内存中重新读取该数据。

### 并发编程的三大概念

- 原子性

一条操作或者多条操作，要么全部执行，要么全部不执行

- 可见性

当多个线程访问某一个共享数据时，其中一条线程对次数据进行了修改，其余线程能够立即看到被修改后的值

- 有序性

程序执行的顺序按照代码的先后顺序执行。有的编译器会对代码进行指令重排序，在单线程中不会影响结果的输出，但是在多线程中有可能会影响结果的输出。

### java中对于并发编程三大性质的保障

- 原子性

  在java中，对基本数据类的变量的读取和赋值操作都是原子性操作。

  ```
  x = 10;         //语句1
  y = x;         //语句2
  x++;           //语句3
  x = x + 1;     //语句4
  ```

  以上的操作只有语句1时原子性的

- 可见性

  对于可见性，java提供了valatile、final关键字来保证可见性。

当一个共享变量被valatile修饰后，它会保证修改的值会立即被更新到主内存当中，当其他线程需要读取时，他会取主内存中读取新值。

另外，通过Synchronized和Lock也能够保证可见性，synchronized和Lock能够保证同一时间二只有一条线程获取锁然后执行同步代码，并在释放锁之前会将对变量的修改同步到主内存当中取。

- 有序性。在java中，编译器和处理器可以对指令进行重排序。使用valatile可以保证一定的有序性，synchronized和Lock可以保证有序性。

valatile关键字可以禁止指令重新排序。主要体现在两个方面：

1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；

2）在进行指令优化时，编译器不会对 volatile 读与 volatile 读后面的任意内存操作重排序；编译器不会对 volatile 写与 volatile 写前面的任意内存操作重排序。

### 内存屏障

LoadLoad、LoadStore、StoreStore、StoreLoad

### 线程的基本状态及转移

新建：创建后尚未启动的线程

运行时（就绪、运行）：可能正在执行也有可能等待系统给他分配执行时间

阻塞：等待一个排他锁，获得锁以后才能进入运行时状态。

限期等待：过一段时间后由系统唤醒  sleep方法 设置了参数的join和wait方法

无限期等待：等待其他线程显式唤醒 wait join方法

终止状态：线程销毁

![img](F:\Pictures\Typora\o_200421111345线程状态转移.png)

### 乐观锁和悲观锁

悲观锁和乐观锁并不是某个具体的“锁”而是一种并发编程的基本概念。乐观锁和悲观锁最早出现在数据库的设计当中，后来逐渐被 Java 的并发包所引入。

悲观锁：认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观地认为，不加锁的并发操作一定会出问题。

乐观锁：正好和悲观锁相反，它获取数据的时候，并不担心数据被修改，每次获取数据的时候也不会加锁，只是在更新数据的时候，通过判断现有的数据是否和原数据一致来判断数据是否被其他线程操作，如果没被其他线程修改则进行数据更新，如果被其他线程修改则不进行数据更新。

### epoll模型

![image-20220323163844991](F:\Pictures\Typora\image-20220323163844991.png)

## JUC

![在这里插入图片描述](F:\Pictures\Typora\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FWX3dvYWlqYXZh,size_16,color_FFFFFF,t_70.jpeg)

### AQS

**AbstractQueuedSynchronize**r 是一个用来构建锁和同步器的框架.**AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**

```
CLH(Craig,Landin and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。
```

![AQS原理图](F:\Pictures\Typora\AQS原理图.png)

**AQS 定义两种资源共享方式**

Exclusive

（独占）：只有一个线程能执行，如ReentrantLock又可分为公平锁和非公平锁：

- 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
- 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的

**Share**（共享）：多个线程可同时执行，如` CountDownLatch`、`Semaphore`、 `CyclicBarrier`、`ReadWriteLock` 我们都会在后面讲到。

### AQS的组件

`Semaphore`(信号量)：可以指定多个线程同时访问某个资源。

countDownLatch:用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。

**`CyclicBarrier`(循环栅栏)：** `CyclicBarrier` 和 `CountDownLatch` 非常类似，它也可以实现线程间的技术等待，但是它的功能比 `CountDownLatch` 更加复杂和强大。主要应用场景和 `CountDownLatch` 类似

这三种其实是java.util.concurrent里面的类

### AQS类

AQS是JUC里面实现多线程的基石。所有的操作都是基于AQS中定义的state等变量和相应的方法。

变量：state、head、tail

方法：setState、getState、compareAndSetState

### 模板方法

```java
/*独占模式获取同步状态，该方法会先调用重写的tryAcquire方法尝试获取同步状态，如果当前线程成功获取同步状态，
 * 该方法直接返回，否则当前线程会被封装成一个节点放入同步队列中等待
 */
public final void acquire(int arg) {//现实省去...}f
                                             
/*与acquire方法类似，但该方法能响应中断，如果当前线程未能获取到同步状态，而在同步队列中，当这个线程被中断时，
 *则该抛出InterruptedException 异常并返回
 */
public final void acquireInterruptibly(int arg){//现实省去...}

/*在acquireInterruptibly方法上加了超时机制，如果当前线程在超过时间内没有获取同步状态，那么将返回false，
 *获取到返回ture
 */
public final boolean tryAcquireNanos(int arg, long nanosTimeout){//现实省去...}

/*共享式获取同步状态，该方法会先调用重写的tryAcquireShared方法尝试获取同步状态，如果当前线程成功获取同步状态，
 *该方法直接返回，否则当前线程会被封装成一个节点放入同步队列中等待
 */
public final void acquireShared(int arg) {//现实省去...}

/*以acquireShared方法类似，在其基础上增加了响应中断的功能
 */
public final void acquireSharedInterruptibly(int arg){//现实省去...}

/*在acquireSharedInterruptibly方法的基础上增加了超时限制
 */public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout){//现实省去...}

/*独占模式释放同步状态，该方法会先调用重写的tryRelease方法，如果释放同步状态成功，将同步队列中第一个节点中
 *对应线程唤醒
 */
public final boolean release(int arg) {//现实省去...}

/*共享模式释放同步状态，该方法会先调用重写的tryReleaseShared方法
 */
public final boolean releaseShared(int arg) {//现实省去...}
```



自定义同步器，只需要继承抽象类AQS并重写一下方法即可：

```java
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

### 锁降级

一个线程先获取写锁，再获取到读锁。随后释放写锁的过程。不允许出现读锁获取写锁的状态。因为如果后面有线程等待获取写锁，那么就会出现锁饥饿。

## 设计模式

### 设计模式的六大原则

单一原则：一个类只有一个职责。

里氏替换原则：子类可以扩展父类的功能，但不能改变父类原有的功能

依赖倒置原则：

- 模块间的依赖通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生的
- 接口或抽象类不依赖于实现类
- 实现类依赖于接口或抽象类

接口隔离原则:

- 客户端不应该依赖它不需要的接口；
- 一个类对另一个类的依赖应该建立在最小的接口上

迪米特法则：一个类对于其他类知道的越少越好，就是说一个对象应当对其他对象有尽可能少的了解,只和朋友通信，不和陌生人说话。

开闭原则：一个系统/模块设计，在决定其架构的时候，应当使在不改变其内部代码的情况下可以实现扩展。

### 线程安全的单例模式

```java


懒汉式
public class Singleton {     
    private static Singleton instance = null;     // 私有构造方法，保证外界无法直接实例化。     
    private Singleton() {}     // 通过公有的静态方法获取对象实例     
    synchronized public static Singleton getInstace() {         
        if (instance == null) {             
            instance = new Singleton();        
        }         
      return instance;     } }
该方法存在的一个问题就是 多线程环境下每个线程执行getInstance() 都要阻塞

双锁检测单例模式
    public static singleton{
    private  volatile static singleton；;
    private static Singleton(){
        
    }
    public static Singleton getInstane(){
        if(singleton==null){
            Synchronized(Singleton.class){
                if(singleton==null){
                    //立即可见，所以不用所有的线程都阻塞了。
                    singleton=new Singleton();
                }
            }
        }
        
        return singleton;
    }     
}
```

### 工厂模式

```
包括简单工厂、工厂方法、抽象工厂
Spring中的BeanFactory
spring中的FactoryBean接口
ApplcationContext
```

### 代理模式

```
为其他对象提供一种代理用来控制对这个对象的访问
Spring中的AOP
```

### 模板方法模式

```
定义了一个算法的步骤，并允许子类别为一个或多个步骤提供其实践方式。
AQS中定义了模板方法，如果需要自定义同步器，继承AQS，并且重写方法即可
spring中的jdbc模板方法
```

### 建造者模式

```
将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象。
```

### 策略模式

```
对象具备某个行为，但是在不同的场景中，该行为有不同的实现算法。
Spring中获取某个bean的注解@Resource
```

### 观察者模式

```
它定义对象间的一种一对多的依赖关系，多个观察者对象都依赖于一个目标对象，当目标对象的状态发生变化时，所有依赖于这个对象的观察者对象都会收到通知。
Spring：
定义一个事件: 实现一个继承自 ApplicationEvent，并且写相应的构造函数；
定义一个事件监听者：实现 ApplicationListener 接口，重写 onApplicationEvent() 方法；
使用事件发布者发布消息: 可以通过 ApplicationEventPublisher 的 publishEvent() 方法发布消息
```

### 发布订阅模式

```
当一个对象的状态发生改变时，所有依赖于它的对象都将得到状态改变的通知。
```

### 责任链模式

```
为了避免请求发送者与多个请求处理者耦合在一起，于是将所有请求的处理者，通过前一对象记住其下一个对象的引用而连成一条链；当有请求发生时，可将请求沿着这条链传递，直到有对象处理它为止。

```

### 适配器模式

```
将一个类的接口转换成客户希望的另一个接口。适配器模式让那些接口不兼容的类可以一起工作。
SpringMVC中处理请求的Handler，最终都是封装到HandlerAdapter统一调用
```

### 装饰器模式

```
装饰器则是对某一个类进行功能扩展，并且不改变其原有类型。
一种是类名中含有Wrapper，另一种是类名中含有Decorator。
InputStream 类下有 FileInputStream (读取文件)、BufferedInputStream (增加缓存,使读取文件速度大大提升)等子类都在不修改InputStream 代码的情况下扩展了它的功能
```

### 发布订阅和观察者的区别

发布订阅是完全解耦的模式，观察者是松耦合的模式

发布订阅模式有broker，观察者模式没有

### 装饰器和代理模式的区别

装饰器关注的是

# RabbitMQ

## 基础概念

作用：解耦、削峰、异步

作用场景：

- 异步 异步下单，减少数据库压力，快速返回结果
- 削峰：减少数据库的压力
- 解耦：将多个模块之间，通过消息队列连接起来，可以降低设计的复杂度

缺点：数据一致性的问题

## 工作模式

- 简单工作模式
- 工作队列模式
- 广播模式
- 路由模式
- topic模式
- RPC模式

## RabbitMQ的组件

- ConnectionFactory（连接管理器）：应用程序与Rabbit之间建立连接的管理器，程序代码中使用。
- Channel（信道）：消息推送使用的通道。
- Exchange（交换器）：用于接受、分配消息。
- Queue（队列）：用于存储生产者的消息。
- RoutingKey（路由键）：用于把生成者的数据分配到交换器上。
- BindingKey（绑定键）：用于把交换器的消息绑定到队列上。

## 消息队列MQ

作用：削峰、解耦、异步

### 消息队列的可靠性

#### 消息队列如何保证顺序消费

拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。

或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理

#### 如何避免重复投递和重复消费

在消息生产时，MQ内部针对每条生产者发送的消息生成一个inner-msg-id，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列；在消息消费时，要求消息体中必须要有一个bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID等）作为去重和幂等的依据，避免同一条消息被重复消费。将该信息存入redis中

#### 处理消息失败（消息补偿）

一般生产环境中，都会在使用MQ的时候设计两个队列：一个是核心业务队列，一个是死信队列。核心业务队列，就是比如专门用来让订单系统发送订单消息的，然后另外一个死信队列就是用来处理异常情况的。

比如说要是第三方物流系统故障了，此时无法请求，那么仓储系统每次消费到一条订单消息，尝试通知发货和配送，都会遇到对方的接口报错。此时仓储系统就可以把这条消息拒绝访问，或者标志位处理失败！注意，这个步骤很重要。

一旦标志这条消息处理失败了之后，MQ就会把这条消息转入提前设置好的一个死信队列中。然后你会看到的就是，在第三方物流系统故障期间，所有订单消息全部处理失败，全部会转入死信队列。然后你的仓储系统得专门有一个后台线程，监控第三方物流系统是否正常，能否请求的，不停的监视。一旦发现对方恢复正常，这个后台线程就从死信队列消费出来处理失败的订单，重新执行发货和配送的通知逻辑。死信队列的使用，其实就是MQ在生产实践中非常重要的一环，也就是架构设计必须要考虑的。

#### 如何保证消息不丢失

对于RabbitMQ 	生产者：提供一个ack机制。当消息被投递到相应的队列中以后，消息队列会返回一个ACK给生产者，否则生产者会尝试重发。

rabbitMQ:持久化和ack同时运用，当持久化失败，通知生产者

消费者：每次消费完消息后，都会回一个ack，此时消息队列会删除该消息。如果长时间没有回ACK且消费者没有断开连接，消息队列不会重发，如果断开了连接，则会把该消息发送给其他的订阅的消费者（可能存在重复消费的问题)

#### 请介绍消息队列推和拉的使用场景

**参考答案**

推模式：

推模式是服务器端根据用户需要，由目的、按时将用户感兴趣的信息主动发送到用户的客户端。

优点：

- 对用户要求低，方便用户获取需要的信息；
- 及时性好，服务器端及时地向客户端推送更新动态信息，吞吐量大。

缺点：

- 不能确保发送成功，推模式采用广播方式，只有服务器端和客户端在同一个频道上，推模式才有效，用户才能接收到信息；
- 没有信息状态跟踪，推模式采用开环控制技术，一个信息推送后的状态，比如客户端是否接收等，无从得知；
- 针对性较差。推送的信息可能并不能满足客户端的个性化需求。

拉模式：

拉模式是客户端主动从服务器端获取信息。

优点：

- 针对性强，能满足客户端的个性化需求；
- 信息传输量较小，网络中传输的只是客户端的请求和服务器端对该请求的响应；
- 服务器端的任务轻。服务器端只是被动接收查询，对客户端的查询请求做出响应。

缺点：

实时性较差，针对于服务器端实时更新的信息，客户端难以获取实时信息；

对于客户端用户的要求较高，需要对服务器端具有一定的了解。

# JVM

![sd](F:\Pictures\Typora\sd.png)

## JVM内存模型（运行时数据区）

![img](F:\Pictures\Typora\2019-3Java运行时数据区域JDK1.8.png)

程序计数器：

- 程序执行下一条字节码指令的地址
- 记录当前线程的位置

虚拟机栈：

方法执行的模型，一次方法调用都会有一个对应的栈帧，并把变量压入栈。

返回有两种形式。return和抛出异常

本地方法栈：

与虚拟机栈一样，也是方法执行的模型。只不过调用的是本地方法

堆

存放对象和字符串常量池

方法区：

存放类型信息、静态变量、常量和JIT编译完成后的热点代码



![img](F:\Pictures\Typora\26038433.jpg)



## 虚拟机栈

![img](https://img-blog.csdnimg.cn/20200606152422595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R5YW5nZWwyMDEz,size_16,color_FFFFFF,t_70)

当栈是动态大小的时候，如果申请内存空间申请失败的时候，就会出现outofMemory

当栈是静态大小的时候，当内存满的时候，抛出stackoverflow错误

动态链接：指向常量池种调用方向的地址

局部变量表：存放的是基本数据类型变量，以及传入参数对象的引用和方法内部声明的对象

操作数栈：本质上是一个栈，弹出压入需要操作的数据

虚方法和非虚方法：

非虚方法：在编译器就确定了具体的调用版本。静态方法、私有方法，final方法，实例构造器、父类方法都是非虚方法

虚方法：在编译期间无法确定具体的调用版本。

invokestatic  静态方法

invokespecial  私有、父类、构造器方法、final方法

invokevirtual 调用虚方法

invokeinterface 调用接口方法

invokestatic  动态调用

## JAVA内存模型

主要是定义程序中各种**变量**的访问规则。用来屏蔽不同硬件和操作系统访问内存的差异。这里说的变量主要是成员变量，类变量和数组元素的对象，不包括局部变量和方法参数。

### 主内存和工作内存交互规范

所有的变量都必须存储在主内存，工作内存保存了自己所需变量的内存副本

java中所有变量的操作必须在工作内存中完成。不能直接读写主内存的数据

不同线程之间不能读取其他工作内存的变量。线程之间的值传递必须通过主内存完成。

这里说的主内存物理硬件的内存。工作内存总是优先存储在寄存器或者高速缓存上。

定义了8条原子性操作：

lock unlock、load、read、use、assign、store、write

同时定义了8条规则

### 先行发生原则

指的是操作A发生在操作B之前，操作B能够看到操作A的影响。时间先后顺序与先行发生没有关系。因为存在指令优化重排序

### volatile型变量的特殊规则

保证可见性 fnal 

保证有序性  

### 对long和double型数据类型的规则

JVM将64位类型的数据是否保证原子性交由各个具体的虚拟机来实现。

### JVM线程

使用线程的几种方式：内核线程实现、用户线程实现、用户线程加轻量级进程实现。轻量级进程就是我们平常所说的线程。用户线程指的是完全建立在用户空间上的线程库上，不被内核锁感知。

HotSpot的线程实现方式取决于操作系统原生线程

线程调度：

协同式：当一个线程执行完毕后，主动通知另一个线程工作。优点：不需要考虑线程同步问题

缺点：执行的时间不可控，很容易发生阻塞

抢占式：每个线程由操作系统分配执行时间。java采用的就是这种。优点：执行时间可控，不会发生长时间阻塞的问题。缺点：线程间同步的问题比较复杂。

## 双亲委派机制

三种系统类加载器

BootstrapClassLoader：核心类库以及两个启动类加载器 jre/lib

ExtendClassLoader：jre/lib/ext

ApplicationClassLoader：我们自己编写的类

当一个类需要加载的时候，如果没有自定义类加载器，首先在applicationClassloader中检查是否有该类，如果有就无需加载，如果没有就向上检查extendclassloader，看它有没有加载该类，如果没有，再找bootstarpclassloader，

破坏双亲委派模型

双亲委派机制的实现主要是在loadClass()方法中实现的。只需要编写一个类重写loadClass方法即可

自定义加载器

主要目的是可以加密解密文件。首先自定义一个类继承ClassLoader，重写findClass方法，该方法主要是传入一个class文件的二进制数据，在findClass里面调用defineClass。

```java
public class MyClassLoader extends ClassLoader {
    //指定路径
    private String path ;
 

    public MyClassLoader(String classPath){
        path=classPath;
    }
 
    /**
     * 重写findClass方法
     * @param name 是我们这个类的全路径
     * @return
     * @throws ClassNotFoundException
     */
    @Override
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        Class log = null;
        // 获取该class文件字节码数组
        byte[] classData = getData();
 
        if (classData != null) {
            // 将class的字节码数组转换成Class类的实例
            log = defineClass(name, classData, 0, classData.length);
        }
        return log;
    }
 
    /**
     * 将class文件转化为字节码数组
     * @return
     */
    private byte[] getData() {
 
        File file = new File(path);
        if (file.exists()){
            FileInputStream in = null;
            ByteArrayOutputStream out = null;
            try {
                in = new FileInputStream(file);
                out = new ByteArrayOutputStream();
 
                byte[] buffer = new byte[1024];
                int size = 0;
                while ((size = in.read(buffer)) != -1) {
                    out.write(buffer, 0, size);
                }
 
            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try {
                    in.close();
                } catch (IOException e) {
 
                    e.printStackTrace();
                }
            }
            return out.toByteArray();
        }else{
            return null;
        }
 
 
    }
}
```



## 类加载过程

![类加载过程](F:\Pictures\Typora\类加载过程.png)

加载过程：类加载过程的第一步，主要完成下面3件事情：

1. 通过全类名获取定义此类的二进制字节流
2. 将字节流所代表的静态存储结构转换为方法区的运行时数据结构
3. 在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口

验证：

![验证阶段示意图](F:\Pictures\Typora\验证阶段.png)

准备：

**准备阶段是正式为类变量分配内存并设置类变量初始值的阶段**，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：

1. 这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在 Java 堆中。
2. 这里所设置的初始值”通常情况”下是数据类型默认的零值（如0、0L、null、false等），比如我们定义了`public static int value=111` ，那么 value 变量在准备阶段的初始值就是 0 而不是111（初始化阶段才会复制）。特殊情况：比如给 value 变量加上了 fianl 关键字`public static final int value=111` ，那么准备阶段 value 的值就被复制为 111。


基本数据类型的零值

![基本数据类型的零值](F:\Pictures\Typora\基本数据类型的零值.png)

解析：

解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。

符号引用就是一组符号来描述目标，可以是任何字面量。**直接引用**就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。在程序实际运行时，只有符号引用是不够的，举个例子：在程序执行方法时，系统需要明确知道这个方法所在的位置。Java 虚拟机为每个类都准备了一张方法表来存放类中所有的方法。当需要调用一个类的方法的时候，只要知道这个方法在方发表中的偏移量就可以直接调用该方法了。通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置，从而使得方法可以被调用。

综上，解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。

初始化：

初始化是类加载的最后一步，也是真正执行类中定义的 Java 程序代码(字节码)，初始化阶段是执行类构造器 `<clinit> ()`方法的过程。

对于`<clinit>（）` 方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为 `<clinit>（）` 方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起死锁，并且这种死锁很难被发现。

对于初始化阶段，虚拟机严格规范了有且只有5种情况下，必须对类进行初始化：

1. 当遇到 new 、 getstatic、putstatic或invokestatic 这4条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。
2. 使用 `java.lang.reflect` 包的方法对类进行反射调用时 ，如果类没初始化，需要触发其初始化。
3. 初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。
4. 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。
5. 当使用 JDK1.7 的动态动态语言时，如果一个 MethodHandle 实例的最后解析结构为 REF_getStatic、REF_putStatic、REF_invokeStatic、的方法句柄，并且这个句柄没有初始化，则需要先触发器初始化。

## 对象的创建

![Java创建对象的过程](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/Java%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%BF%87%E7%A8%8B.png)

#### step1:类加载检查

虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。

#### Step2:分配内存

在**类加载检查**通过后，接下来虚拟机将为新生对象**分配内存**。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。**分配方式**有 **“指针碰撞”** 和 **“空闲列表”** 两种，**选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定**。

**内存分配的两种方式：（补充内容，需要掌握）**

选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的

![内存分配的两种方式](F:\Pictures\Typora\内存分配的两种方式.png)



**内存分配并发问题（补充内容，需要掌握）**

在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：

- **CAS+失败重试：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。**
- **TLAB：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配

#### Step3:初始化零值

内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

#### Step4:设置对象头

初始化零值完成之后，**虚拟机要对对象进行必要的设置**，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 **这些信息存放在对象头中。** 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

#### Step5:执行 init 方法

在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，`<init>` 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 `<init>` 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

### 3.2 对象的内存布局

在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：**对象头**、**实例数据**和**对齐填充**。

**Hotspot 虚拟机的对象头包括两部分信息**，**第一部分用于存储对象自身的自身运行时数据**（哈希码、GC 分代年龄、锁状态标志等等），**另一部分是类型指针**，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。

**实例数据部分是对象真正存储的有效信息**，也是在程序中所定义的各种类型的字段内容。

**对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。** 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。

## 对象的使用

### 对象的内存布局

一个对象主要有三个部分：

- 对象头。hash码，GC分代年龄，锁状态标志；指向该对象的类源数据的指针。
- 实例数据。程序中定义的各种类型的字段内容
- 对齐填充。占位作用

### 对象的访问定位

- 使用句柄

![对象的访问定位-使用句柄](F:\Pictures\Typora\对象的访问定位-使用句柄.png)

通过句柄访问的话，java会在堆空间开启一个句柄池，引用指向的是该对象句柄，句柄里面存放的是指向实例数据和类型数据的地址

- 直接指针

![对象的访问定位-直接指针](F:\Pictures\Typora\对象的访问定位-直接指针.png)

通过直接指针进行访问的话，引用指向堆空间的一块地址，在这块地址中，存放的是java的实例数据和指向类型数据的地址。

## JVM的垃圾回收

### 判断对象死亡的两种方法

可达性分析和引用计数法

可达性分析

```
这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。
```

引用计数法

```
给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。但是该方法不被普遍使用，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。

```

### GC roots

GC roots可以是哪些变量：虚拟机栈中引用的对象、类变量引用的对象、字符串常量池的引用、基本数据类对应的Class对象，异常对象、系统类加载器、synchronized持有的对象。

### 安全区域和安全点

OOPMap中存放GCRoots中对象的地址。只在指定的地点生成oopMap，该地方称为安全点。

安全区域是为了解决线程阻塞的时候出现了GC的情况。安全区域是指在这段代码中，引用关系不会发生改变。当用户线程进入安全区域还没有出来的时候，系统可以随时启动垃圾回收，当走出安全区域的时候，他会询问虚拟机是否可以走出（是否需要暂停线程，初始标记或者），如果不行一直等待。

### 记忆集

为了避免将老年代加入GCROOts，记录从非收集区域指向收集区域的对象引用。卡表是记忆集的一种实现方式。

卡表中存放是内存中的一块地址，称为卡页，只要该地址中有一个对象存在着跨代引用，就会将卡表变脏，加入GCRootS扫描。

### 中断

当GC进行垃圾回收的时候，会暂停用户线程。此时线程有两种方式暂停：

主动式中断：一直到安全点才会暂停线程

抢先式中断：先停下来，如果没到安全点，在启动线程到安全点

### 四种引用

- 强引用：

- 软引用

- 弱引用

- 虚引用

### 堆空间结构与垃圾回收

Java 堆是垃圾收集器管理的主要区域，因此也被称作**GC 堆（Garbage Collected Heap）**.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。**进一步划分的目的是更好地回收内存，或者更快地分配内存。**
![img](F:\Pictures\Typora\2019-3堆结构.png)

#### 划分的依据

如果没有survivor区，每次minorGC后的对象进入老年代，老年代很快就会被装满，造成频繁的fullGC。解决办法是增加老年代的空间，但是扫描更加耗时。所以需要额外设置一个空间。

又进一步划分s0、s1的原因是，新生代基于标记复制算法。

#### 垃圾回收过程

在进行YGC的时候，会查看老年代的最大连续可用空间是否大于新生代中所有对象的总和。如果大于，那么此次YGC就是安全的，如果不大于，就会检查是否允许分配担保机制。

如果允许，则会检查新生代历年平均晋升老年代的大小，如果老年代 大于该值，则尝试进行一次Minor GC，如果小于该值或者不允许分配担保机制，则进行一次full gc。

**垃圾回收的原则**

- 对象优先在eden区分配
- eden区不足时，会进行一次Minor GC
- 当对象太大时，直接进入老年代
- Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需达到要求的年龄(动态对象年龄判定)



### 垃圾回收GC

#### 垃圾搜集算法

- 标记-清除算法

```
先标记待清除对象(或者不需要清除的对象)，在进行清除
优点：简单
缺点：效率低，需要标记和清除两个阶段，会随着对象的增加而降低
	空间碎片化的问题
```



- 标记-复制算法

```
将可用内存分为大小相等两块，只使用其中的一块。当对象在一次GC后存活了下来，就将该对象复制到另一块区域
设计依据：大多对象朝生夕灭
优点：避免了标记-清除算法的效率低下问题(只是在对象存活较少的情况下)
缺点：浪费了空间
```

- 标记-整理算法

```java
与标记-清除算法基本一致，区别在于在清除阶段，会先将存活的对象移到一边，更新引用位置等操作。一般应用在老年代这种对象存活较多的区域
优点：争对老年代无法使用标记-复制的情况
缺点：移动对象极为耗时，且更新引用也是，会暂停用户进程，造成“stop the wold"现象
```

#### 垃圾回收器

serial，parallel new parallel scanvage

serial old parallel old CMS 

- CMS

目的：获得最短回收停顿时间。

针对区域：老年代,服务侧

```
初始标记：标记GCroots能够直接关联的对象，需要stop the world
并发标记：遍历整个对象图，不需要stop the world 。
重新标记：更新在并发标记阶段，因为用户线程继续运作而导致的标记产生变动的那一部分（采用增量更新)
并发清除：清除标记对象


优点：并发标记和并发清除的耗时最长，但是可以并发执行，因为几乎没有stop the world

缺点：
无法处理浮动垃圾(在并发标记阶段和并发清除阶段，会有新的垃圾产生，且标记阶段已经结束，无法清除)
降低总吞吐量（垃圾回收线程占用cpu资源，致使用户工作线程占用时间减少）
产生大量的空间碎片（基于标记-清除算法）
```

- G1

目的：在一个M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N 毫秒

针对区域：全堆空间、服务侧

设计思想：采用局部收集和基于Region的内存布局形式  Mixed GC

```
将java堆分为Region，存放大对象的Region又称为Humongous。G1会维护一个优先级表，此表时根据回收垃圾所需的时间以及释放的空间大小来判定的。当用户指定了停顿时间，G1会优先回收那些价值大的Region。同时，G1采用的是原始快照(SATB)来解决并发时的可达性问题，
整体上基于标记整理算法，局部基于标记-复制算法。
初始标记：
并发标记
最终标记
筛选回收:暂停用户线程，所以可以清除浮动垃圾
每个Region都维护着一个记忆集，占用的空间非常大。

```

## 执行引擎

执行引擎（Execution Engine）的任务就是将字节码指令解释/编译为对应平台上的本地机器指令才可以。简单来说，JVM中的执行引擎充当了将高级语言翻译为机器语言的译者

JVM 有三种执行方式：解释执行、编译执行、混合模式（默认）

JIT及时编译器是编译器，先把字节码全部翻译成机器码指令后在执行。执行效率高，但是启动速度慢



### 什么是热点代码

JVM 设置一个阈值，当方法或者代码块的在一定时间内的调用次数超过这个阈值，就会被编译，存入 CodeCache。

再次执行这段代码时，直接从 CodeCache 中读取机器码执行，使执行效率大幅提升。



## JVM常用参数

显式指定堆内存`–Xms`和`-Xmx`

```
-Xms2G -Xmx5G 单位为***“ g”*** (GB) 、“ m”（MB）、“ k”（KB）。
```

指定新生代内存

```
默认为1310MB
-Xmn
```

设置新老年代的内存比值

```
-XX:NewRatio  老年代:新生代
```

Eden和Survivor区的比值

```
-XX:SurvivorRatio  默认为8：1：1
```

指定永久代/元空间的大小

```
初始大小：--XX:PermSize
最大值:-XX:MaxPermSize
-XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小）
-XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。
```

打印GC消息

```
-XX:+PrintGCDetails

```

指定GC

```
-XX:+UseSerialGC 使用serial+serial old
-XX:+UseParallelGC 使用Parallel Scavenge  +Parallel old
-XX:+UseParNewGC  使用CMS +parallel New
-XX:+UseG1GC  使用G1
```

大对象指定

```
-XX:PretenureSizeThreshold=
```

年轻代最大年纪

```
-XX:MaxTenuringThreshold=10  默认值为15，超过15就进入老年代
```

## JVM调优

### CPU满载

首先通过top 命令查看哪个线程占用的cpu过高

然后可以通过 jstack  PID查看该线程对应的堆栈信息

然后根据线程的堆栈信息定位到具体业务方法。从代码逻辑找到问题所在。

一般是递归调用没有终止条件

### 内存飙高

一般是因为短时间创建了大量的对象，GC跟不上对象的创建速度。或者存在内存泄露。

先观察jstat -gc PID 1000  打印GC信息

jmap -histo PID|head -20 查看堆内存占用最大的前二十个对象类型

如果每次回收的对象特别多，那就可能存在对象创建速度太快；

如果每次回收的对象比较少，那就可能存在内存泄露的问题

使用 jmap -dump：live，format=b，file=/home  生成堆内存快照文件

找到占用内存高的对象，定位到具体的业务代码

### 网站反应很慢

推测可能是因为频繁GC导致STW

通过jstat -gc打印gc信息，如果GC时间过长，就可以推断是因为频繁gc导致的STW

可以通过增加内存来解决。如果内存过后反应有所改善，但是偶尔加载仍旧会慢

就可能使因为内存过大，导致的GC时间过长。这时候可以尝试换G1垃圾回收器。

### 频繁进行FULL GC

通过jstat 命令查看每次GC进入老年代的大小，如果太大，就有可能是survivor区内存太小，导致许多对象提前进入老年代。

### 排查内存溢出

使用MAT软件

# Redis

redis是个内存数据库，即它的数据是放在内存里的。所以可以用来做缓存，除此之外，还可以做分布式锁，甚至消息队列。

## Redis和Memcached的对比

相同点：

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

不同点：

1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。
3. **Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。**
4. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** （Redis 6.0 引入了多线程 IO ）
5. **Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。**
8. **Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**

```
string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。
```

```
惰性删除
含义：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null。
优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了）
缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）
定期删除：REdis采用定期随机抽取的策略，选择将抽取的一批数据进行删除。

```

## Redis为什么快

![img](F:\Pictures\Typora\9d82d158ccbf6c81a5b7d1c201bbb13c32fa40a2.png)

## Redis的基本使用

### String

应用场景：

```
 一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等
```

常用命令

```
set 、get、strlen、incr，decr，mset、del
```

使用范例

```
127.0.0.1:6379> set key value #设置 key-value 类型的值
OK
127.0.0.1:6379> get key # 根据 key 获得对应的 value
"value"
127.0.0.1:6379> exists key  # 判断某个 key 是否存在
(integer) 1
127.0.0.1:6379> strlen key # 返回 key 所储存的字符串值的长度。
(integer) 5
127.0.0.1:6379> del key # 删除某个 key 对应的值
(integer) 1
127.0.0.1:6379> get key
(nil)
```

```Redis
127.0.0.1:6379> mset key1 value1 key2 value2 # 批量设置 key-value 类型的值
OK
127.0.0.1:6379> mget key1 key2 # 批量获取多个 key 对应的 value
1) "value1"
2) "value2"

```

```
127.0.0.1:6379> set number 1
OK
127.0.0.1:6379> incr number # 将 key 中储存的数字值增一
(integer) 2
127.0.0.1:6379> get number
"2"
127.0.0.1:6379> decr number # 将 key 中储存的数字值减一
(integer) 1
127.0.0.1:6379> get number

```

过期

```
127.0.0.1:6379> expire key  60 # 数据在 60s 后过期
(integer) 1
127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
OK
127.0.0.1:6379> ttl key # 查看数据还有多久过期
(integer) 56
```

### list

应用场景

```
发布与订阅或者说消息队列、慢查询
```

常用命令

```
rpush,lpop,lpush,rpop,lrange,llen
```

范例

```
通过 rpush/lpop 实现队列：

127.0.0.1:6379> rpush myList value1 # 向 list 的头部（右边）添加元素
(integer) 1
127.0.0.1:6379> rpush myList value2 value3 # 向list的头部（最右边）添加多个元素
(integer) 3
127.0.0.1:6379> lpop myList # 将 list的尾部(最左边)元素取出
"value1"
127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
1) "value2"
2) "value3"
127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一
1) "value2"
2) "value3"


```

```
通过 rpush/rpop 实现栈： 
127.0.0.1:6379> rpush myList2 value1 value2 value3
(integer) 3
127.0.0.1:6379> rpop myList2 # 将 list的头部(最右边)元素取出
"value3"

```

```
通过 lrange 查看对应下标范围的列表元素： 
127.0.0.1:6379> rpush myList value1 value2 value3
(integer) 3
127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
1) "value1"
2) "value2"
127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一
1) "value1"
2) "value2"
3) "value3"

lrange还可以实现分页查询功能
```

```
通过 llen 查看链表长度：


127.0.0.1:6379> llen myList
(integer) 3
```

### hash

hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，**特别适合用于存储对象**，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。 

应用场景：

```
对象数据的存储
```

常用命令：

```
hset,hmset,hexists,hget,hgetall,hkeys,hvals
```

范例

```
127.0.0.1:6379> hmset userInfoKey name "guide" description "dev" age "24"
OK
127.0.0.1:6379> hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。
(integer) 1
127.0.0.1:6379> hget userInfoKey name # 获取存储在哈希表中指定字段的值。
"guide"
127.0.0.1:6379> hget userInfoKey age
"24"
127.0.0.1:6379> hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值
1) "name"
2) "guide"
3) "description"
4) "dev"
5) "age"
6) "24"
127.0.0.1:6379> hkeys userInfoKey # 获取 key 列表
1) "name"
2) "description"
3) "age"
127.0.0.1:6379> hvals userInfoKey # 获取 value 列表
1) "guide"
2) "dev"
3) "24"
127.0.0.1:6379> hset userInfoKey name "GuideGeGe" # 修改某个字段对应的值
127.0.0.1:6379> hget userInfoKey name
"GuideGeGe"

```

### set

 set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。

应用场景：

```
需要存储的数据不能重复以及需要获取多个数据源的交集
```

常用命令

```
sadd,spop,smembers,sismember,scard,sinterstore,sunion
```

范例

```
127.0.0.1:6379> sadd mySet value1 value2 # 添加元素进去
(integer) 2
127.0.0.1:6379> sadd mySet value1 # 不允许有重复元素
(integer) 0
127.0.0.1:6379> smembers mySet # 查看 set 中所有的元素
1) "value1"
2) "value2"
127.0.0.1:6379> scard mySet # 查看 set 的长度
(integer) 2
127.0.0.1:6379> sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素
(integer) 1
127.0.0.1:6379> sadd mySet2 value2 value3
(integer) 2
127.0.0.1:6379> sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中
(integer) 1
127.0.0.1:6379> smembers mySet3
1) "value2"

```

### zset

和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。 

使用场景

```
对某个数据根据权重进行排行
```

常用命令

```
zadd,zcard,zscore,zrange,zrevrange,zrem
```

延迟队列：使用zset，生产者将生产消息的时间戳座位score，消息作为value。消费者通过zrangeByscore获取数据。

## Redis单线程

Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。

而Redis的主要性能瓶颈在于内存的大小，而不是cpu，减少了线程切换带来的系统性能开销。

但是多核cpu的性能无法完全发挥出来。

redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。

多路-指的是多个socket连接，复用-指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll是最新的也是目前最好的多路复用技术。

epoll多路复用

- `epoll_create1`: 创建一个epoll实例，文件描述符
- `epoll_ctl`: 将监听的文件描述符添加到epoll实例中，实例代码为将标准输入文件描述符添加到epoll中
- `epoll_wait`: 等待epoll事件从epoll实例中发生， 并返回事件以及对应文件描述符l

epoll的两种触发方式：边沿触发、水平触发

```
当epoll_wait检测到fd上有事件发生并将此事件通知应用程序后，应用程序必须立即处理该事件，因为后续的epoll_wait调用将不再向应用程序通知这一事件。

      epoll_wait只有在客户端第一次发数据是才会返回,以后即使缓冲区里还有数据，也不会返回了。epoll_wait是否返回，是看客户端是否发数据，客户端发数据了就会返回，且只返回一次。

         eg：客户端发送数据，I/O函数只会提醒一次服务端fd上有数据，以后将不会再提醒

所以要求服务端必须一次把数据读完--->循环读数据 (读完数据后，可能会阻塞)  --->将描述符设置成非阻塞模式

二、LT模式（水平触发）的文件描述符(fd)：

        当epoll_wait检测到fd上有事件发生并将此事件通知应用程序后，应用程序可以不立即处理该事件，这样，当应用程序下一次调用epoll_wait时，epoll_wait还会再次向应用程序通知此事件，直到此事件被处理。

```



## Redis内存淘汰机制

```
Redis 提供 6 种数据淘汰策略： 
volatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 

volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰

volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 
allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）

allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 
no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种： 

volatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰 

allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key


```

下8种选项：

| **策略**        | **描述**                                                 | **版本** |
| :-------------- | :------------------------------------------------------- | :------- |
| noeviction      | 直接返回错误；                                           |          |
| volatile-ttl    | 从设置了过期时间的键中，选择过期时间最小的键，进行淘汰； |          |
| volatile-random | 从设置了过期时间的键中，随机选择键，进行淘汰；           |          |
| volatile-lru    | 从设置了过期时间的键中，使用LRU算法选择键，进行淘汰；    |          |
| volatile-lfu    | 从设置了过期时间的键中，使用LFU算法选择键，进行淘汰；    | 4.0      |
| allleys-random  | 从所有的键中，随机选择键，进行淘汰；                     |          |
| allkeys-lru     | 从所有的键中，使用LRU算法选择键，进行淘汰；              |          |
| allkeys-lfu     | 从所有的键中，使用LFU算法选择键，进行淘汰；              | 4.0      |

## LRU算法

基于HashMap和双向链表。HasMap存储Redis的key，value指向双向链表实现LRU的Node节点。

LRU的实现过程：首先设置双向链表的容量，如果存储满了，就淘汰尾部的数据。增加或者访问数据的时候，把数据放在链表头部。



## Redis的持久化机制

**快照（snapshotting）持久化（RDB）**

Redis会fork出一个子线程用于将redis中的数据写入磁盘当中，当数据写入完成后，删除原有的RDB文件，用新写入的RDB文件代替

优点：通过子进程来完成数据的复制，可以最大化redis的性能

缺点：如果数据量太大，可能会造成一定时间内的停止请求。同时，一旦redis异常退出，会损失很大的数据。

默认有此下配置：

```
save 60 10000     #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

**AOF（append-only file）持久化**

每执行一条会更改Redis中数据的命令。Redis就会将该命令追加到硬盘中的AOF文件。

优点：可以尽量避免在服务器故障时丢失数据

缺点：AOF的文件体积更大

RDB非常适合做数据容灾，同时恢复数据也比AOF文件快。

```
appendonly yes
```



```
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显式地将多个写命令同步到硬盘
appendfsync no        #让操作系统决定何时进行同步

```

## Redis并发竞争问题和事务

并发竞争问题主要是多个事务同时读取key-value，并对value操作。读取的数据可能一样，操作的顺序无法保证，从而导致出现数据安全问题。

解决办法：分布式锁（setnx、zookeeper），消息队列，CAS

redis的CAS主要是通过watch来实现的。在exec命令执行之前，监视key，如果key改变了，就拒绝修改。

在分布式环境中，不推荐使用事务。

事务的四大特性

```
原子性：指代事务是一个不可再分割的工作单位,该事务中的操作要么都成功,要么都不成功.
隔离性：并发的事务之间互不影响
一致性：事务完成前后不会改变数据的完整性。即结果符合操作的预期
持久性：事务一旦完成，就不可更改
```

Redis的事务与普通数据库的有所不同。其不支持原子性和回滚。

没有必要支持回滚。事务执行失败，只是因为自己的语法问题。

## Redis的读写机制

旁路缓存模式

读：先从redis缓存中读，如果不存在，再到数据库进行读取。读取完毕以后将数据写到redis缓存中

写：先写到数据库中，然后直接删除redis中的值

```
一般采用直接删除的办法：因为如果更新缓存的话
先更新数据库，后更新缓存，两个事务A先于B更新数据库，但是B先于A更新缓存
先更新缓存，再更新数据库 事务A先于B更新缓存，但是B却先于A更新数据库

先删除缓存，再更新数据库？读写并发的场景下会出现问题。A删除缓存，B读数据库，A更新数据库

先更新数据库，再删除缓存：B读缓存不存在，到数据库读。A写数据库，删除缓存，B更新缓存
```

读写缓存模式

将redis作为主力 读：从redis中读，如果redis不存在，则让redis从数据库中读，然后再返回结果

写：往redis中写，最后redis再往数据库写。

异步缓存模式

## Redis的事务

在Redis中开启事务使用multi命令，执行事务使用exec命令。multi到exec命令之间的所有Redis命令将采取进入队列的形式，直至exec命令的出现，才会一次性发送队列里的命令去执行，而在执行这些命令的时候中间不会被其他Redis命令所打断，这就是Redis的事务机制。

取消事务 discard。

如果是数据类型的操作出现错误，该命令不会被执行，但是其他命令仍旧执行

如果是命令的错误，该事务仍会被执行。



## Redis的应用场景

### 分布式缓存

因为Redis的数据是存储在内存上的，读写速度非常快。而对于传统的关系型数据库来说，一次读写的IO操作非常费时，不利于大规模的应用

### 消息队列

Redis自带的list数据结构可以作为一个简单的消息队列来使用

### 限流

Redis+lua+AtomicInteger脚本的方式

方式:自定义一个注解.并对该注解做一个AOP切面.该切面主要完成的功能是每次在方法调用之前将调用lua脚本检查redis里面的缓存是否大于限制,如果大于就返回,不大于就将key加一,然后设置过期时间.调用结束之后将将该注解放置到方法上,每次调用该方法时,就会执行通知.

### 分布式锁

一般采用Redission。当不同的服务请求Redis上的缓存数据时，发现并不存在该key，就会跑到数据库中查询，可能会造成数据不一致的问题。根本原有是其他服务不受另一个服务加锁的限制。

![图片](F:\Pictures\Typora\640.png)

加了分布式锁之后，是这样的情形：

![图片](F:\Pictures\Typora\640-164724130670615.png)

第一种方案：

![图片](F:\Pictures\Typora\640-164724131089717.png)

利用setnx命令。

- 多个并发线程都去 Redis 中申请锁，也就是执行 setnx 命令，假设线程 A 执行成功，说明当前线程 A 获得了。
- 其他线程执行 setnx 命令都会是失败的，所以需要等待线程 A 释放锁。
- 线程 A 执行完自己的业务后，删除锁。
- 其他线程继续抢占锁，也就是执行 setnx 命令。因为线程 A 已经删除了锁，所以又有其他线程可以抢占到锁了。

缺点：容易造成死锁

改进：将锁设置过期时间

第二种方案：

将setnx的key设置过期时间。

缺点：setnx和设置定期时间是两步操作。如果中间出现了异常，依旧会出现死锁的情况

第三种方案:

redis支持事务操作.利用set key value ex xx nx 来实施

缺点:过期时间到了以后进程还没有完成任务,此时B获得了锁进入了操作.A也在操作.当A执行完毕后,删除了锁,

第四种解决方案:

​	将value设置一个唯一编号,只要唯一编号相同时,才会删除锁.

缺点:依旧保证不了数据一致性.因为A拿到了锁,目的是为了获取编号值删除锁,之后锁自动过期,B拿到了锁,但是此时A会认为目前的锁就是自己的,删除.

第五种方案:

将查询锁和删除锁变成原子性的操作.

该方式采用Lua脚本的方法.Lua脚本是执行一组命令，所有命令的执行要么全部成功或者失败，以此达到原子性。也可以把`Lua`脚本理解为，一段具有业务逻辑的代码块。

第六种方案:

使用Redission

总结：设置锁、锁的过期时间、唯一id（原子性），当完成事务操作后，获取锁的ID，当锁的value为事务的id时，才可以删除锁（查询锁和删除锁采用lua脚本）。

### 延迟队列

**如果对方追问[redis]()如何实现延时队列？**我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 

 到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。

## 击穿与雪崩

### 击穿

定义

```
某一个热点key不存在于缓存上，导致查询请求直接到了数据库上，而根本没有经过缓存这一层面
```

热点数据设置永不过期

设置分布式锁，当查到一个key过期时，设置分布式锁，然后从数据库读取，更新redis。其他请求将从redis中查询。

### 穿透

```
请求的key根本就不存在，绕过了redis
```

缓存空对象、布隆过滤器

### 布隆过滤器简介

![img](F:\Pictures\Typora\v2-73f4ab0824e1353fb80a60dced10b5e2_720w.jpg)

- 如果这些点有任何一个 0，则被查询变量一定不在；
- 如果都是 1，则被查询变量很**可能存在**
- **一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在**。
- **布隆过滤器可以添加元素，但是不能删除元素**。因为删掉元素会导致误判率增加。

应用场景：防止穿透、去重、

### 雪崩

```
缓存在某个时间点内大面积失效，或者服务器宕机，导致所有的请求都落到了数据库上。
```

设置集群

服务降级

热点数据永不过期

## Redis的集群

### 为什么需要集群

- 提高容错
- 读写分离，提高并发量

### 主从复制

![image-20220317145510224](F:\Pictures\Typora\image-20220317145510224.png)

主从模式解决了Redis单机版存在的问题，但其本身也不是完美的，主要优缺点如下：
优点：
高可靠性，在master数据库出现故障后，可以切换到slave数据库
读写分离，slave库可以扩展master库节点的读能力，有效应对大并发量的读操作
缺点：
不具备自动容错和恢复能力，主节点故障，从节点需要手动升为主节点，可用性较低

### 哨兵模式

![image-20220317145956395](F:\Pictures\Typora\image-20220317145956395.png)

从上图中可以看出，哨兵模式相比于主从模式，主要多了一个哨兵集群，哨兵集群的主要作用如下：

- 监控所有服务器是否正常运行：通过发送命令返回监控服务器的运行状态，处理监控主服务器、从服务器外，哨兵之间也相互监控。

- 故障切换：当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换master。同时那台有问题的旧主也会变为新主的从，也就是说当旧的主即使恢复时，并不会恢复原来的主身份而是作为新主的一个从。


优点：

​	哨兵模式是基于主从模式的，解决可主从模式中master故障不可以自动切换故障的问题。

缺点

​	主机宕机后，选举投票结果出来之前，这段时间会禁止写操作

​	全量数据写入主从节点，造成很大的压力

### Redis Cluster

![image-20220317151910971](F:\Pictures\Typora\image-20220317151910971.png)

一致性哈希和哈希槽

分布式缓存系统中的数据选择节点存储问题和数据选择节点读取问题以及在增删节点后减少数据缓存的消失范畴，防止雪崩的发生。

一致性哈希问

​	将某一个数映射到闭合的圆环上，具体的映射方法为，存放的位置是顺时针离他最近的redis实例上。

数据倾斜的问题:采用增加虚拟节点。虚拟节点是到真实节点的映射。比如顺时针方向是A->B，新来的key在其之间，正常应该分配到B，但是增加了一个虚拟节点，在AB之间，C指向A，此时会映射到A节点。

哈希槽

​	redis cluster中有16384个槽。当需要存储一个key—value时，首先采用crc16算法得出hash值，最后对16384取余，得到key在槽中的位置。每个Redis节点负责某一段的哈希槽，此时该数据就会存放在对应得节点中了

![img](F:\Pictures\Typora\832_8fd_67a.jpg)

master节点的slave节点不分配槽，**只拥有读权限。可是注意在代码中redis cluster执行读写操做的都是master节点，并非你想 **

**的读是从节点，写是主节点**。

区别：

1. 它并非闭合的，key的定位规则是**根据CRC-16(key)%16384的值来判断属于哪一个槽区，从而判断该key属于哪一个节点**，而一致性哈希是根据hash(key)的值来顺时针找第一个hash(ip)的节点，从而肯定key存储在哪一个节点。
2. 一致性哈希是建立虚拟节点来实现节点宕机后的数据转移并保证数据的安全性和集群的可用性的。redis cluster是采用master节点有多个slave节点机制来保证数据的完整性的,master节点写入数据，slave节点同步数据。当master节点挂机后，slave节点会经过选举机制选举出一个节点变成master节点，实现高可用

采用槽分区的概念。将key映射到不同的分区。

![img](F:\Pictures\Typora\99D279C3308D2714C0B5201E581386F7.png)





## Redis数据类型的底层结构

- String类型

简单动态字符串(simple dynamic string, SDS)的抽象类型。Redis中，默认以SDS作为自己的字符串表示。只有在一些字符串不可能出现变化的地方使用C字符串。

![image-20220403170731207](F:\Pictures\Typora\image-20220403170731207.png)

- list

(1)**压缩列表实现**，(2)**双向循环链表实现**。

列表中保存的单个数据小于64字节**，列表中数据个数小于512个。**

压缩列表ziplist

底层是一个类似于数组的结构，只不过每个数组的大小不固定，可以装载不同的数据类型

- Hash

（1）压缩列表实现，（2）散列表实现

字典中保存的键和值数据大小，都要小于64字节。字典中数据个数小于512个

- set

（1）有序数组实现，（2）散列表实现。

存储的数据都是整数，并且存储的元素个数小于512个时

- zset

score允许重复

（1）压缩列表，（2）跳表

**数据大小都小于64字节，并且元素的个数小于128个时，使用压缩列表实现。**



为什么用跳跃列表而不用平衡树

![img](F:\Pictures\Typora\714264ea6eba7af0fe67.pngtplv-t2oaga2asx-zoom-in-crop-mark1304000.awebp)

节点层数的概率为p

首先跳跃列表相较于平衡树更容易实现

其次跳跃列表的查找速度比平衡树快。在查找到某一范围的值后，跳跃列表只需要堆第一层的数据进行遍历即可

而且跳跃列表在进行插入删除时仅更新相邻节点的指针，不涉及到树的选择操作

最后，跳跃列表的占用内存跟p有关系，更加灵活1/(1-p)。redis中p取值1/4。p是层数分布的概率。

## 布隆过滤器

布隆过滤器是基于位图的一种设计。布隆过滤器第一次初始化的时候，会把数据库中所有已存在的key，经过一系列的hash算法计

算，算出每个key的位置，并将该位置的值置为1，为了减少哈希冲突的影响，可以对每个key进行多次hash计算，如下图现在，用户

所有的请求都要经过布隆过滤器过滤一遍，如果只有用户请求的key的hash值都是1才可以通过，否则直接拦截，如下图

![image-20220317155726652](F:\Pictures\Typora\image-20220317155726652.png)

# 计算机网络

## 网络协议

### 七层协议

- 物理层

​	传输比特流。集线器，中继器

- 数据链路层

将ip层传输下来的ip数据报组装成帧，进行差错检测，同步等功能。交换机，网桥

- 网络层

将传输层传下来的报文段封装成分组，路由转发，拥塞控制。数据段

- 传输层

负责两个主机之间进程的通信。提供可靠性服务，差错控制，流量控制，服务质量等。

- 会话层

管理主机之间会话的进程

- 表示层

负责两个主机之间的数据转化，加密解密等

- 应用层

提供具体的应用服务

### URL

包括协议、网址、文件地址部分

URI(Uniform Resource Identifier)：中文全称为统一资源标志符，主要作用是唯一标识一个资源。  
		URL(Uniform Resource Location)：中文全称为统一资源定位符，主要作用是提供资源的路径。  
		有个经典的比喻是URI像是身份证，可以唯一标识一个人，而URL更像一个住址，可以通过URL找到这个 



### ARP协议

- 在局域网内，主机A要向主机B发送IP数据报时，首先会在主机A的ARP缓存表中查找是否有IP地址  及其对应的MAC地址，如果  有，则将MAC地址写入到MAC帧的首部，并通过局域网将该MAC帧发   送到MAC地址所在的主机B。

- 如果主机A的ARP缓存表中没有主机B的IP地址及所对应的MAC地址，主机A会在局域网内广播发送  一个ARP请求分组。局域网内的所有主机都会收到这个ARP请求分组。  主机B在看到主机A发送的ARP请求分组中有自己的IP地址，会像主机A以单播的方式发送一个带有  自己MAC地址的响应分组。  
- 主机A收到主机B的ARP响应分组后，会在ARP缓存表中写入主机B的IP地址及其IP地址对应的MAC地址。    
-  如果主机A和主机B不在同一个局域网内，即使知道主机B的MAC地址也是不能直接通信的，必须通  过路由器转发到主机B的局     域网才可以通过主机B的MAC地址找到主机B。并且主机A和主机B已经  可以通信的情况下，主机A的ARP缓存表中寸的并不是主    机B的IP地址及主机B的MAC地址，而是主 机B的IP地址及该通信链路上的下一跳路由器的MAC地址。

### 为什么需要MAC地址

如果只用IP地址而不用MAC地址的话，当一个网络中的设备数量极为庞大，就会出现查找路由表极为耗时的情况。同时，IP并不是固定，一个网卡可以绑定多个IP,这也会给寻址带来困难。

### IP数据包经过路由器转发的过程

首先通过子网掩码与IP地址进行与操作判断该IP是否在本子网内，如果在的话，就会通过ARP表查找相应主机的MAC地址，如果ARP表不存在，就会通过ARP协议发送广播信号得到目的主机的MAC地址，然后将该IP数据包转发至相应的主机。如果不在同一个子网内，就会查找路由表，找到下一跳的地址和MAC地址，将IP数据包的目的MAC换为下一跳的目的MAC地址，IP数据包的源MAC变为自己的MAC地址，IP数据包的目的MAC变为下一跳路由的MAC地址。

### DNS流程

主机向本地域名服务器的查询一般是采用递归查询，而本地域名服务器向根域名的查询一般是采用迭代查询。  
 在浏览器中输入www.baidu.com域名，操作系统会先检查自己本地的hosts文件是否有这个域名的映射关系，如果有，就先调用这个IP地址映射，完成域名解析。  
如果hosts文件中没有，则查询本地DNS解析器缓存，如果有，则完成地址解析。  
如果本地DNS解析器缓存中没有，则去查找本地DNS服务器，如果查到，完成解析。  
如果没有，则本地服务器会向根域名服务器发起查询请求。根域名服务器会告诉本地域名服务器去查询哪个顶级域名服务器。   
本地域名服务器向顶级域名服务器发起查询请求，顶级域名服务器会告诉本地域名服务器去查找哪个权限域名服务器。  
本地域名服务器向权限域名服务器发起查询请求，权限域名服务器告诉本地域名服务器www.baidu.com所对应的IP地址。本地域名服务     器告诉主机www.baidu.com所对应的IP地址。

### TTL、MSL、RTT、RTO

TTL:在ip报文首部，有个TTL标志位，它表示该报文最多可以经过的跳数。每一跳就将其值减一

MSL：数据包在网络中生存的最大时间

RTT:***客户从发送数据到收到相应数据的往返所花时间\***

RTO：发送方在发送出一个报文后的RTO时间里没有收到应答，就会重新发送

### TraceRoute的原理

利用TTL来获取。客户端首先会发送三个TTL为1的IP数据包，收到后再次发送TTL为2的IP 数据包

以此类推，直到未收到响应为止。

### IP地址分类



### BGP和OSPF

一个是自治系统内部路由-ospf。属于内部网关协议。基于UDP通信
		一个是自治系统间路由-bgp。属于外部网关协议。基于TCP通信

### DNS解析失败排查

首先排查是否有DNS解析的问题：nslookup会出现DNS的服务器地址，之后输入网址，如果收到错误信息，说明DNS解析解析真正出现了问题，在进行排查

先看DNS服务器是否正常工作。

### 说一下ping的过程   

ping是ICMP(网际控制报文协议)中的一个重要应用，ICMP是网络层的协议。ping的作用是测试两个主机的连通性。ping的工作过  程： 

- 向目的主机发送多个ICMP回送请求报文
- 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率

### 网页上不了网的原因排查

网络防火墙

hosts文件

网络设置（网关、ip）

DNS服务器的问题

### 网络攻击

- SQL注入

预编译

- 文件上传攻击

指定文件上传类型、改名

- CSRF   跨站请求伪造

samesite 不推荐

reference origin

token

- XSS 跨站脚本攻击

反射性、存储型

httpOnly

- DDOS  分布式拒绝访问服务

SYN泛洪、UDP泛洪、Http泛洪、ARP泛洪

## HTTP和https

![image-20220317101402667](F:\Pictures\Typora\image-20220317101402667.png)

### HTTP 各版本的区别

![image-20220316103336805](F:\Pictures\Typora\image-20220316103336805.png)

HTTP/2一个域名只使用一个TCP⻓连接来传输数据，而且请求直接是并行的、非阻塞的，这就是多路复用

### https的工作原理



![img](F:\Pictures\Typora\B7268EF66524898CEF0E068EA5F1BA26.gif)

首先是ip地址查找

- 输入url后，浏览器根据浏览器缓存、本地缓存和hosts文件查找对应的ip地址。如果没有找到就到本地DNS服务第查找，最后递归遍历DNS服务器。找到对应的ip地址

其次是建立tcp连接

- 首先客户端向服务端发送请求连接，发送SYN
- 服务器收到SYN后，返回ACK和SYN，表示接收请求和请求和客户端建立连接
- 客户端收到以后，回应一个ACK。表示同意建立连接。至此三次握手完成

然后是发送HTTP请求

- 客户端向服务端发送http请求
- 服务端收到请求后返回一个响应
- 客户端收到响应后进行渲染并呈现给客户

最后是TLS请求

- 客户端向服务端发送支持的tls协议版本、压缩算法、随机数和支持的加密算法
- 服务端收到后，确定使用的TLS版本和加密算法，并将选择的结果+CA证书发送给客户端。CA证书中包含了服务端的公钥
- 客户端收到该CA证书后，对CA证书进行验证，验证完成后，用服务端的公钥对自己的公钥进行加密，传输给服务端。
- 服务端收到后，用自己的私钥解密，得到客户端的公钥。

#### CA证书

CA:颁发CA证书的机构

证书包含以下信息：申请者[公钥](https://so.csdn.net/so/search?q=公钥&spm=1001.2101.3001.7020)、申请者的组织信息和个人信息、签发机构 CA 的信息、有效时间、证书序列号等信息的明文，同时包含一个签名（指纹）；
签名的产生算法：首先，使用[散列](https://so.csdn.net/so/search?q=散列&spm=1001.2101.3001.7020)函数计算公开的明文信息的信息摘要，然后，采用 CA 的私钥对信息摘要进行加密，密文即签名；

浏览器认证CA证书的流程：

客户端收到服务端传来的CA证书后，首先在本地找是否有相应CA机构的根证书，如果没有，警告该证书是非法的。如果有，进行下一步认证：利用根证书里面的公钥对签名进行解密，得到摘要和散列函数，再用散列函数对证书中的明文进行计算得到另一个摘要，将两者的摘要进行对比，一致就认为是合法的。

只要我们将根证书安装上，就说明我们对根证书是信任的，若终端信任根证书，则信任根证书生成的其他证书。终端没有安装相应https证书则不能访问https网站。

### HTTP的状态码

![image-20220228221437378](F:\Pictures\Typora\image-20220228221437378.png)

1. **2xx （3种）**

   **200 OK：**表示从客户端发送给服务器的请求被正常处理并返回；

   202 Created ：已接受该请求，但是未处理完成

   **204 No Content：**表示客户端发送给客户端的请求得到了成功处理，但在返回的响应报文中不含实体的主体部分（没有资源可以返回）；

   **206 Patial Content：**表示客户端进行了范围请求，并且服务器成功执行了这部分的GET请求，响应报文中包含由Content-Range指定范围的实体内容。

2. **3xx （5种）**

   **301 Moved Permanently：**永久性重定向，表示请求的资源被分配了新的URL，之后应使用更改的URL；

   **302 Found：**临时性重定向，表示请求的资源被分配了新的URL，希望本次访问使用新的URL；

   301与302的区别：前者是永久移动，后者是临时移动（之后可能还会更改URL）

   **303 See Other：**表示请求的资源被分配了新的URL，应使用GET方法定向获取请求的资源；

   302与303的区别：后者明确表示客户端应当采用GET方式获取资源

   **304 Not Modified：**表示客户端发送附带条件（是指采用GET方法的请求报文中包含if-Match、If-Modified-Since、If-None-Match、If-Range、If-Unmodified-Since中任一首部）的请求时，服务器端允许访问其使用缓存资源，但是请求为满足条件的情况下返回该状态码；

   **307 Temporary Redirect：**临时重定向，与303有着相同的含义，307会遵照浏览器标准不会从POST变成GET；（不同浏览器可能会出现不同的情况）；

3. **4xx （4种）**

   **400 Bad Request：**表示请求报文中存在语法错误；

   **401 Unauthorized：**未经许可，需要通过HTTP认证；

   **403 Forbidden：**服务器拒绝该次访问（访问权限出现问题）

   **404 Not Found：**表示服务器上无法找到请求的资源，除此之外，也可以在服务器拒绝请求但不想给拒绝原因时使用；

4. **5xx （2种）**

   **500 Inter Server Error：**表示服务器在执行请求时发生了错误，也有可能是web应用存在的bug或某些临时的错误时；

   **503 Server Unavailable：**表示服务器暂时处于超负载或正在进行停机维护，无法处理请求；

### 重定向和请求转发的区别

1. （1）请求次数：重定向是浏览器向服务器发送一个请求并收到响应后再次向一个新地址发出请求，转发是服务器收到请求后为了完成响应跳转到一个新的地址；重定向至少请求两次，转发请求一次；

   （2）地址栏不同：重定向地址栏会发生变化，转发地址栏不会发生变化；

   （3）是否共享数据：重定向两次请求不共享数据，转发一次请求共享数据（在request级别使用信息共享，使用重定向必然出错）；

   （4）跳转限制：重定向可以跳转到任意URL，转发只能跳转本站点资源；

   （5）发生行为不同：重定向是客户端行为，转发是服务器端行为。

### HTTP的请求头、响应头、响应体

- 请求报文

  ```
  请求行：GET /charter/index.html  http1.1
  请求头:键值对的形式。与cache有关的信息均存在请求头中
  Accept，Cookie、Referer，Cache-control
  请求体：将请求内容以键值对的方式呈现
  ```

- 响应报文

```
响应行：HTTP/1.1 400 Bad request
响应头：key:value
响应体：
```

字段

cookie：

```
name、value、domain、path、size、expire、secure、
httponly：只允许在http请求中附带cookie，无法通过js脚本获取cookie
```

User-Agent

Accept-charset

Accept-encoding

connection：keep-alive/closed

reference:跳转的来源网址

Content-length：内容长度

If-Modified-Since：条件请求。客户只想比指定日期更新的文档

响应头

Transfer-Encoding: chunked 资源分块传输

 Last-Modified  服务器对该资源最后的修改时间

Refresh: 1;url=http://www.it315.org(服务端要求客户端1秒钟后，刷新，然后访问指定的页面路径)

### HTTP和TCP的长连接

Http1.0长连接默认关闭，http1.1默认开启。可以通过connection:keep alive/closed来开启或关闭。

HTTP的长连接属性是通过keep-alive=timeout来进行设置的。当http完成最后一个请求响应后，如果在timeout时间内没有新的请求，http就会关闭连接。

TCP的长连接属性keep_alive=timeout则是在通信双方没有继续传输数据的情况下，等待timeout然后再去发送一个侦测报文，多次发送如果都没有收到回应，就会断开连接。

### 如何判断http传输数据完毕

当http请求的是静态资源时，通过content：length来告诉浏览器数据是否已经传输完毕

当http请求的是动态资源时，通过Transfer-Encoding：chunked来告诉浏览器数据是分块传输的，当收到一个长度为0的chunked时，表示数据传送完毕



### URL的过程

​		1.对www.baidu.com这个网址进行DNS域名解析，得到对应的IP地址

```
先去DNS缓存里面找，找不到就去根域名服务器，根域名服务器到顶级域名服务器、二级域名服务器、三级域名服务器
```

　　2.根据这个IP，找到对应的服务器，发起TCP的三次握手

　　3.建立TCP连接后发起HTTP请求

　　4.服务器响应HTTP请求，浏览器得到html代码

　　5.浏览器解析html代码，并请求html代码中的资源（如js、css图片等）（先得到html代码，才能去找这些资源）

　　6.浏览器对页面进行渲染呈现给用户

### GET和POST的区别

- GET在浏览器回退时是无害的，而POST会再次提交请求。
- GET产生的URL地址可以被Bookmark，而POST不可以。
- GET请求会被浏览器主动cache，而POST不会，除非手动设置。
- GET请求只能进行url编码，而POST支持多种编码方式。
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
- GET请求在URL中传送的参数是有长度限制的，而POST没有。
- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
- GET参数通过URL传递，POST放在Request body中。
- 幂等性。GET方法是具有幂等性的，而POST方法不具有幂等性。这里幂等性指客户端连续发出多次请求，
  收到的结果都是一样的

### 处理POST的两次请求

- 利用session防止表单重复提交。当返回表单页面的时候，session中生成一个token，并将该token传给页面。当页面第一次提交  的时候带上token，如何session上的token和传过来的token一致，则进行处理；不一致就不进行处理。

- 通过redis实现。将第一次提交的内容保存到redis上，设置过期时间。

###  post不幂等是为什么？

HTTP方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。



get符合幂等性(多次操作后的结果是一样的，get操作只是查询)和安全性(不会修改原有数据)，post则反之

HTTP方法的幂等性是指一次和多次请求某一个资源应该具有同样的副作用。幂等性属于语义范畴，正如编译器只能帮助检查语法错误一样，HTTP规范也没有办法通过消息格式等语法手段来定义它。

POST所对应的URI并非创建的资源本身，而是资源的接收者。比如：POST http://www.forum.com/articles的语义是在http://www.forum.com/articles下创建一篇帖子，HTTP响应中应包含帖子的创建状态以及帖子的URI。两次相同的POST请求会在服务器端创建两份资源，它们具有不同的URI。所以，POST方法不具备幂等性。

###  cookie、session和token的区别是什么？

1. 存储位置不同：cookie存放于客户端；session存放于服务端。
2. 存储容量不同：单个cookie保存的数据<=4KB，一个站点最多保存20个cookie；而session并没有上限。
3. cookie存储在客户端，并不安全。token可以跨域，session不可以跨域，它是与域名绑定的。
3. 如果禁用了cookie，session也就不能使用了。但是可以通过其他方式，比如url传递sessionid

session存储在服务端，当有大量的请求过来时，十分浪费服务端的内存空间

![img](https://pic3.zhimg.com/80/v2-8acae7d043476c47143a9a4b5e2782f9_720w.jpg?source=1940ef5c)

都是用来解决http无状态协议的，在浏览器第一次向服务器发送请求时，服务器会随机生成一个JESSIONID，并通过setCookie将该JessionID返回给浏览器，

此后浏览器每次发送请求，都会带上该cookie。

URL地址重写是对客户端不支持Cookie的解决方案。URL地址重写的原理是将该用户Session的id信息重写到URL地址中。服务器能够解析重写后的URL获取Session的id。这样即使客户端不支持Cookie，也可以使用Session来记录用户状态。HttpServletResponse类提供了encodeURL(Stringurl)实现URL地址重写，

cookie字段熟悉：

name，value，domian（二级域名）、path、expire、httponly、size、secure

### 处理session跨域

采用分布式session

### 处理请求过程中的乱码问题

get请求：new String(username.getBytes("ISO-8859-1"),"UTF-8"); 或者修改tomcat中的配置文件

encodeURL（）方法

post请求：在取参数的时候设置编码格式

## TCP和UDP

### TCP报文结构

![img](F:\Pictures\Typora\B238C95751C34672AE79F902AD6A83CF.jpeg)

CP首部包括20字节的固定首部部分及长度可变的其他选项，所以TCP首部长度可变。20个字节又分为5部分，每部分4个字节32位，如图中的5行，每行表示32位。

1. **源端口和目的端口**字段——各占 2 字节（16位）。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。

2. **序号**字段——占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则**指的是本报文段所发送的数据的第一个字节的序号。**比如分组的第一个数据包由文件的14个字节数据组成，那么该数据包所添加的序号就是1，同理第二个数据包由文件的59个字节数据组成，那么该数据包所添加的序号就是15；

3. **确认号**字段——占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。比如接收端收到由文件14个字节数据+TCP首部组成的数据包后，删除首部提取14个字节数据，返回的确认号为5，即告诉发送端下一次应该发送文件的第5个字节及其之后字节组成的数据包过来。

4. **数据偏移**（即首部长度）——，也就是TCP首部的长度。“数据偏移”的单位是 32 位字（以 4 字节为计算单位），最大1111表示15x4=60个字节，即表示TCP首部最大长度为60个字节，因此“选项”部分最多40个字节。

5. **保留**字段——占 6 位，保留为今后使用，但目前应置为 0。

6. 这里的六位二进制位，分别表示不同含义：

   （1）**紧急 URG** —— 当 URG = 1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。 即URG=1的数据包不用排队直接优先传输。

   （2）**同步 SYN** —— 同步 SYN = 1 表示这是一个连接请求或连接接受报文。即A想与B建立连接，发送过去的第一个数据包（第一次握手）中SYN=1；B返回的数据包（第二次握手）中SYN=1表示同意建立连接。

   （3）**确认 ACK** —— 只有当 ACK = 1 时确认号字段才有效。当 ACK = 0 时，确认号无效。

   （4）**FIN断开连接**——发送端向接收端表示数据以传输完毕，将会单方向关闭连接。

   （5）***RST*异常终止报文***——*表示关闭由于异常而导致的连接，避免浪费系统资源

   （6）PSH表示希望该报文需要优先被处理

7. **窗口**字段 —— 占 2 字节，用来让对方设置发送窗口的依据，单位为字节。

8. **检验和** —— 占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。

9. **紧急指针**字段 —— 占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。

10. **选项**字段 —— 长度可变。TCP 最初只规定了一种选项，即最大报文段长度 MSS (Maximum Segment Size)是 TCP 报文段中的数据字段的最大长度。数据字段加上 TCP 首部才等于整个的 TCP 报文段。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节。”**其他选项**有：窗口扩大选项、时间戳选项、选择确认选项（SACK）。

11. **填充**字段 —— 这是为了使整个首部长度是 4 字节的整数倍。

### TCP和UDP的对比

连接：TCP通信之前必须建立连接，而UDP通信则直接发送数据

可靠性：TCP可靠性强，保证交付；而UDP不可靠，只提供尽力而为的服务

拥塞控制和流量控制：TCP有拥塞控制和流量控制，而UDP没有。因为拥塞不影响源主机的发送效率

报文长度：TCP的报文长度是根据收发双方的窗口和拥塞状态来决定的。而UDP是固定的

首部开销：TCO首部开销大，而UDP首部开销小

### 三次握手四次挥手

![img](F:\Pictures\Typora\d8f9d72a6059252d20d93b0a6645fb3e59b5b9d2.jpeg)

![img](F:\Pictures\Typora\48540923dd54564e5260495ce0006487d0584fb6.jpeg)

队头阻塞：主要是由于tcp协议的可靠性机制引入的问题。TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理。



```
TCP是一种全双工的模式。当客户端要断开连接时，说明它已经没有数据可以传输了，但是对于服务端却可能还存在着未发送完毕的数据。
```

为什么要有最后一次ACK:

三次握手

```
为了防止已经失效的连接请求报文段突然又传到服务端，因此产生错误
```

四次挥手

```
在服务端收到客户端请求断开连接后，由于服务端可能还存在着未发送完毕的数据，所以需要先发送一个ACk，数据发送完毕后再和客户端断开连接。
```

 

### TIME_WAIT和CLOSE_WAIT的区别在哪?  


CLOSE_WAIT是被动关闭形成的，当客户端发送FIN报文，服务端返回ACK报文后进入CLOSE_WAIT。

TIME_WAIT是主动关闭形成的，当第四次挥手完成后，客户端进入TIME_WAIT状态

### HTTP和TCP的队头阻塞

 **1. TCP队头阻塞**

​    TCP数据包是有序传输，中间一个数据包丢失，会等待该数据包重传，造成后面的数据包的阻塞。

  **2. HTTP队头阻塞**

​    http队头阻塞和TCP队头阻塞完全不是一回事。

​    http1.x采用长连接(Connection:keep-alive)，可以在一个TCP请求上，发送多个http请求。

​    有非管道化和管道化，两种方式。

​    **非管道化**，完全串行执行，请求->响应->请求->响应...，后一个请求必须在前一个响应之后发送。

​    **管道化**，下一个请求可以在没有收到响应之前发出，但是响应必须串行返回。后一个响应必须在前一个响应之后。原因是，没有序号标明顺序，只能串行接收。

​    **管道化请求的致命弱点**:

  （1）会造成队头阻塞，前一个响应未及时返回，后面的响应被阻塞   （2）请求必须是幂等请求，不能修改资源。因为，意外中断时候，客户端需要把未收到响应的请求重发，非幂等请求，会造成资源破坏。

​    由于这个原因，目前大部分浏览器和Web服务器，都关闭了管道化，采用非管道化模式。

  **解决http队头阻塞的方法：**

  **（1）并发TCP连接**（浏览器一个域名采用6-8个TCP连接，并发HTTP请求）   **（2）域名分片**（多个域名，可以建立更多的TCP连接，从而提高HTTP请求的并发）

### **为什么客户端在TIME-WAIT阶段要等2MSL?**

当客户端发出最后的ACK确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完ACK确认报文之后，会设置一个时长为2MSL的计时器。MSL指的是Maximum Segment Lifetime：一段TCP报文在传输过程中的最大生命周期。2MSL即是服务器端发出为FIN报文和客户端发出的ACK确认报文所能保持有效的最大时长。

服务器端在1MSL内没有收到客户端发出的ACK确认报文，就会再次向客户端发出FIN报文

### TCP粘包和拆包问题



MSS:MSS=MTU-header

MTU:传输层每次传输的数据最大值 

TCP为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了以后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制来接受数据。 发生TCP粘包、拆包主要是以下原因：   （1）应用程序写入数据大于套接字缓冲区大小，会发生拆包；   （2）应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发送粘包；   （3）进行MSS（最大报文长度）大小的TCP分段，当TCP报文长度——TCP header长度>MSS 的时候会发生拆包；   （4）接收方法不及时读取套接字缓冲区数据，这将发生粘包。

短链接的TCP不会发生粘包，但是会发生拆包

处理拆包：

- 包头+包长+包体
- 设置包结束标志位

处理粘包：

- 关闭negle算法
- 发送方及时的接收数据包



UDP无粘包现象。每次发送完毕后都断开连接。



### TCP的可靠性保障

#### 校验和

**计算方式：**在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。 **发送方：**在发送数据之前计算检验和，并进行校验和的填充。 **接收方：**收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。

![img](F:\Pictures\Typora\615A581F8A18065E509E57958679912F.png)

#### 序列号和确认应答、超时重传、连接管理



**序列号：**TCP传输时将每个字节的数据都进行了编号，这就是序列号。 **确认应答：**TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送ACK报文。这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。

 **超时重传**：在进行TCP传输时，由于确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功。如果发送方发送完数据后，迟迟没有等到接收方的ACK报文，这该怎么办呢？而没有收到ACK报文的原因可能是什么呢？

  首先，发送方没有接收到响应的ACK报文原因可能有两点：

  （1）数据在传输过程中由于网络原因等直接全体丢包，接收方根本没有接收到。

  （2）接收方接收到了响应的数据，但是发送的ACK报文响应却由于网络原因丢包了。

  TCP在解决这个问题的时候引入了一个新的机制，叫做超时重传机制。**简单理解就是发送方在发送完数据后等待一个时间，时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送。**如果是刚才第一个原因，接收方收到二次重发的数据后，便进行ACK应答。如果是第二个原因，接收方发现接收的数据已存在（判断存在的根据就是序列号，所以上面说序列号还有去除重复数据的作用），那么直接丢弃，仍旧发送ACK应答。

**连接管理**：连接管理就是三次握手与四次挥手的过程，保证可靠的连接，是保证可靠性的前提。



#### 拥塞控制

慢启动：在tcp刚建立连接之后，将拥塞窗口置为1，此后每有一个报文被确认，就会将拥塞窗口增加一倍。

拥塞避免：当拥塞窗口增加到某个阈值的时候，拥塞窗口的增加不再呈指数级，而是线性增加

快重传：当接收方连续收到三个重复确认的时，就会立即重传，而不是等待一个RTO时间

快恢复：当收到连续三个重复确认后，将拥塞窗口的阈值置为原先的一半，执行拥塞避免算法。

#### 流量控制

利用**滑动窗口机制**就可以实施流量控制。

在TCP协议的报头信息当中，有一个16位字段的窗口大小。在介绍这个窗口大小时我们知道，窗口大小的内容实际上是接收端接收数据缓冲区的剩余大小。这个数字越大，证明接收端接收缓冲区的剩余空间越大，网络的吞吐量越大。接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入，并跟随ACK报文一起发送过去。而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。并定期的向接收端发送窗口探测数据段，让接收端把窗口大小告诉发送端。

  **原理**就是运用TCP报文段中的窗口大小字段来控制，发送方的发送窗口不可以大于接收方发回的窗口大小。考虑一种特殊的情况，就是接收方若没有缓存足够使用，就会发送零窗口大小的报文，此时发送放将发送窗口设置为0，停止发送数据。之后接收方有足够的缓存，发送了非零窗口大小的报文，但是这个报文在中途丢失的，那么发送方的发送窗口就一直为零导致死锁。

   解决这个问题，TCP为每一个连接设置一个持续计时器（persistence timer）。只要TCP的一方收到对方的零窗口通知，就启动该计时器，周期性的发送一个零窗口探测报文段。对方就在确认这个报文的时候给出现在的窗口大小（注意：TCP规定，即使设置为零窗口，也必须接收以下几种报文段：**零窗口探测报文段、确认报文段和携带紧急数据的报文段**）。

### UDP的可靠传输

在应用层完成设计保证可靠性

应答机制

滑动窗口

拥塞控制

### TCP异常终止

（1）客户端尝试与服务器未对外提供服务的端口建立TCP连接，服务器将会直接向客户端发送reset报文。

（2）客户端和服务器的某一方在交互的过程中发生异常（如程序崩溃等），该方系统将向对端发送TCP reset报文，告之对方释放相关的TCP连接。

（3）接收端收到TCP报文，但是发现该TCP的报文，并不在其已建立的TCP连接列表内，则其直接向对端发送reset报文。

（4）在交互的双方中的某一方长期未收到来自对方的确认报文，则其在超出一定的重传次数或时间后，会主动向对端发送reset报文释放该TCP连接。

（5）有些应用开发者在设计应用系统时，会利用reset报文快速释放已经完成数据交互的TCP连接，以提高业务交互的效率。

# 项目相关

## 荣耀笔试

第一题：青蛙跳台阶变种。可以跳一阶、两阶，只可以回退一次。求n台台阶所有可能的跳法




这时候如果在第i个台阶退一步，那么可能的方法数是dp(i)*dp(n-i+1)，其中dp(i)表示从原点到台阶i的方法数，dp(n-i+1)表示从第i-1个台阶跳到终点的方法数（此时相当于把第i-1个台阶当做原点，向上跳n-i+1个台阶）。
累加每一个可能的i，最后再算上不退的情况，就得到最后的结果了。

![image-20220419165638790](F:\Pictures\Typora\image-20220419165638790.png)

第二题：寻找一个组成一个偶数最近的两个素数

![image-20220419165755534](F:\Pictures\Typora\image-20220419165755534.png)

第三题

![image-20220419161604936](C:\Users\pinus\AppData\Roaming\Typora\typora-user-images\image-20220419161604936.png)

```java
public class 荣耀_超级左旋 {
    static int[] c;
    static  int[]num;

    public static void main(String[] args) {
        Scanner sc=new Scanner(System.in);
        int t= sc.nextInt();
        while(t>0){
            int n=sc.nextInt();
            int max=Integer.MIN_VALUE;
            c=new int[100050];
            num=new int[100050];
            int sum=0;
            int x;
            for(int i=0;i<n;i++){
                x=sc.nextInt();
                int t1=getSum(x-1);
                int t3=getSum(100004);
                t3-=num[x];
                int t2=t3-t1;
                sum+=(t1-t2);
                max=Math.max(max,sum);
                num[x]++;
                update(x,1,100004);
            }
            System.out.println(max+" "+sum);

            t--;
        }
    }
    private static int getSum(int p){
        if(p==0){
            return 0;
        }
        int res=0;
        while(p>0){
            res+=c[p];
            p-=lowbit(p);
        }
        return res;
    }
    private static void update(int x,int y,int n){
        for(int i=x;i<=n;i+=lowbit(i)){
            c[i]+=y;
        }
    }
    //x&(-x) 保留二进制下最后出现的1的位置，其余位置置0（即一个数中最大的2的n次幂的因数
    //x&(x-1)：消除二进制下最后出现1的位置，其余保持不变
    private static int lowbit(int x){
        return x&(-x);
    }
}
```



## 安卓

八大基本数据类型 ： short 短整型 、 int 整型 、 long 长整型 、 float 浮点型 、 char 字符型 、 boolean 布尔型 、 byte 字节型 

直接算个公共子字符串长度，然后结果就是给的两个字符串长度之和-2*最长公共子串长度

```java
    class Solution {
    public int minDistance(String word1, String word2) {
        int n = word1.length();
        int m = word2.length();
// 有一个字符串为空串
    if (n * m == 0) {
        return n + m;
    }

    // DP 数组 d[i][j] 表示 A 的前 i 个字母和 B 的前 j 个字母之间的编辑距离
    int[][] D = new int[n + 1][m + 1];

    // 边界状态初始化
    for (int i = 0; i < n + 1; i++) {
        D[i][0] = i;
    }
    for (int j = 0; j < m + 1; j++) {
        D[0][j] = j;
    }

    // 计算所有 DP 值
    for (int i = 1; i < n + 1; i++) {
        for (int j = 1; j < m + 1; j++) {
           if(word.charAt(i)==word.charAt(j)){
               
           }else{
               dp[i][j]=Math.min(dp[i-1][j-1]+2, Math.min(dp[i-1][j], dp[i][j-1])+1);
           }
        }
    }
    return D[n][m];
}}
```




## nDPI

### 工作流程

- 首先是从网络上抓包，不同系统下数据包的格式可能不尽相同，在Linux下数据格式为sk_buff；
- 抓取到数据包后，搜集其layer3、layer4这两层的报头信息；
- 查看链接跟踪（如果是之前已经标示过的流，我们可以直接获取其数据包所属的协议类型，更新协议包的数量）；
- 如果从链接跟踪中没有获取到流的协议类型，表示之前未标示，即这是第一次检测到该类型的数据包，下面进入ndpi的深度报文检测过程；
- 首先是对数据包进行协议猜测，调用相应的协议分析器进行分析，成功后可返回其协议类型；
- 猜测协议错误、此时ndpi将会分类遍历所有相关的协议分析器进行分析，直至分析出结果或者遍历完所有协议分析器停止；
- 将分析出的协议类型标记到链接跟踪中，这样便于之后直接从连接跟踪的数据包中获取其协议类型。

### 具体的识别流程

获取到每一个包的信息，得到其报文信息。一层 一层的拆包直到传输层，得到相应的信息。然后到应用层以后，先依靠传统的端口检测方法，比如说如果是8080端口的话，先猜测是http协议，那么它就会到http协议的协议注册器里面去检测，如果检测成功，则把该流标识为已识别。如果不成功，遍历所有的协议注册器，进行AC算法匹配。如果匹配成功的话，它不会立即停止，而是接着往下匹配。这样做的原因是因为http使用的是tcp协议，TLS使用的也是tcp协议，当匹配到tcp的时候，无法得知具体的是哪一个、所以还会接着往上匹配。找到优先级最大的那一个。匹配完成后，它会将该协议

## 秒杀系统

![image-20220302191811084](F:\Pictures\Typora\image-20220302191811084.png)

首先用户登录界面：前端通过md5+salt加密的方式将用户信息传递到服务器，服务器收到该信息后先会对用户id做参数校验。这部分是通过自定义注解来实现的。该注解使用constraint注解和自定义参数校验器；校验完成以后会从数据库中读取该用户信息并将读取到的信息进行比对，如果正确则跳转到商品详情页。如果错误抛出异常，该异常我用controlleradvice注解和exception注解来处理的。根据抛出的异常状态码，向前端展示不同的提示。进入商品详情页后，就是秒杀阶段了。在秒杀开始前，在前端页面会将相应的按钮置灰，而服务器在一开始启动的时候，通过bean的声明周期，实现了InitialingBean接口，重写它的afterPropertiesset方法，将数据库里面的商品信息和库存，秒杀的开始时间、秒杀的结束时间都写入redis，通过redis做一个预减库存的操作。到了正式开始秒杀的阶，需要解决的主要有两个问题，一个问题是商品的超卖，一个是用户的超买。第一个问题的解决办法是首先在数据库减库存时会做一个条件判断；在redis层面我是采用decr这个原子性操作，保证预减库存的一个正确性。如果返回的是个负数，说明库存没有了，就直接抛出异常。当返回的是一个正数的话，就执行秒杀的操作。这部分我是采用rabbitmq来进行异步下单，目的是削峰。再然后就是用户超买的问题，首先在数据库层面生成订单时通过加唯一索引，然后用户下单后也会将用户信息写入redis；

除此之外，针对限流问题，一个是解决整体的限流，我是通过令牌桶算法，用的是google一个开源库，@ratelimit注解，选择一秒丢进去1000个令牌。

用户的限流的话，我是通过注解+AOP实现的，用户登录的次数写入redis，并设置key的过期时间。如果在10秒类超过了5次请求，则拒绝。

关于实际优化方向，我做了以下工作：通过redis缓存页面，比如说在商品详情页；此外，隐藏秒杀地址，用户在点击秒杀的时候，使用的接口并不是实际的秒杀接口，首先会判断秒杀时间是否开始，开始了才会将真实的地址返回给他，再由浏览器进行跳转；还有就是用户在秒杀成功后，并不会立即获得返回结构，而是获得一个秒杀中得页面，并且通过ajax不停得轮询接口，当消费者处理完消息将其写入到redis中，才会通知其秒杀成功。另外，关于消息处理失败和超时未支付的情形。我设置了一个延迟队列，当用户在一定时间内未支付，就会取消订单。如果消息处理失败，就会向前端返回秒杀失败，并将库存加1。

另外，就是关于jmeter压测。这部分做的不是很多，主要是。。

主要是模拟电商的秒杀活动。实现的功能主要有登录，参数解析，自定义参数校验注解、异常处理，限流、秒杀

技术亮点：

### 测试过程

线程组：1个。线程数1000，循环次数10次

Http请求的默认值：

![image-20220425171920912](F:\Pictures\Typora\image-20220425171920912.png)

CSV数据文件设置：

![image-20220425172012801](F:\Pictures\Typora\image-20220425172012801.png)

http cookie 管理器

![image-20220425172108507](C:\Users\pinus\AppData\Roaming\Typora\typora-user-images\image-20220425172108507.png)

Http请求

![image-20220425172232119](F:\Pictures\Typora\image-20220425172232119.png)

聚合报告

### 数据库

秒杀商品表：

![image-20220428100030378](F:\Pictures\Typora\image-20220428100030378.png)

商品名称

订单表：![image-20220428100128955](F:\Pictures\Typora\image-20220428100128955.png)

用户：![image-20220428095951250](F:\Pictures\Typora\image-20220428095951250.png)

- 自定义参数处理器、

```
将前端传过来的参数转换为user对象，并存储在redis中，解决分布式session问题
继承webmvcconfigure，在里面重写addArgumentREsolver方法，添加处理器
处理器实现HandlerMEthodArgumentResolver接口，通过supportParameter()方法判断，然后执行resolveArgument()方法
```

- 校验器，

```
校验器：除了Springboot自带的注解，自定义了一个注解，该注解用了@Constraint注解，并传入一个参数校验器，该参数校验器实现了ContraintValidator接口
```

- 预处理秒杀商品，提前查询数据库中的商品信息，并将其存储在redis中（热点数据，减少秒杀过程的I/O操作），

```
在秒杀controller中，实现InitilizingBean，重写afterPropertiesSet方法，从redis中写入数据库的秒杀商品订单
```

- 解决超卖问题

```
数据库方面：加一个条件判断
并发问题：首先通过内存标记获取到redis中商品库存，如果为false则表明还有，可以进行预减库存。如果没有，则返回错误，再用异常处理器进行跳转。
如果有，通过jedis.incr来减库存，返回的是剩余库存。进行库存判断

```

- 关于限购问题

```
数据库方面，加唯一性索引，索引为用户id
redis方面；当用户下单成功后，会在redis中保存一个记录。
```

- 自定义全局异常处理，通过自定义异常类，异常处理器handler，

```
通过@ControllerAdvice和@ExceptionHandler注解实现
@ControllerAdvice捕获全局异常
@ExceptionHandler 捕获具体的异常类型
```

- 使用页面缓存

```
页面缓存技术：用redis作页面缓存，减少thymeleaf的渲染时间
thymeleafViewResolver.getTemplateEngine().process("goods_list",ctx)）
```

- 对象缓存

```
在用户第一次登录的时候，并随机返回一个token保存到cookie中，将tokeb、user写入redis中。
当用户在修改密码的时候，先更新数据库，随后立即删除redis中的数据。
```

- 前后端分离技术

```
增加服务器的响应速度，提高吞吐量
前端静态资源写死，后端只传输动态数据
```

- 客户端轮询


```
将用户id等信息保存在redis的list中，客户端进行轮询新的地址，写入数据库，返回成功页如果失败，继续轮询
客服端轮询操作，前端通过定时器和ajax轮询客户端。加使用zset数据结构，使用到期时间戳作为score，value为用户id，然后
避免无限轮询：在轮询的时候，依旧通过redis读取时间。
```

- 隐藏秒杀地址

将秒杀url动态化，在进行秒杀之前，先请求一个服务端地址，/getmiaoshaPath 这个地址，用来获取秒杀地址，传参为 商品id，在服务端生成随机数（MD5）作为pathId存入缓存，（缓存过期时间60s），然后将这个随机数返回给前端.

2.获得该pathid,后 前端在用这个pathid拼接在Url上作为参数，去请求domiaosha服务

3.后端通过@pathVariabe注解接收到这个pathid 参数，并且与缓存中的pathid 比较。如果通过比较，进行秒杀逻辑，如果不通过，抛出业务异常，非法请求

- 限流操作：通过AOP切片，redis+lua 。设置key的过期时间。一个请求过来，得到key的值，如果超过了阈值，返回0，如果没有超过，返回1，并设置过期时间

```lua
local times =redis.call('incr',KEYS[1]) 
if(times==1) then
    redis.call('expire',KEY[1],ARGV[1]);
    end
if(times>tonumber(ARGV[2])) then
    return 0
    end

```

- 活动结束

前端：跳转到商品详情页的时候，会获取到秒杀结束时间，此时通过前端代码自动将按钮变灰

后端:在系统初始化的时候，将设置一个key，过期时间为秒杀结束时间。在执行秒杀的过程中，首先判断秒杀是否已经结束。



## 自我介绍

面试官您好，我叫林松。来自于河南省信阳市，现在就读于南京邮电大学，硕士研究生二年级，专业是电子信息。我想要应聘的岗位是java后台开发工程师。之所以想要应聘这个岗位，是因为我对于编程开发比较有兴趣，通过编写程序，在系统上实现各种各样的功能，会让自己很有成就感。

上学期间，我主要使用的编程语言是Java，并且自学了JVM的相关知识，了解Spring boot、SSM等Java常用开发框架的应用，掌握了Mysql、Redis等常用数据库的基本使用。此外，因为我的研究方向是关于嵌入式的安全研究方面，所以我还有过Linux系统，git版本控制工具的使用的经验。

关于实际项目方面，我参与了两个项目的开发。一个是基于5G MEC的工业互联网安全防护系统，这个项目是我们团队跟运营商合作的一个项目，主要是验证工业物联网体系的安全问题。另一个是我跟随网络视频教学学习的一个基于Java的电商秒杀项目。主要使用的技术有Spring boot框架和Redis。此外，在参与比赛方面，我曾分别参加了全国大学生物联网技术与应用三创大赛和中国研究生电子设计竞赛，并且获得了省三等奖和二等奖。

在日常生活中，我是一个比较乐观向上的人，面对困难，抗压能力比较强。做事也比较沉稳。

各位面试官，你们好！我叫林松，来自于河南省信阳市，现在就读于南京邮电大学，硕士研究生二年级。专业是电子信息。今天应聘得岗位是信息科技管培生岗位。之所以想要应聘这个岗位，是因为我自己对系统开发这方面比较有兴趣，研究生期间也做了很多得项目开发这方面得工作。

在研究生期间，我参加了两个项目得开发，一个是基于5GMEC的工业物联网安全防护系统，这个项目是我们团队跟运营商合作得一个项目，主要是验证工业物联网体系下安全问题。另一个项目是**面向物联网应用的新型边缘控制系统**，该系统。该项目在物联网平台中引入了分布式边缘计算的概念，利用边缘节点控制器分担云平台的计算负载，且每台边缘控制器配备多种异构网卡（5G， WAN， WIFI），使用基于 QUIC 协议的多流传输智能控制系统来为边缘控制器提供更大的接入带宽。

在校期间，我曾分别获得过校一等奖学金两次，校二等奖学金3次，国家励志奖学金一次，全国大学生物联网技术与应用大赛省三等奖和中国研究生电子设计竞赛省二等奖。除此之外，本科期间我曾获得校学生会先进个人、校园文化活动积极分子等荣誉。目前的政治面貌是一名光荣的共产党员。

在日常生活方面，我是一个比较乐观开朗得，面对困难，抗压能力比较强，做事也比较沉稳。今天很荣幸有机会参加中国银行的面试，希望可以通过自己的努力得到进去实习的机会。谢谢



体现出银行在积极调整物理网点布局，提升经营效率，以更好适应经营环境变化。一方面可以减少不必要的支出，另一方面的话也适应了现在年轻人的需求。除此之外的话，银行网点智能化转型，引入很多的智能终端设备，5G网点，可以吸引客户，提升竞争力。



## 常见问题

### 怎么看待华为和华为的文化

华为，主要是做ICT（信息与通信）基础设施和智能终端的提供商。从大的方面来讲的话，我个人感觉华为有点像我们国家的一个缩影。当前正处在一个攀高峰但是被他人打压的一个状况。我个人其实跟绝大多数一样，都希望华为能够作为一个代表，完完全全打破外国的技术垄断，实现自立自强；另外，我认为华为就是一家真正的技术驱动公司，我曾经看到一个数据，华为2015年研发费用就投入了1000多亿，在2021年研发经费全球第二，仅次于谷歌，超过了bat全年研发投入的总和；我认为华为真的是一家尊重技术的公司；而且任正非在很多场合发表关于人才培养这方面的话，对待人才是毫不吝惜，也让我感受到了华为这家公司的魄力和魅力；我个人非常希望华为能够打破外国的技术封锁，成为国家民族企业走向世界的一个标杆。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   



文化：我曾经下载过华为的心声社区，在里面浏览了很多帖子，感觉华为人都有一种拼搏无畏的精神，无论是对待工作还是生活，所以说一个优秀的企业文化，真的可以影响员工很多。作为最重要的团队精神之一，华为的“[狼性文化](https://baike.baidu.com/item/狼性文化/2816568)”可以用这样的几个词语来概括：学习，创新，获益，团结。用狼性文化来说，学习和创新代表敏锐的嗅觉，获益代表进攻精神，而团结就代表群体奋斗精神。其实现在很多年轻人都爱说躺平，我觉得躺平只是极少数，奋斗才是我们这代青年的主旋律。

### 职业规划

大方向来说的话，我目前可能更多倾向于做技术方面的工作。然后以后进入了企业的话，我的打算是先通过一到两年的时间，逐渐适应职场环境，在技术上成为能够独立完成工作，独当一面的人。在然后，对于一些机会，我也会尽力的去争取，总之，就是要通过不断的学习，来增强自己的竞争力。

### 如何看待加班和工作强度

首先就是我认为i加班是不可避免的，因为一个企业总会遇到各种紧急的情况，作为服务提供者，及时满足客户的需求是我们的责任。就工作强度来说，我个人感觉是能够承担的，因为就我读研期间来说，每天也是早上8点到夜晚10：30都是待在教研室的，周六周日进行汇报。另外，我们也能从中学习到很多，对于个人的成长非常有利。

### 怎么看待内卷和996

内卷的话，我认为更多是年轻人的一种调侃。就是无论在哪里，只要有人，就会有竞争，如果没有竞争的话，那么每个人都会选择躺平，这样可能我们的社会也不会进步；所以我觉得应该理性的看待内卷这个现象，他源于我们对于奋斗，通过双手来获取到我们想要的东西。前几天国家新出的青年白皮书，也说了，当代青年躺平只是极少数，大部分都还是懂得，幸福生活要靠自己的奋斗才能获得。

### 为什么要来华为实习？来华为实习你想要得到什么？

之所以想要来华为实习，是因为我觉得华为有着比较浓厚的技术氛围和技术沉淀，如果能够在这里实习的话，对于我个人的技术成长将会是非常大的帮助；另外，我很早以前就关注了华为，身边人谈论最多的企业也是华为，我希望有机会可以到华为看看，具体了解一下，如果适合我的话，我会把华为作为我秋招的首选目标。

### 关于荣耀

荣耀是2013年成立的。主要做的是智能终端这方面的。以前是华为的子公司，后来独立了出来。荣耀的精神，**永远不变奋斗者的精神**，**以消费者为核心，以产品为支点**，**用开放的心态拥抱一切先进技术**



### 最困难最有成就感



### 给自己定的目标。、自己已经达成的目标

目标：发表一篇好的论文，参加比赛(内向)、一年学会一项技能。比如说前年学会了玩滑板、去年我学习了弹吉他，然后今年正在学习

### 最近一年的 最近让你不开心的、委屈的事

没有什么特别委屈的事情。因为可能我这个人可能情绪波动不是很大。虽然在当时可能觉得无语，但是过后就会忘记。因为很多时候委屈也没有用。主要的困难还是来自于学校里面的科研、论文和毕业压力。但这些都不是一蹴而就的，所以还是按部就班的去做，遇到困难就尝试解决，解决不了的话就寻找周围能够帮助我的人。而且很多时候困难不是一下子就能解决的，可能在某一个不经意间，我们突然想到了一个解决之前困难的办法，所以面对困难最主要的还是会放平自己的心态，坚信只要努力，困难的解决是迟早的事

### 自己在哪方面比较优秀，学习生活中都可以 

我认为自己有个优点就是自己的情绪波动不大，抗压能力强。举个例子来说，

### DDos

SYN泛洪：通过大量的SYN请求，但是不回应，占用服务器资源

```
解决办法：减少SYN 的timeout时间，尽快释放连接
当某个IP重复多次连接的时候，拒绝访问
```

UDP泛洪：僵尸主机向服务器发送大量的UDP数据

ICMP泛洪

#### 检测方法：

1. 服务器主机上有大量等待的TCP连接；

2、检查网站后台服务器发现大量无用的数据包；*

3、一段时期中IP请求异常且源地址虚假；

4、网络流量出现异常变化突然暴涨；

5、当发现Ping超时或丢包严重时，注意连接错误。假如遇到无法访问网站这种情况，并看到类似于“无法访问站点”之类的错误，且无法访问其他Internet服务，则可能是DoS攻击带来的影响。

6、查看自己的邮箱里是否突然收到大量的垃圾邮件。



### 为什么想要从事互联网行业/进入本部门

进入互联网是因为我本身学通信的，但是对于硬件方向不是很感兴趣，所以想进入互联网行业，而且我本身对用编程语言实现功能也很感兴趣

为什么想要进阿里：应聘阿里的话，也是听说阿里的技术在互联网公司里面是顶尖的，如果能够在这里有一段实习经历的话，对自己的技术提升肯定非常大

为什么想要进网商银行：之前投递阿里的时候，也在网上找过相关信息，对于网商银行的评价比较高，所以就投了这个部门。

### 项目中遇到了什么困难？怎么协调解决的？

在我第一个项目里遇到的困难主要就是首先对于进程间通信的问题，刚开始想的是通过共享内存来完成，后来在网上找了好多资料也没有头绪，又去请教我们的指导工程师，工程师给我的建议是采用socket。后来我思考了一段时间，也就采用了这种方法。

第二个项目遇到的困难主要是在于

### 和团队里的人怎么沟通协调的，怎么分配任务的

分配任务的时候老师肯定是根据我们每个人的实际方向和能力大小分配。具体到我们每个人身上的话，比如说最开始我的方向是边缘网关这方面，当时除了我还有另外一个人做，每次导师让我们实现一个新的功能时，我都会跟另一个商量。把目标的完成分为几部，谁做那几部，然后再合并。

### 你还有什么需要问我的么

贵公司对待实习生的培养机制是什么样的？

贵部门主要是做什么的

一共几面？什么时候可以出结果？

## 高可用系统设计

### 负载均衡

常见的负载均衡系统包括 3 种：

1. **DNS 负载均衡** ：一般用来实现地理级别的均衡。
2. **硬件负载均衡** ： 通过单独的硬件设备比如 F5 来实现负载均衡功能（硬件的价格一般很贵）。
3. **软件负载均衡** ：通过负载均衡软件比如 Nginx 来实现负载均衡功能。

### 高可用

**高可用描述的是一个系统在大部分时间都是可用的，可以为我们提供服务的。高可用代表系统即使在发生硬件故障或者系统升级的时候，服务仍然是可用的。**

措施：集群、限流、降级和熔断、超时重试机制、容灾设计（主从复制）

### 高性能

负载均衡

读写分离、分库分表

### CDN

内容分发网络。部署多个静态存储服务器，当一个请求到来时，就近选择节点，而不是请求原始服务器。本质上还是用空间换时间。

# Mysql

## 常用命令

```
登录：mysql -uroot -p

授权：grant 允许操作 on 库名.表名 to 账号@来源 identified by '密码';

- SQl基本操作

查看数据库：show databases；

创建数据库：create databases xx if no exists

进入数据库：use tablename

删除数据库：drop database if exists 库名

查看所有的表：show tables；

查看表结构：desc table；show create table 表名

创建表：create table `xx`（

​	`id` comments '' ,
	

​	`name' default 10

)engine=innodb default charset=utf-8

删除表:drop table if exists xx;
将表中的数据库导出: sqldump -u root -p xx xx
将数据库导入 mysql -u root -p xx xx
```

- 增删改查

  

```
插入:insert into xx(`id`,`name`)values(2,5)
删除：delete from xx where 
更新：update xx set id= where
查找：select name from 
```

- 更改表结构

```
增加字段 alter table xx add  age INT(4)
删除字段 alter table xx drop 
修改字段 alter talbe xx change(modify) age auto_increment
添加索引 alter table xx add unique(index) ·uni_name(name)
删除索引: alter table xx drop unique uni_name
更改表名:alter talbe xx rename as xx1

```

## 存储引擎

InnoDB索引表分布



![img](F:\Pictures\Typora\webp-164724137242326.webp)



MyISAM索引表分布

![img](F:\Pictures\Typora\webp-164724137429228.webp)

InnoDB支持事务和表、行级锁和外键，MyISAM只支持表级锁

InnoDB必须要有主键，而MyISAM可以没有

InnoDB不存储行数数据，而MyISAM存储

InnnoDB采用的是聚簇索引，MyiSAM采用的是非聚簇索引

MyISAM叶节点的data域存放的是数据记录的地址。innodb叶节点存放的是数据

## 事务日志

![img](F:\Pictures\Typora\mysql日志)

![img](F:\Pictures\Typora\mysql事务日志2)

![img](F:\Pictures\Typora\日志)

### binlog 二进制文件

存储的是逻辑日志，适合做主从复制和容灾回复。

binlog有两种形式：

statement：SQL语句的形式

row：记录相关行的每一列的值（官方推荐）

### redo log

InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为***\*crash-safe\**** 

在操作完一条语句后，将最新的数据备份到redo log buffer中去。

redo log buffer并不是只在事务提交的时候刷盘，因为InnoDB有一个后台线程，每隔`1`秒，就会把`redo log buffer`中的内容写到文件系统缓存（`page cache`），然后调用`fsync`刷盘。

作用：为了事务的持久化,当执行完commit,若redo log写完了,则事务提 交成功,

### undo log

在操作一条语句之前,把需要操作的数据备份到undo log中,若查询数据就有undo log +不在undo log的数据(事务未提交之前)

### 为什么需要binlog和redo log同时存在

innodb利用WAL技术进行数据恢复，write ahead logging技术依赖于物理日志进行数据恢复，binlog不是物理日志是逻辑日志，因此无法使用

binlog还不能去掉。一个原因是，redolog只有InnoDB有，别的引擎没有。另一个原因是，redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。

### XA阶段

内部XA事务就是将事务提交分为了两个阶段，prepare阶段和commit阶段！

prepare：写入redo log，并将回滚段置为prepared状态，此时binlog不做操作。

commit：innodb释放锁，释放回滚段，设置提交状态，写入binlog，然后存储引擎层提交。

### 恢复步骤

redolog中的事务如果经历了二阶段提交中的prepare阶段，则会打上prepare标识，如果经历commit阶段，则会打上commit标识（此时redolog和binlog均已落盘）。

Step1. 按顺序扫描redo log，如果redolog中的事务既有prepare标识，又有commit标识，就直接提交（复制redolog disk中的数据页到磁盘数据页）

Step2 .如果redolog事务只有prepare标识，没有commit标识，则说明当前事务在commit阶段crash了，binlog中当前事务是否完整未可知，此时拿着redolog中当前事务的XID（redolog和binlog中事务落盘的标识），去查看binlog中是否存在此XID

 a. 如果binlog中有当前事务的XID，则提交事务（复制redolog disk中的数据页到磁盘数据页）

 b. 如果binlog中没有当前事务的XID，则回滚事务（使用undolog来删除redolog中的对应事务）

## Mysql的范式

1、第一范式(1NF)是指数据库表的每一列都是不可分割的基本数据线；也就是说：每列的值具有原子性，不可再分割。

2、第二范式(2NF)是在第一范式(1NF)的基础上建立起来得，满足第二范式(2NF)必须先满足第一范式(1NF)。如果表是单主键，那么主键以外的列必须完全依赖于主键；如果表是复合主键，那么主键以外的列必须完全依赖于主键，不能仅依赖主键的一部分。

3、第三范式(3NF)是在第二范式的基础上建立起来的，即满足第三范式必须要先满足第二范式。第三范式(3NF)要求：表中的非主键列必须和主键直接相关而不能间接相关；也就是说：非主键列之间不能相关依赖。

### 主键索引

定义为Primary Key的字段。主键不能为null

### 辅助索引

不是主键索引的其他索引成为辅助索引。

唯一索引（可以为null)、普通索引都是辅助索引

### 联合索引

联合索引对多个索引进行排序，采用B+树进行排序

![img](F:\Pictures\Typora\v2-b2506d877144b08f52f46d1f2157ce35_1440w.jpg)

### 覆盖索引

覆盖索引其实是一种特殊的联合索引，怎么理解呢，即是你查询的字段的所有数据都在索引上，不需要再进行一次回表查询，这样的索引即为覆盖索引。例如下sql即会走覆盖索引



## 聚簇索引和非聚簇索引

聚簇索引:索引的存放顺序和数据存放的顺序是相同的，即索引和数据放在同一个文件里

非聚簇索引:索引存放的顺序和数据存放的顺序不相关，即索引和数据保存在两个文件中。

innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引 

唯一索引、普通索引、前缀索引、全文索引都是辅助索引。

## 逻辑外键和物理外键

逻辑外键指的是不显示的声明外键，而是通过代码来实现两张表之间的关联。

外键同样也是一种索引，它目的是建立起来两张表之间的联系。外键可以是一对一，也可以是一对多。外键的作用是保持数据一致性、完整性，主要体现在下面两个方面

阻止执行

从表插入新行，其外键值不是主表的主键值便阻止插入；
		从表修改外键值，新值不是主表的主键值便阻止修改；
	 	主表删除行，其主键值在从表里存在便阻止删除(要想删除，必须先删除从表的相关行)；
 		主表修改主键值，旧值在从表里存在便阻止修改(要想修改，必须先删除从表的相关行)。

级联执行

主表删除行，连带从表的相关行一起删除；
 		主表修改主键值，连带从表相关行的外键值一起修改。

物理外键的缺点
		性能问题:  比如每次在从表A表中插入数据都会去主表B表查询是否有对应数据,如果不止一个外键呢?如果批量插入或更新呢?
		并发问题:  在使用外键的情况下，每次修改数据都需要去另外一个表检查数据,需要获取额外的锁。若是在高并发大流量事务场景，使用外键更容易造成死锁。



## B+树

首先B+树符合平衡二叉搜索树

B-树：

![在这里插入图片描述](F:\Pictures\Typora\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZWZlY3Rfc3RhcnQ=,size_16,color_FFFFFF,t_70.png)

![img](https://img-blog.csdnimg.cn/20210403190530975.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZWZlY3Rfc3RhcnQ=,size_16,color_FFFFFF,t_70)



1. B+ 树将 data 信息挪到了叶子节点，非叶子节点不存放 data 信息，只存储索引，这就意味着非叶子节点可以存放更多的索引，IO操作的时间复杂度低
2. B+树的查找路径是由根到叶子节点，每次查找路径长度比较稳定
3. 范围遍历，B+树的叶子节点构成一条链表，访问更加方便。支持范围查询

## 索引的优点

创建唯一性索引保证每一行数据的唯一性

加快检索的速度

使用外键可以实现数据的完整性

通过使用索引，mysql会使用查询优化器，提高系统性能

## 哪些字段适合建立索引

经常需要查询的字段

需要保障唯一性的字段

在经常需要排序，范围搜索的字段上

经常用在连接上的字段

经常作为where查询条件的字段

## 页分裂和页合并

构是 B+ 树，**所谓的索引其实就是一颗 B+ 树，一个表有多少个索引就会有多少颗 B+ 树，mysql 中的数据都是按顺序保存在 B+ 树上的**（所以说索引本身是有序的）。mysql 在底层又是以数据页为单位来存储数据的，一个数据页大小默认为 16k，当然你也可以自定义大小，也就是说如果一个数据页存满了，mysql  就会去申请一个新的数据页来存储数据，如果主键为自增 id 的话，mysql 在写满一个数据页的时候，直接申请另一个新数据页接着写就可以了。如果主键是非自增 id，为了确保索引有序，mysql 就需要将每次插入的数据都放到合适的位置上。当往一个快满或已满的数据页中插入数据时，新插入的数据会将数据页写满，mysql 就需要申请新的数据页，由于可能把上个数据页中的部分数据挪到新的数据页上。这就造成了页分裂，这个大量移动数据的过程是会严重影响插入效率的



同理,当删除某个元素时,如果要删除的聚簇索引过大,也会导致相应的页合并.

## 主键自增

 InnoDB引擎使用聚集索引，数据记录本身被存于主索引（一颗 B + Tree）的叶子节点上，这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放。因此每当有一条新的记录插入时，MySQL 会根据其[主键](https://so.csdn.net/so/search?q=主键&spm=1001.2101.3001.7020)将其插入适当的节点和位置，如果页面达到装载因子（InnoDB 默认为 15 / 16 ），**则开辟一个新的页（节点）。**

​    1、如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前[索引](https://so.csdn.net/so/search?q=索引&spm=1001.2101.3001.7020)节点的后续位置，当一页写满，就会自动开辟一个新的页。

​    这样就会形成一个紧凑的索引结构，近似顺序填满。***\*由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上\**。**

​    2、 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：**此时 MySQL 不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片**，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE 来重建表并优化填充页面。

​    在使用 InnoDB 存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。

## 事务的四大特征

原子性：主要描述事务操作时一个不可分割的单元，一次事务操作要么都成功，要么失败。通过redo log来保证

一致性：事务在操作前后数据之间的逻辑关系是否正确和完整。质量守恒定律。通过AID来保证

隔离性：多个并发的事务操作互无影响。通过隔离级别来保证

持久性：事务一旦提交不可更改。通过redo log来保证

其中AID是用来保障一致性的

## 隔离级别

脏读

```
如果A读取了B未提交的数据,但是B最后出现了回滚,就会出现脏读的情况
```

不可重复读

```
一个事务在前后两次查询同一个数据，发现数据不一致。偏向于修改
```

幻读

```
一个事务在前后两次查询同一个范围的时候、后一次查询看到了前一次查询未看到的行
```

隔离级别

- 读未提交

- 读 已提交

- 可重复读

- 可串行化

## MVCC

```
保障可重复读的机制是MVCC	多版本并发控制。它主要是通过控制数据的版本号来进行并发事务操作安全性。其具体实现采用了read view 和undo log。read view的算法原理是
维护一条活跃的事务链，活跃指的是那些正在操作，但是还没提交的事务。在该事务链中，最小的事务id为min_id，最大的事务id为max_id。当前操作的事务id为n_id
在数据库中的每一行都有都有两个或者三个隐藏字段。其中有一个数据行事务ID，表明该行最近被哪一个事务修改，还有一个是回滚指针，该指针指向的是该行数据未被修改前的一个版本。
如果数据行的事务id小于min_id,那么说明该行的数据是已经被提交了的，所以数据可见
如果该数据行的事务id大于max_id，说明操作该行的事务是在n_id之后创建的，所以数据不可见，数据根据回滚指针找到上一个版本继续判断。

如果该数据行的事务id大小在两个中间，主要看其是否在该事务链中，如果在，说明数据不可见，因为还没有提交
如果不再，说明该事务已经提交了，数据可见。

具体实现RC 和RP的read_view还不同
实现RC是在每次事务开启的时候关闭旧的read_view，创建一个当前新的事务链
实现RP则是从事务开启的时候就一直开启read view 
```

### 快照读和当前读

当前读, 读取的是最新版本, 并且对读取的记录加锁, 阻塞其他事务同时改动相同记录，避免出现安全问题。实现的方式是next-key锁(行记录锁+Gap间隙锁)

select ... lock in share mode 、

select ... for update、

update 、delete 、insert

快照读：读取的是记录数据的可见版本（可能是过期的数据），不用加锁。主要靠MVCC来实现。

### Read View

当事务进行快照读时产生的读视图。主要是来做可见性判断的

### MVCC实现RC和RR

MVCC只工作在RC和RR两种隔离级别下，在RR隔离级别下，通过间隙锁+MVCC可以解决幻读的问题。

RR：不允许出现幻读、不可重复读、脏读等。重复读在第一次读取数据的时候才会生成ReadView，之后每次读取都会按照快照读来。

RC：不允许出现脏读。每次读取数据时，都会生成一个新的ReadView。

## in 和exist的区别

结论：当B表小的时候，用in。当B表大的时候，用exist

in一次性查询出子表中的数据，并缓存出来，最后将于主表中的数据对比

exist 会先查询主表中的结果，在根据主表的查询结果于B表一一匹配

## 锁

死锁的定义：两个或两个以上的事务想要获取对方的锁而产生死循环状态。

解决办法：等待，超时后自动释放锁  innodb_lock_wait_timeout 默认值50s

​				发起死锁检测，主动让一条事务回滚，其他事务得以执行。innodb_deadlock_detect = on

**InnoDB 存储引擎的锁的算法有三种：**

- Record lock：记录锁，单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- Next-key lock：record+gap 临键锁，锁定一个范围，包含记录本身

InnoDB存储引擎实现了如下两种标准的行级锁：

- 共享锁（S Lock），又称读锁。允许多个事务读一行数据。不允许写
- 排他锁（X Lock），又称写锁。允许单个事务删除或更新一行数据。不允许其他事务读或者写。

表级锁和行级锁的：

- 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁。
- 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁。

具体算法

间隙锁用于锁定一个范围，但不包含记录本身。它的作用是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生。InnoDB自动使用间隙锁条件：

- 在RR隔离级别下
- 检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加）

## 两阶段锁协议和两阶段提交协议

2PL：适用于单机模式。一个事务获得锁后，即使不做任何操作，它也不会释放锁，释放锁只在事务提交或者回滚后

2PC：适用于分布式锁。分为两个阶段，第一阶段表决阶段。协调者通知事务参与者准备回滚或提交事务，然后进入表决。参与者告诉协调者同意或者取消

进入提交第二阶段，协调者根据第一阶段的表决结果，当且仅当所有的参与者同意提交的时候，才进行提交；否则就进行取消回滚。

## 为什么MVCC+间隙锁可以解决幻读

在RR和RC级别下，数据库的读分为快照读和当前读:

- 快照读：单纯的select操作。读取的是快照（ReadView）中的数据，可能是历史数据
- 当前读：select ... for update/in share mode、update、insert、delete。读取的总是当前的最新数据

RR模式下幻读的问题我觉得要分快照读和当前读两种情况来讨论：


对于快照读，RR中一个事务的所有快照读读取的都是同一份快照，所以无论其他的事务怎么修改，无论是更新还是插入删除，都不会影响当前事务的快照读结果，也就不会出现不可重复读、幻读的情形。


对于当前读，你读取的行，以及行的间隙都会被加锁，直到事务提交时才会释放，其他的事务无法进行修改，所以也不会出现不可重复读、幻读的情形。
所以如果你总是进行快照读，或者总是进行当前读，是不会出现幻读的情况的。

## 优化

### 索引优化

索引可以提高查询的速度，但并不是使用带有索引的字段查询时索引都会起作用。有几种特殊情况，在这些情况下有可能使用带有索引的字段查询时索引并没有起作用。

1. 使用LIKE关键字的查询语句

   在使用LIKE关键字进行查询的查询语句中，如果匹配字符串的第一个字符为“%”，索引不会起作用。只有“%”不在第一个位置，索引才会起作用。

3. 使用OR关键字的查询语句

   查询语句的查询条件中只有OR关键字，且OR前后的两个条件中的列都是索引时，查询中才使用索引。否则，查询将不使用索引。
   
3. 根据索引查询时不符合最左匹配原则

4. 对索引所在的列进行计算或者内置函数

### 子查询优化

使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。

子查询虽然可以使查询语句很灵活，但执行效率不高。执行子查询时，MySQL需要为内层查询语句的查询结果建立一个临时表。然后外层查询语句从临时表中查询记录。查询完毕后，再撤销这些临时表。因此，子查询的速度会受到一定的影响。如果查询的数据量比较大，这种影响就会随之增大。

在MySQL中，可以使用连接（JOIN）查询来替代子查询。连接查询不需要建立临时表，其速度比子查询要快，如果查询中使用索引，性能会更好。

### 插入优化

1. 禁用索引

   对于非空表，插入记录时，MySQL会根据表的索引对插入的记录建立索引。如果插入大量数据，建立索引会降低插入记录的速度。为了解决这种情况，可以在插入记录之前禁用索引，数据插入完毕后再开启索引。对于空表批量导入数据，则不需要进行此操作，因为MyISAM引擎的表是在导入数据之后才建立索引的。

2. 禁用唯一性检查

   插入数据时，MySQL会对插入的记录进行唯一性校验。这种唯一性校验也会降低插入记录的速度。为了降低这种情况对查询速度的影响，可以在插入记录之前禁用唯一性检查，等到记录插入完毕后再开启。

3. 使用批量插入

   插入多条记录时，可以使用一条INSERT语句插入一条记录，也可以使用一条INSERT语句插入多条记录。使用一条INSERT语句插入多条记录的情形如下，而这种方式的插入速度更快。

### 慢查询优化

首先在配置文件中和mysql中开启慢查询优化，指定慢查询得时间

利用explain关键字来模拟优化器执行sql语句

### 表结构优化

选择合适的存储引擎

字段选择合适的数据类型

数据类型的大小要尽可能的小

索引尽量不要为null

### 总体优化

分库分表

读写分离

# Linux

## VIM相关

选择文本、删除、复制、粘贴

```
v    从光标当前位置开始，光标所经过的地方会被选中，再按一下v结束。 

V    从光标当前行开始，光标经过的行都会被选中，再按一下Ｖ结束。 

Ctrl + v   从光标当前位置开始，选中光标起点和终点所构成的矩形区域，再按一下Ｃtrl + v结束。 

ggVG 选中全部的文本， 其中gg为跳到行首，V选中整行，G末尾
选中以后，可以进行操作

d   删除 

y   复制 （默认是复制到"寄存器） 

p  粘贴 （默认从"寄存器取出内容粘贴） 

"+y    复制到系统剪贴板(也就是vim的+寄存器） 

"+p   从系统剪贴板粘贴 

删除
删除光标选中的字符 ：x
删除光标所在行：dd

撤销：u撤销上一次操作
撤销对上一行的全部操作:U
撤销的撤销：crtl+r

追加
i 在当前光标之前插入文本
a 在当前光标之后插入文本
o 向下另起一行插入文本
O 向上另起一行插入文本

移动
9k 上光标上移动9行
33G 将光标移到33行 没有数字则移到最后一行

```

```
head - n 10 filename:查看前10行

tail - n 10 filename：查看后十行


grep -A100 -B100 "XX" filename 在filename中查找xx的前后100行
grep -n  "xxx" finaname 查找指定字符出现的行
grep -c 查找匹配到的次数
grep -r		 path 搜索子目录
grep -l 	输出匹配文件名

cat
	filename 查看文件
	-n 带编号的文件内容,包括空行
	-b 不包括空行
	
more
  file 查看文件内容
  -n filename 一次显示n行
  +n fileaname 从第n行开始显示

tail 
	-f -n 10 filename 实时显示最后10行
  	-r -n 10 filename  逆序显示最后十行
  	
find 
	path -name "*.c" -type f -size n -atime n -amin -ctime -cmin
查看符合条件的文件

sed -i “s/oldString/newString/g" grep oldString -rl path; 批量替换内容
d：表示删除行。
p：打印该行。
r：读取指定文件的内容。
w：写入指定文件。
a：在下面插入新行新内容。
```



## 网络命令

### ifconfig

```
用来查看配置当前主机的网卡和ip信息
当网卡重启后，配置就不存在了
如果要永久性修改，需要网卡配置文件
```

### telnet

```
远程登录  或者确定远程服务器的某个端口是否可以访问
采用明文传输，安全性不高
telnet ip port
```

ssh

```
ssh -p port localhost@ip
```

### netstat

```
显示网络连接、路由表、接口状态等
a 显示所有，默认不显示listen相关
n 显示ip地址，而不是域名服务器
p 显示建立相关链接的程序名
-r 显示路由表
-l 仅显示listen状态的信息
```

### traceroute

```
表示数据从本机出发到服务器的路径

```

### route

```
显示并设置linux内核中的网络路由表
```

### host

```
域名查询服务
```

### iptables

```
设置防火墙过滤规则
```

### ps -aux|grep 端口

```
查看系统进程
```

### systemctl restart network

```
重启网络服务
```

网卡的配置文件

/etc/sysconfig/network-scripts/

apt的配置文件

/etc/apt/apt.conf

## 其他命令

### free

![「干货」linux free 命令输出中 buffer 与 cache 的区别，有这篇就够了](F:\Pictures\Typora\0d26dde9abec6bfe6bb89f7954343921.png)

“buffers” 表示块设备(block device)所占用的缓存页，包括：直接读写块设备、以及文件系统元数(metadata)比如SuperBlock所使用的缓存页；

“cached” 表示普通文件数据所占用的缓存页。

shared表示进程共享内存的大小

avaliable：`available`列为可用内存

swap:`Swap`行是虚拟内存作用情况

total=used+free

-buffers/cache 的内存数：82956(等于第1行的 used - buffers - cached)

+buffers/cache 的内存数: 432784 (等于第1行的 free + buffers + cached)

### df

-h 以合适的格式显示磁盘大小

### du

-sh：显示某个文件或者文件夹大小，以合适的格式显出

### mount

挂载移动设备

## Git

git clone 

```
# 默认在当前目录下创建和版本库名相同的文件夹并下载版本到该文件夹下
$ git clone <远程仓库的网址>

# 指定本地仓库的目录
$ git clone <远程仓库的网址> <本地目录>

# -b 指定要克隆的分支，默认是master分支
$ git clone <远程仓库的网址> -b <分支名称> <本地目录>
```

git init

```
初始化项目所在目录，初始化后会在当前目录下出现一个名为 .git 的目录
```

git status

```
$ git status

# 以简短模式查看本地仓库的状态
# 会显示两列，第一列是文件的状态，第二列是对应的文件
# 文件状态：A 新增，M 修改，D 删除，?? 未添加到Git中
$ git status -s
```

git remote

```
# 列出已经存在的远程仓库
$ git remote

# 列出远程仓库的详细信息，在别名后面列出URL地址
$ git remote -v
$ git remote --verbose

# 添加远程仓库
$ git remote add <远程仓库的别名> <远程仓库的URL地址>

# 修改远程仓库的别名
$ git remote rename <原远程仓库的别名> <新的别名>

# 删除指定名称的远程仓库
$ git remote remove <远程仓库的别名>

# 修改远程仓库的 URL 地址
$ git remote set-url <远程仓库的别名> <新的远程仓库URL地址>

```

git  branch

```
# 列出本地的所有分支，当前所在分支以 "*" 标出
$ git branch

# 列出本地的所有分支并显示最后一次提交，当前所在分支以 "*" 标出
$ git branch -v

# 创建新分支，新的分支基于上一次提交建立
$ git branch <分支名>

# 修改分支名称
# 如果不指定原分支名称则为当前所在分支
$ git branch -m [<原分支名称>] <新的分支名称>
# 强制修改分支名称
$ git branch -M [<原分支名称>] <新的分支名称>

# 删除指定的本地分支
$ git branch -d <分支名称>

# 强制删除指定的本地分支
$ git branch -D <分支名称>

```

git checkout

```
# 切换到已存在的指定分支
$ git checkout <分支名称>

# 创建并切换到指定的分支，保留所有的提交记录
# 等同于 "git branch" 和 "git checkout" 两个命令合并
$ git checkout -b <分支名称>

# 创建并切换到指定的分支，删除所有的提交记录
$ git checkout --orphan <分支名称>

# 替换掉本地的改动，新增的文件和已经添加到暂存区的内容不受影响
$ git checkout <文件路径>

```

git cherry-pick

```
# 把已经提交的记录合并到当前分支
$ git cherry-pick <commit ID>
```

git add

```
# 把指定的文件添加到暂存区中
$ git add <文件路径>

# 添加所有修改、已删除的文件到暂存区中
$ git add -u [<文件路径>]
$ git add --update [<文件路径>]

# 添加所有修改、已删除、新增的文件到暂存区中，省略 <文件路径> 即为当前目录
$ git add -A [<文件路径>]
$ git add --all [<文件路径>]

# 查看所有修改、已删除但没有提交的文件，进入一个子命令系统
$ git add -i [<文件路径>]
$ git add --interactive [<文件路径>]

```

git commit

```
# 把暂存区中的文件提交到本地仓库，调用文本编辑器输入该次提交的描述信息
$ git commit

# 把暂存区中的文件提交到本地仓库中并添加描述信息
$ git commit -m "<提交的描述信息>"

# 把所有修改、已删除的文件提交到本地仓库中
# 不包括未被版本库跟踪的文件，等同于先调用了 "git add -u"
$ git commit -a -m "<提交的描述信息>"

# 修改上次提交的描述信息
$ git commit --amend
```

git fetch

```
# 将远程仓库所有分支的最新版本全部取回到本地
$ git fetch <远程仓库的别名>

# 将远程仓库指定分支的最新版本取回到本地
$ git fetch <远程主机名> <分支名>

```

git merge

```
# 把指定的分支合并到当前所在的分支下
$ git merge <分支名称>

```

git diff

```
# 比较当前文件和暂存区中文件的差异，显示没有暂存起来的更改
$ git diff

# 比较暂存区中的文件和上次提交时的差异
$ git diff --cached
$ git diff --staged

# 比较当前文件和上次提交时的差异
$ git diff HEAD

# 查看从指定的版本之后改动的内容
$ git diff <commit ID>

# 比较两个分支之间的差异
$ git diff <分支名称> <分支名称>

# 查看两个分支分开后各自的改动内容
$ git diff <分支名称>...<分支名称>
```

git push

```
# 从远程仓库获取最新版本。
$ git pull
从远程仓库获取最新版本并合并到本地。 git fetch+git merge
```

git push

```
# 把本地仓库的分支推送到远程仓库的指定分支
$ git push <远程仓库的别名> <本地分支名>:<远程分支名>

# 删除指定的远程仓库的分支
$ git push <远程仓库的别名> :<远程分支名>
$ git push <远程仓库的别名> --delete <远程分支名>

```

git reset

```
# 重置暂存区，但文件不受影响
# 相当于将用 "git add" 命令更新到暂存区的内容撤出暂存区，可以指定文件
# 没有指定 commit ID 则默认为当前 HEAD
$ git reset [<文件路径>]
$ git reset --mixed [<文件路径>]

# 将 HEAD 的指向改变，撤销到指定的提交记录，文件未修改
$ git reset <commit ID>
$ git reset --mixed <commit ID>

# 将 HEAD 的指向改变，撤销到指定的提交记录，文件未修改
# 相当于调用 "git reset --mixed" 命令后又做了一次 "git add"
$ git reset --soft <commit ID>

# 将 HEAD 的指向改变，撤销到指定的提交记录，文件也修改了
$ git reset --hard <commit ID>

```

git revert

```
撤销某一次提交，该次提交后面还有提交，但是想保留后一次提交
```

git rm

```
# 移除跟踪指定的文件，并从本地仓库的文件夹中删除
$ git rm <文件路径>

# 移除跟踪指定的文件夹，并从本地仓库的文件夹中删除
$ git rm -r <文件夹路径>

# 移除跟踪指定的文件，在本地仓库的文件夹中保留该文件
$ git rm --cached

```

git mv

```
# 重命名指定的文件或者文件夹
$ git mv <源文件/文件夹> <目标文件/文件夹>

```



# Web开发

## Springboot

![img](F:\Pictures\Typora\v2-912d9181496a25f578a970615189c378_1440w.jpg)

### springboot和spring的区别

springboot本身就是基于spring的。Spring Boot 简化了 Spring 应用的搭建和开发过程。Spring Boot 去除了大量的 XML 配置文件，简化了复杂的依赖管理。

#### Springboot的四大组件

starter， autoconfigure, CLI 以及actuator

#### Springboot的配置原理

- 提供了固定的配置来简化配置，即`约定大于配置`
- 尽可能地自动配置 Spring 和第三方库，即能`自动装配`
- 内嵌容器，创建独立的 Spring 应用
- 让测试变的简单，内置了JUnit、Spring Boot Test等多种测试框架，方便测试
- 提供可用于生产的特性，如度量、运行状况检查和外部化配置。
- 完全不需要生成代码，也不需要 XML 配置。

### 注解

@SpringbootApplication主要包含三个注解，@Springbootconfiguration，@ComponentScan，@EnableAutoConfiguration

```java
@Springbootconfiguration  //表明这是springboot的配置类，可以向容器中注入组件
```

```java
@ComponentScan //配置用于configuration类的组件扫描指令 默认路径是springbootApplication类所在包及其子目录
```

```java
@EnableAutoConfiguration //借助@Import注解，将符合自动配置条件的bean加载到IOC容器
```

![image-20220331090027272](F:\Pictures\Typora\image-20220331090027272.png)

```java
@AutoConfigurationPackage   //其内部有一个@Import注解，利用registrar.class类中的registerBeanDefinitions方法，注册当前启动类所在的package
```

![image-20220331090750505](F:\Pictures\Typora\image-20220331090750505.png)

```java
@Import({AutoConfigurationImportSelector.class})
getCandidteConfigurations() //寻找所有的候选配置类
SpringFactoriesLoader.class   //负责导入META-INF/spring.factories文件  
LoadSpringFactories //从META/Spring.factories中加载给定类型的完全限定类名放到map中
loadFactoryName  //根据springboot的启动，当需要加载配置类时，就会传入org.springframework.boot.autoconfigure.EnableAutoConfiguration参数，从map中查找key为该参数的值，通过反射加入容器当中区。
```

run方法

首先实例化SpringApplication类

```
设置监视器 Listener
推断应用类型是否是web环境
设置初始化器Inititalizer
推断应用入口类  构建一个运行时异常，通过异常栈中的方法名为main的栈帧来得到入口类的名字

```

执行run方法

```
获取SpringApplcationRunisteners
准备Environment  
创建上下文 ConfigurableApplicationContext
刷新 上下文

```

![img](F:\Pictures\Typora\1158841-20190716164535793-477823131.png)

### Springboot自动装配原理



### 修改Springboot的启动图标和启动页面

将图标的ASCII码保存为txt文件，命名为banner。放在resource目录下

Springboot的首页会默认在static中查找index.html，其次到template中查找。

如果想要自定义首页，通过在webmvcConfigure中重写addviewControllers方法，

通过控制跳转来实现。默认跳转到template目录下，如果要跳转到static下，就要使用forward：来实现

### 占位符${}和#{}的区别

#会对传入的参数进行预编译处理，不会引起sql注入的问题。

### Springboot的启动流程

![img](F:\Pictures\Typora\format,png)

首先是SpringbootApplcaiton的注解，该注解主要的作用有

- SpringBootConfiguration  标注当前类是配置类，加载到IOC容器内

- @ComponentScan  扫描contoller等组件，加载到IOC容器

- EnableAutoConfiguration  ，借助@import注解将符合自动配置条件的bean加入IOC容器

其次是SpringApplicaiton.run方法：

- 首先实例化一个springApplication对象。并执行run方法
- 在实例化的过程中，主要做了几件事

```
推断当前应用的类型
搜索META-INF\spring.factories文件配置的ApplicationContextInitializer的实现类并加载
搜索META-INF\spring.factories文件配置的ApplicationListenerr的实现类并加载
推断MainApplication的Class
```

- 在run之后，做了几件事情

```
首先遍历执行所有通过SpringFactoriesLoader可以查找到并加载的SpringApplicationRunListener
创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。
创建applicationContext
借助上面的ApplicationContextInitializer刷新上下文
将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext
```

### Springboot的注解

@SpringBootApplication：申明让spring boot自动给程序进行必要的配置，这个配置等同于：

@Configuration ，@EnableAutoConfiguration 和 @ComponentScan 三个配置。

@ResponseBody：表示该方法的返回结果直接写入HTTP response body中，一般在异步获取数据时使用，用于构建RESTful的api。

@Controller：用于定义控制器类，在spring项目中由控制器负责将用户发来的URL请求转发到对应的服务接口（service层），一般这个注解在类中，通常方法需要配合注解@RequestMapping。

@RestController：用于标注控制层组件(如struts中的action)，@ResponseBody和@Controller的合集。



### springboot开启日志记录

日志级别从低到高分为:

```
	TRACE < DEBUG < INFO < WARN < ERROR < FATAL 。
```

如果设置为warn，则低于warn的都不会输出。

引入依赖，排除logback默认配置

```
<dependency>  
    <groupId>org.springframework.boot</groupId>  
    <artifactId>spring-boot-starter-web</artifactId>  
    <exclusions><!-- 去掉springboot默认配置 -->  
        <exclusion>  
            <groupId>org.springframework.boot</groupId>  
            <artifactId>spring-boot-starter-logging</artifactId>  
        </exclusion>  
    </exclusions>  
</dependency> 

<dependency> <!-- 引入log4j2依赖 -->  
    <groupId>org.springframework.boot</groupId>  
    <artifactId>spring-boot-starter-log4j2</artifactId>  
</dependency> 
```

配置log4j2.xml文件

```
<?xml version="1.0" encoding="UTF-8"?>
<!--Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时，你会看到log4j2内部各种详细输出-->
<!--monitorInterval：Log4j能够自动检测修改配置 文件和重新配置本身，设置间隔秒数-->
<configuration monitorInterval="5">
  <!--日志级别以及优先级排序: OFF > FATAL > ERROR > WARN > INFO > DEBUG > TRACE > ALL -->

  <!--变量配置-->
  <Properties>
    <!-- 格式化输出：%date表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %msg：日志消息，%n是换行符-->
    <!-- %logger{36} 表示 Logger 名字最长36个字符 -->
    <property name="LOG_PATTERN" value="%date{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n" />
    <!-- 定义日志存储的路径 -->
    <property name="FILE_PATH" value="更换为你的日志路径" />
    <property name="FILE_NAME" value="更换为你的项目名" />
  </Properties>

  <appenders>

    <console name="Console" target="SYSTEM_OUT">
      <!--输出日志的格式-->
      <PatternLayout pattern="${LOG_PATTERN}"/>
      <!--控制台只输出level及其以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
      <ThresholdFilter level="info" onMatch="ACCEPT" onMismatch="DENY"/>
    </console>

    <!--文件会打印出所有信息，这个log每次运行程序会自动清空，由append属性决定，适合临时测试用-->
    <File name="Filelog" fileName="${FILE_PATH}/test.log" append="false">
      <PatternLayout pattern="${LOG_PATTERN}"/>
    </File>

    <!-- 这个会打印出所有的info及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档-->
    <RollingFile name="RollingFileInfo" fileName="${FILE_PATH}/info.log" filePattern="${FILE_PATH}/${FILE_NAME}-INFO-%d{yyyy-MM-dd}_%i.log.gz">
      <!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
      <ThresholdFilter level="info" onMatch="ACCEPT" onMismatch="DENY"/>
      <PatternLayout pattern="${LOG_PATTERN}"/>
      <Policies>
        <!--interval属性用来指定多久滚动一次，默认是1 hour-->
        <TimeBasedTriggeringPolicy interval="1"/>
        <SizeBasedTriggeringPolicy size="10MB"/>
      </Policies>
      <!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖-->
      <DefaultRolloverStrategy max="15"/>
    </RollingFile>

    <!-- 这个会打印出所有的warn及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档-->
    <RollingFile name="RollingFileWarn" fileName="${FILE_PATH}/warn.log" filePattern="${FILE_PATH}/${FILE_NAME}-WARN-%d{yyyy-MM-dd}_%i.log.gz">
      <!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
      <ThresholdFilter level="warn" onMatch="ACCEPT" onMismatch="DENY"/>
      <PatternLayout pattern="${LOG_PATTERN}"/>
      <Policies>
        <!--interval属性用来指定多久滚动一次，默认是1 hour-->
        <TimeBasedTriggeringPolicy interval="1"/>
        <SizeBasedTriggeringPolicy size="10MB"/>
      </Policies>
      <!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖-->
      <DefaultRolloverStrategy max="15"/>
    </RollingFile>

    <!-- 这个会打印出所有的error及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档-->
    <RollingFile name="RollingFileError" fileName="${FILE_PATH}/error.log" filePattern="${FILE_PATH}/${FILE_NAME}-ERROR-%d{yyyy-MM-dd}_%i.log.gz">
      <!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
      <ThresholdFilter level="error" onMatch="ACCEPT" onMismatch="DENY"/>
      <PatternLayout pattern="${LOG_PATTERN}"/>
      <Policies>
        <!--interval属性用来指定多久滚动一次，默认是1 hour-->
        <TimeBasedTriggeringPolicy interval="1"/>
        <SizeBasedTriggeringPolicy size="10MB"/>
      </Policies>
      <!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖-->
      <DefaultRolloverStrategy max="15"/>
    </RollingFile>

  </appenders>

  <!--Logger节点用来单独指定日志的形式，比如要为指定包下的class指定不同的日志级别等。-->
  <!--然后定义loggers，只有定义了logger并引入的appender，appender才会生效-->
  <loggers>

    <!--过滤掉spring和mybatis的一些无用的DEBUG信息-->
    <logger name="org.mybatis" level="info" additivity="false">
      <AppenderRef ref="Console"/>
    </logger>
    <!--监控系统信息-->
    <!--若是additivity设为false，则 子Logger 只会在自己的appender里输出，而不会在 父Logger 的appender里输出。-->
    <Logger name="org.springframework" level="info" additivity="false">
      <AppenderRef ref="Console"/>
    </Logger>

    <root level="info">
      <appender-ref ref="Console"/>
      <appender-ref ref="Filelog"/>
      <appender-ref ref="RollingFileInfo"/>
      <appender-ref ref="RollingFileWarn"/>
      <appender-ref ref="RollingFileError"/>
    </root>
  </loggers>

</configuration>
```

在properties.yml中进行配置

```
logging:
  config: xxxx.xml
  level:
    cn.jay.repository: trace
```

### POJO、mapper、DAO、DTO的区别

DAO:数据访问层，数据库的每一张表，都对应着一个DAO接口以及对应的实现类，负责基本的增删改查功能。

mapper是mybatis中的叫法，与DAO属于同一个范畴。mapper.XML与DAO的实现类同一个意思

POJO、domain:对应数据库中每一个实体类。

DTO：数据传输对象。它表示的是服务层需要接收的对象或者返回的对象

VO：视图对象。表示的是展示层需要展示的数据。



## Spring

### BeanFactory和ApplicationContext的区别

- BeanFactory和ApplicationContext都是接口，并且ApplicationContext间接继承了BeanFactory。

- BeanFactory是Spring中最底层的接口，提供了最简单的容器的功能，只提供了实例化对象和获取对象的功能，

- 而ApplicationContext是Spring的一个更高级的容器，提供了更多的有用的功能。  

- ApplicationContext提供的额外的功能：获取Bean的详细信息(如定义、类型)、国际化的功能、统一加载资源的功能、强大的事件机制、对Web应用的支持等等。


- 加载方式的区别：BeanFactory采用的是延迟加载的形式来注入Bean；ApplicationContext则相反的，它是在容器启动时就一次性创建所有的Bean,好处是可以马上发现Spring配置文件中的错误，坏处是造成浪费。

### ApplicationContext的实现类

1. `ClassPathXmlApplication`：把上下文文件当成类路径资源。
2. `FileSystemXmlApplication`：从文件系统中的 XML 文件载入上下文定义信息。
3. `XmlWebApplicationContext`：从Web系统中的XML文件载入上下文定义信息。

### FactoryBean和BeanFactory的区别

BeanFactory是一个最底层的接口，实现了IOC容器的功能，仅提供对象实例化和获取对象的功能

FactoryBean是一个Bean，除此之外还是一个代理工厂，它可以通过getObject方法获得更加复杂的对象.



### 实现Bean的方式

通过XML

通过注解

通过properties

### Bean的生命周期

![img](F:\Pictures\Typora\7EF8F66C3DFA7434E4CA11B47CF8F1F7.png)

- 配置xml
- 通过xmlBeanDefinitonReader获取到配置信息，并封装到BeanDefiniton
- 通过BeanDefinitonRegister注册bean
- 将BeanDefiniton封装到BeanDefinitionMap中去
- 加载Bean的class对象
- 实例化
- 依赖注入

- 初始化阶段

然后如果Bean实现了三个Aware(BeanNameAware，BeanFactoryAware，ApplcationContextAwarre)的话,分别执行setBeanName、setBeanFactory、setApplcationContext方法。

如果实现了BeanPostProcessor接口的话，会先执行postProcessorBeforeInitialzation方法

如果Bean实现了InitializationBean接口，将会调用afterPropertiesSet方法，该方法中最后还会调用是否指定了init-method

如果Bean实现了BeanPostProcessor接口，将会调用postProcessorAfterInitilization方法

此时Bean已经就绪

最后当Bean销毁前，如果Bean实现了DisposableBean接口，将会调用destory方法

### IOC

#### 依赖注入

通常，依赖注入可以通过三种方式完成，即：

- 构造函数注入

直观，在对象被初始化时就完成了依赖注入。所以被注入的对象不可更改。强制性的依赖或者当目标不可变时，使用构造函数

- setter 注入

在需要用到该对象时才会进行依赖注入。被注入的对象可以更改。可选或者多变的依赖使用setter。

```xml
<bean id="" class="">
    <property name="属性名称" value="属性值" />
    ...
    <property name="属性名称" value="属性值" />
</bean>
```

- 接口注入

实现接口

#### 注入复杂对象的方法

```
<property name="属性名称" ref="需要注入的bean的名称" />
```

```xml
<property name="list1">
            <list>
                <value>Spring</value>
                <value>SpringBoot</value>
            </list>
        </property>
        <!-- 注入java.util.Set对象 -->
        <property name="set1">
            <set>
                <ref bean="user1"/>
                <ref bean="user2"/>
                <ref bean="user1"/>
            </set>
        </property>
        <!-- 注入java.util.Map对象 -->
        <property name="map1">
            <map>
                <entry key="路人甲Java" value="30"/>
                <entry key="路人" value="28"/>
            </map>
        </property>
        <!-- 注入数组对象 -->
        <property name="array1">
            <array>
                <value>10</value>
                <value>9</value>
                <value>8</value>
            </array>
        </property>
        <!-- 注入java.util.Properties对象 -->
        <property name="properties1">
            <props>
                <prop key="key1">java高并发系列</prop>
                <prop key="key2">mybatis系列</prop>
                <prop key="key3">mysql系列</prop>
            </props>
        </property>
```



#### Spring中有哪几种IOC

- BeanFactory - BeanFactory 就像一个包含 bean 集合的工厂类。它会在客户端要求时实例化 bean。


- ApplicationContext - ApplicationContext 接口扩展了 BeanFactory 接口。它在 BeanFactory 基础上提供了一些额外的功能。其主要实现类有ClassPathXmlApplicationContext，AnnotationConfigApplicationContext

  

#### 获取Bean的方式

- 如果Bean是在xml里面定义的，首先通过ClassPathxmlApplicationContext()或者FileSystemXmlApplicationContext()获取ApplicationContext，然后调用其getBean方法
- 如果使用了Conponet、Service、Controller、Repository等注解，开启componentScan，用AnnotationConfigApplicationContext。

#### AutoWired、Resource和Qulifier的区别

AutoWired和Aulifier都可以获取Bean，前者是通过类型。后者通过名字。当要获取的类有多个实例对象时，两个搭配使用。Resource既可以通过类型，也可以通过名称

#### 循环依赖

一级缓存：SingletonObjects

二级缓存：earlySinglrtonObjects

三级缓存：singleonFactories

Bean被创建出来的过程：

实例化。进入三级缓存，属性注入（当A有属性依赖B,B也有属性依赖A)，那么B先实例化，从三级缓存取A，并将三级缓存中的A删除，放入二级缓存中。此时B完成属性注入和初始化，进入一级缓存，然后A正常的进行实例化并属性注入，初始化，进入一级缓存。

为社么是三级缓存

简单而言，就是如果A使用了AOP，那么B中注入的对象就是没有使用代理的A对象。因为代理对象是在初始化后完成的，而B的依赖注入是在AOP之前完成的。

一级缓存很明显存在循环依赖的过程，不合适

被AOP增强的Bean会在初始化后代理成为一个新的对象，也就是说如果有AOP，A依赖于B，B依赖于A，A实例化完成暴露出去，开始注入属性，发现引用B，B开始实例化，使用A暴露的对象，初始化完成后封装成代理对象，A再将代理后的B注入，再做代理，那么代理A中的B就是代理后的B，但是代理后的B中的A是没用代理的A。

spring 支持集中 bean scope？

### Spring bean 支持 5 种 scope：

Singleton - 每个 Spring IoC 容器仅有一个单实例。

Prototype - 每次请求都会产生一个新的实例。

Request - 每一次 HTTP 请求都会产生一个新的实例，并且该 bean 仅在当前 HTTP 请求内有效。

Session - 每一次 HTTP 请求都会产生一个新的 bean，同时该 bean 仅在当前 HTTP session 内有效。

Global-session - 类似于标准的 HTTP Session 作用域，不过它仅仅在基于 portlet 的 web 应用中才有意义。Portlet 规范定义了全局 Session 的概念，它被所有构成某个 portlet web 应用的各种不同的 portlet 所共享。在 global session 作用域中定义的 bean 被限定于全局 portlet Session 的生命周期范围内。如果你在 web 中使用 global session 作用域来标识 bean，那么 web 会自动当成 session 类型来使用。

### AOP

概念：面向切面编程。主要目的是在不改变原有程序结构的基础上，额外增加一些功能。

![img](F:\Pictures\Typora\webp-164724139301832.webp)

#### 使用AOP的方式

1.经典的基于代理的AOP
		2.@AspectJ注解驱动的切面
		3.纯POJO切面（纯粹通过<aop:fonfig>标签配置）
		4.注入式AspectJ切面

#### AOP的应用场景

日志记录、全局异常拦截

#### 为什么JDK动态代理需要实现接口

生成代理类主要是通过Proxy.newProxyInstance方法进行的，该方法有三个参数，类加载器，对应的接口class数组，以及实现了InvocationHandler的类，其中第二个参数的目的主要是给代理类提供方法的模板，但是代理类已经继承了Proxy，所以必须需要被代理类继承接口。

#### AOP的底层

- JDK动态代理

必须实现该接口才能采用JDK动态代理方式.使用了反射的方式，代理类实现InvocationHandler接口，里面有个invoke方法，在代理类中写下增强的方法。

- CGLIB

不必实现接口.它的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类进行代理。

#### 动态代理和静态代理的区别

在编译完成时，代理类是一个实际的class文件 

| 静态代理 | 静态代理在编译完成时，代理类已经存在了一个实际的class文件    |
| :------- | ------------------------------------------------------------ |
| 动态代理 | 动态代理在编译完成后没生成实际的代理类class文件，而是在运行时动态生成字节码文件，加载到JVM里面去的 |

#### 动态代理的方式

JDK动态代理

CGLIB动态代理

javassist

asm动态代理

#### AOP不能对哪些类进行增强

- Spring AOP只能对IoC容器中的Bean进行增强，对于不受容器管理的对象不能增强。

- 由于CGLib采用动态创建子类的方式生成代理对象，所以不能对final修饰的类进行代理。

#### AOP的术语

连接点：被增强类的中的所有方法

切入点：我们选择增强的方法。

通知：自己编写的需要在特定连接点处执行的方法.包括before、after，afterreturning、afterthrowing 、around

切面：通常是一个类，里面有着许多的切入点和通知

### 事务

![image-20220331102246713](F:\Pictures\Typora\image-20220331102246713.png)

#### Spring如何管理事务？

Spring事务管理的亮点在于声明式事务管理，它允许我们通过声明的方式，在IoC配置中指定事务的边界和事务属性，Spring会自动在指定的事务边界上应用事务属性。

1. 编程式事务

   Spring提供了TransactionTemplate模板，利用该模板我们可以通过编程的方式实现事务管理，而无需关注资源获取、复用、释放、事务同步及异常处理等操作。相对于声明式事务来说，这种方式相对麻烦一些，但是好在更为灵活，我们可以将事务管理的范围控制的更为精确。

2. 声明式事务

   Spring事务管理的亮点在于声明式事务管理，它允许我们通过声明的方式，在IoC配置中指定事务的边界和事务属性，Spring会自动在指定的事务边界上应用事务属性。相对于编程式事务来说，这种方式十分的方便，只需要在需要做事务管理的方法上，增加@Transactional注解，以声明事务特征即可。

事务的传播方式有哪些：

对于声明式事务，是使用@Transactional进行标注的。这个注解可以标注在类或者方法上。

- 当它标注在类上时，代表这个类所有公共（public）非静态的方法都将启用事务功能。
- 当它标注在方法上时，代表这个方法将启用事务功能。

另外，在@Transactional注解上，我们可以使用isolation属性声明事务的隔离级别，使用propagation属性声明事务的传播机制。

#### 事务的传播机制7种

![image-20220331102018838](F:\Pictures\Typora\image-20220331102018838.png)

#### 事务失效

![image-20220331102149547](F:\Pictures\Typora\image-20220331102149547.png)

### Spring框架中用到了哪些设计模式？

Spring框架在实现时运用了大量的设计模式，常见的有如下几种：

1. 简单工厂

   Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。

2. 工厂方法

   实现了FactoryBean接口的bean是一类叫做factory的bean。其特点是，spring会在使用getBean()调用获得该bean时，会自动调用该bean的getObject()方法，所以返回的不是factory这个bean，而是这个bean的getOjbect()方法的返回值。

3. 单例模式

   Spring依赖注入Bean实例默认是单例的。Spring的依赖注入（包括lazy-init方式）都是发生在AbstractBeanFactory的getBean里。getBean的doGetBean方法调用getSingleton进行bean的创建。

4. 适配器模式

   SpringMVC中的适配器HandlerAdatper，它会根据Handler规则执行不同的Handler。即DispatcherServlet根据HandlerMapping返回的handler，向HandlerAdatper发起请求处理Handler。HandlerAdapter根据规则找到对应的Handler并让其执行，执行完毕后Handler会向HandlerAdapter返回一个ModelAndView，最后由HandlerAdapter向DispatchServelet返回一个ModelAndView。

5. 装饰器模式

   Spring中用到的装饰器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。

6. 代理模式

   AOP底层就是动态代理模式的实现。即：切面在应用运行的时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象创建动态的创建一个代理对象。SpringAOP就是以这种方式织入切面的。

7. 观察者模式

   Spring的事件驱动模型使用的是观察者模式，Spring中Observer模式常用的地方是listener的实现。

8. 策略模式

   Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。Resource 接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。

9. 模板方法模式

   Spring模板方法模式的实质，是模板方法模式和回调模式的结合，是Template Method不需要继承的另一种实现方式。Spring几乎所有的外接扩展都采用这种模式。

## SpringMVC

MVC是一种设计模式，在这种模式下软件被分为三层，即Model（模型）、View（视图）、Controller（控制器）。Model代表的是数据，View代表的是用户界面，Controller代表的是数据的处理逻辑，它是Model和View这两层的桥梁。将软件分层的好处是，可以将对象之间的耦合度降低，便于代码的维护。

### WebMvcConfigure接口

拦截器  addInterceptor 接口：implements HandlerInterceptor

视图跳转控制器 addviewControllers

静态资源处理器

视图解析器

跨域

参数解析器  接口：HandlerMethodArgumentREsolvers  方法： addArgumentResolvers

异常处理器  

### Spring MVC的执行流程

![SpringMVC工作流程图](F:\Pictures\Typora\format,f_auto.png)

1. 整个过程开始于客户端发出的一个HTTP请求，Web应用服务器接收到这个请求。如果匹配DispatcherServlet的请求映射路径，则Web容器将该请求转交给DispatcherServlet处理。
2. DispatcherServlet接收到这个请求后，将根据请求的信息（包括URL、HTTP方法、请求报文头、请求参数、Cookie等）及HandlerMapping的配置找到处理请求的处理器（Handler）。可将HandlerMapping看做路由控制器，将Handler看做目标主机。值得注意的是，在Spring MVC中并没有定义一个Handler接口，实际上任何一个Object都可以成为请求处理器。
3. 当DispatcherServlet根据HandlerMapping得到对应当前请求的Handler后，通过HandlerAdapter对Handler进行封装，再以统一的适配器接口调用Handler。HandlerAdapter是Spring MVC框架级接口，顾名思义，HandlerAdapter是一个适配器，它用统一的接口对各种Handler方法进行调用。
4. 处理器完成业务逻 辑的处理后，将返回一个ModelAndView给DispatcherServlet，ModelAndView包含了视图逻辑名和模型数据信息。
5. ModelAndView中包含的是“逻辑视图名”而非真正的视图对象，DispatcherServlet借由ViewResolver完成逻辑视图名到真实视图对象的解析工作。
6. 当得到真实的视图对象View后，DispatcherServlet就使用这个View对象对ModelAndView中的模型数据进行视图渲染。
7. 最终客户端得到的响应消息可能是一个普通的HTML页面，也可能是一个XML或JSON串，甚至是一张图片或一个PDF文档等不同的媒体形式。



### 介绍一下Spring MVC的拦截器

拦截器会对处理器进行拦截，这样通过拦截器就可以增强处理器的功能。Spring MVC中，所有的拦截器都需要实现HandlerInterceptor接口，该接口包含如下三个方法：preHandle()、postHandle()、afterCompletion()。

![img](F:\Pictures\Typora\31C010B3F63CB1CC1ADC5481E9E77BDB.png)

Spring MVC拦截器的开发步骤如下：

1. 开发拦截器：

   实现handlerInterceptor接口，从三个方法中选择合适的方法，实现拦截时要执行的具体业务逻辑。

2. 注册拦截器：

   定义配置类，并让它实现WebMvcConfigurer接口，在接口的addInterceptors方法中，注册拦截器，并定义该拦截器匹配哪些请求路径。拦截器实现
   
   定义一个注解，对该注解使用一个AOP切面，切面实现并

### 拦截器和过滤器的区别

![image-20220409100956587](F:\Pictures\Typora\image-20220409100956587.png)

### 参数校验

自定义一个注解，该注解上必须有constraint注解，和校验类（实现constraintValidator接口），使用AOP切面或者拦截器，

## Mybatis

### 四大组件

**Executor，StatementHandler，ParameterHandler，ResultSetHandler**

底层都是使用了interceptor类的plugin方法

它的主要作用是对四大组件类生成各自的动态代理类，类似于AOP的功能。**核心就是动态代理机制**

### Mybatis的缓存

MyBatis的缓存分为一级缓存和二级缓存。

一级缓存：

一级缓存也叫本地缓存，它默认会启用，并且不能关闭。一级缓存存在于SqlSession的生命周期中，即它是SqlSession级别的缓存。在同一个 SqlSession 中查询时，MyBatis 会把执行的方法和参数通过算法生成缓存的键值，将键值和查询结果存入一个Map对象中。如果同一个SqlSession 中执行的方法和参数完全一致，那么通过算法会生成相同的键值，当Map 缓存对象中己经存在该键值时，则会返回缓存中的对象。**一级缓存在一次数据库连接断开以后就失效了**。

二级缓存：

二级缓存存在于SqlSessionFactory 的生命周期中，即它是SqlSessionFactory级别的缓存。若想使用二级缓存，需要在如下两处进行配置。

在MyBatis 的全局配置settings 中有一个参数cacheEnabled，这个参数是二级缓存的全局开关，默认值是true ，初始状态为启用状态。

MyBatis 的二级缓存是和命名空间绑定的，即二级缓存需要配置在Mapper.xml 映射文件中。在保证二级缓存的全局配置开启的情况下，给Mapper.xml 开启二级缓存只需要在Mapper. xml 中添加如下代码：

```
<cache />
```

二级缓存具有如下效果：

- 映射语句文件中的所有SELECT 语句将会被缓存。
- 映射语句文件中的所有时INSERT 、UPDATE 、DELETE 语句会刷新缓存。
- 缓存会使用Least Rece ntly U sed ( LRU ，最近最少使用的）算法来收回。
- 根据时间表（如no Flush Int erv al ，没有刷新间隔），缓存不会以任何时间顺序来刷新。
- 缓存会存储集合或对象（无论查询方法返回什么类型的值）的1024 个引用。
- 缓存会被视为read/write（可读／可写）的，意味着对象检索不是共享的，而且可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。

只要开启了二级缓存，在同一个Mapper文件下就有效；所有的数据都会先放在一级缓存中；只有当会话提交，或者关闭的时候，才会提交到二级缓存中

### MyBatis 是如何进行分页的？分页插件的原理是什么？

答：**(1)** MyBatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的内存分页，而非物理分页；**(2)** 可以在 sql 内直接书写带有物理分页的参数来完成物理分页功能，**(3)** 也可以使用分页插件来完成物理分页。

分页插件的基本原理是使用 MyBatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。

举例： `select _ from student` ，拦截 sql 后重写为： `select t._ from （select \* from student）t limit 0，10`

- limit关键字来实现
- interceptor plugin实现
- PageHelper 实现

```
需要定义一个类实现Interceptor接口
```

优化

使用 id 限定优化

使用子查询优化

### #{}和${}的区别

#{}在mybatis中会将其标注为一个占位符，相当于prepareStatement中的？

${}则是简单的替换。一般用于不变的参数

## Tomcat

### 功能组件结构

Tomcat 的核心功能有两个，分别是负责接收和反馈外部请求的连接器 Connector，和负责处理请求的容器 Container。其中连接器和容器相辅相成，一起构成了基本的 web 服务 Service。每个 Tomcat 服务器可以管理多个 Service。

![img](F:\Pictures\Typora\285763-20210402152801353-414130083.png)

![img](F:\Pictures\Typora\285763-20210402152815724-50545618.png)

### 连接器核心功能

一、监听网络端口，接收和响应网络请求。

二、网络字节流处理。将收到的网络字节流转换成 Tomcat Request 再转成标准的 ServletRequest 给容器，同时将容器传来的 ServletResponse 转成 Tomcat Response 再转成网络字节流。

### 容器请求处理

容器的请求处理过程就是在 Engine、Host、Context 和 Wrapper 这四个容器之间层层调用，最后在 Servlet 中执行对应的业务逻辑。各容器都会有一个通道 Pipeline，每个通道上都会有一个 Basic Valve（如StandardEngineValve）， 类似一个闸门用来处理 Request 和 Response 。其流程图如下。

![img](F:\Pictures\Typora\285763-20210402153338867-1203348616.png)

### 映射器功能介绍

这里需要引入一个上面没有介绍的组件 Mapper。顾名思义，其作用是提供请求路径的路由映射。根据请求URL地址匹配是由哪个容器来处理。其中每个容器都会它自己对应的Mapper，如 MappedHost。不知道大家有没有回忆起被 Mapper class not found 支配的恐惧。在以前，每写一个完整的功能，都需要在 web.xml 配置映射规则，当文件越来越庞大的时候，各个问题随着也会出现

# 操作系统

概念：管理计算机硬件与软件资源的计算机程序。同时也是计算机系统的内核与基石。操作系统需要处理如管理与配置内存、决定系统资源供需的优先次序、控制输入与输出设备、操作网络与管理文件系统等基本事务

## 用户态和内核态

内核态（Kernel Mode）：运行操作系统程序，操作硬件

用户态（User Mode）：运行用户程序

用户态--->内核态：唯一途径是通过中断、异常、陷入机制（访管指令）

内核态--->用户态：设置程序状态字PSW

.特权级别

特权环：R0、R1、R2和R3。当再R0及以上的时候，称为内核态。运行再R3时称为用户态

### 系统调用

![img](F:\Pictures\Typora\v2-d3723a14f07a42c7e016ae9bc38eddef_720w.jpg)

系统调用就是用户在程序中调用操作系统所提供的一个子功能，也就是系统API，系统调用可以被看做特殊的公共子程序。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、进行I/O传输及管理文件等），都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。通常，一个操作系统提供的系统调用命令有几十个乃至上百个之多。这些系统调用按照功能大致可以分为以下几类：

- 设备管理：完成设备的请求或释放，以及设备启动等功能。
- 文件管理：完成文件的读、写、创建及删除等功能
- 进程控制：完成进程的创建、撤销、阻塞、及唤醒的功能
- 进程通信：完成进程之间的消息传递或信号的传递
- 内存管理：完成内存的分配、回收以及获取作业占用内存区大小及始址等功能。

## 内存分配

连续分配存储管理和非连续分配存储管理

### 连续分配存储管理

首先确定外部碎片和内部碎片的定义。在内存空间中，内部碎片是指分配给某进程的内存区域中没有被用到的部分，例如一个进程5MB,操作系统为其分配了6MB,则存在1MB用不到的内部碎片。

外部碎片是指还没有被分配出去(不属于任何进程)，但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。

#### 单一连续分配

在单一连续分配中，内存分为系统区和用户区，系统区存放操作系统相关数据，用区去存放用户进程相关数据。在内存中只有一道用户程序。

该分配方式实现简单，但是存储器利用率极低，只适用于单用户、单任务的操作系统。无外部碎片，有内部碎片。

#### 固定分区分配

固定分区分配是指将用户空间等分为若干个固定大小的分区，每个分区内最多装入一道作业，分为分区大小相等(例如每个分区都为5MB大小)和分区大小不等(划分为多种分区，例如5MB,10MB,20MB..，各种分区数量不等)。

固定分区分配的实现需要一张分区说明表，从而实现分区的分配与回收。

#### 动态分区分配

在进程装入内存时，操作系统会根据进程的大小动态分配分区，分区大小等同于进程大小。使用动态分区分配需要维护一张空闲分区表或空闲分区链，用于记录空闲分区。

动态分区分配无内部碎片，但是会产生外部碎片(某些空闲分区由于太小而难以利用)，可以利用紧凑技术合并小分区。

### 非连续分配存储管理

#### 分页存储管理

进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，目的是为了让两个进程间互不影响。如下图所示：

![图片](F:\Pictures\Typora\sdsfd)

管理内存主要有两种方式，分别是**内存分段和内存分页**，分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。

![图片](F:\Pictures\Typora\640-16487094842039.png)

页表实际上存储在 CPU 的**内存管理单元** （*MMU*） 中，于是 CPU 就可以直接通过 MMU，找出要实际要访问的物理内存地址。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而**采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。**

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

![图片](F:\Pictures\Typora\640-164870975470011.png)

映射规则

![图片](F:\Pictures\Typora\640-164870988045213.png)

##### 页面置换算法

当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间，而用来选择淘汰哪一页的规则叫做页面置换算法。

**最佳置换算法（OPT）**

**先进先出置换算法（FIFO）**

##### 内存抖动

由于页中断而导致的频繁换入换出。

#### 分段存储管理

 进程的地址空间：按照程序**自身的逻辑关系划分为若干个段**，每个段都有一个段名。**每个段在内存中占据连续空间，但各段之间可以不相邻。**

通过段表来管理映射关系

### 区别

页是信息的物理单位（一个进程分配一个页表），段是信息的逻辑单位

页的大小是固定的，由操作系统决定。而段的大小是不固定的，由用户来决定

### 优缺点

- 段式存储管理

避免了内部碎片，提高了对物理内存的利用率；按照逻辑分段，可以方便进行共享和保护

产生大量的外部碎片

分段式分配：内存总量相同，100M，比如，内存分配依次5M，15M，50M，25M，程序运行一段时间 之后，5M，15M的程序运行完毕，释放内存，其他程序还在运行，再次分配一个10M的内存供其它程序 使用，只能从头开始分片，这样，就会存在10M+5M的外部碎片

- 页式存储管理

解决了外部碎片

产生了内部碎片；页表占用空间过大，采用多级页表的方式可以解决

- 段页式存储

同时具备段式和页式的所有优点

需要更多的硬件支持，当TLB未命中时，需要更多的时间访问内存。

## fork的写时复制

fork创建子进程的时候，系统为了减少损耗，并不是一开始就复制了一份物理内存给子进程，而是复制了一份虚拟地址给子进程，父子进程的虚拟地址映射到相同的物理地址。该物理地址被标记为只读。当子进程需要对该地址进行写的时候，此时系统才会调用exec函数给子进程复制一份自己的物理地址，然后他们各自的物理地址被标记为可写。

写时复制的优缺点：

优点：COW技术可减少分配和复制大量资源时带来的瞬间延时。COW技术可减少不必要的资源分配
		缺点：如果在fork()之后，父子进程都还需要继续进行写操作，那么会产生大量的分页错误(页异常中断page-fault)，这样就得不偿失。写放大

vfork()也是用于创建进程的,与fork()不同的是,vfork()创建子进程后,除非子进程结束,否则父进程不能运行。子进程都不用复制，直接和父进程共享虚拟地址数据段。因此每一时刻只能运行一个进程，vfork规定必须子进程先运行，直到它调用exec函数创建新程序或者_exit()函数退出，否则会发生死锁。正常退出不要用return退出，否则报错。其主要目的是创建一个和父进程不同的新程序。所以省掉了复制。

## 页错误/缺页

当cpu执行进程的某个页面时，发现他要访问的页(虚拟地址的页)没有在物理内存中，而导致的中断（页错误）。（一个可执行文件可能很大，放在磁盘上，由局部性原理一次只将其中一部分读进内存）

## 临界区

指的是某一个共用资源无法同时被多个线程访问的特性

## 进程

### 进程的状态

![img](F:\Pictures\Typora\Aryfbt.png)

#### 进程通信

### 概念

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**

### 实现进程通信的7种方式

#### 管道/匿名管道pipe

![img](F:\Pictures\Typora\webp.webp)

管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。

只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程(因为该管道是匿名的,脱离了父子进程,其他进程就找不到)

单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。

数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。

而有名管道则是为其提供了一个名字,这样不具备情缘关系的进程也可以访问,

管道实质上是一个文件系统,且严格执行先进先出,不支持定位符的操作.有名管道的文件存在于磁盘上,匿名管道的文件存在于内存中

#### 信号量

当有一个进程想要获取共享资源，首先它会检查信号量得大小，如果大于0，就能获得使用权限，同时信号量减一

如果等于0，进程进入休眠状态

当进程使用资源完毕后，信号量加1

#### 信号

信号只能完成线程间消息同步，并不能传递数据。

#### 消息队列

消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。

与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。

另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。

#### 共享内存

使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。

为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。![这里写图片描述](F:\Pictures\Typora\2017071010565722.png)

#### socket通信

分为网络套接字和本地套接字。本地套接字更节省资源。

### 信号与信号量的区别

信号是内核、线程等发送给另一个线程的通知，表示同步消息

信号量本质是一个计数器，协调进程之间共享资源的使用



### 进程锁

. 自旋锁：当一个进程位于其临界区时，其他试图进入临界区的进程必须在进入代码中连续地循环(忙等待)。自旋锁对于单处理器，忙等待浪费CPU时间，但优势在于自旋锁不用上下文切换(有时候上下文切换花费更多时间)，自旋锁经常用在多处理器（一个线程在处理自旋锁时，另一个线程在另一个处理器上在其临界区内执行）

 2.互斥锁：进程在等待进入临界区时是阻塞，将进程放入与互斥锁相关的等待队列中，并将进程的状态切换成等待状态，控制转到CPU调度程序，以选择另一个进程来执行。

### 多进程和多线程的区别

![image-20220401104944896](F:\Pictures\Typora\image-20220401104944896.png)

![image-20220401105048845](F:\Pictures\Typora\image-20220401105048845.png)

**进程被分配的资源：包括用于存放程序正文、数据的磁盘和内存地址空间，以及在运行时所需要的I/O设备，已打开的文件，信号量等**

### 线程进程切换

线程的分类：内核线程（1：1），用户线程（1：N)，用户线程+轻量级进程（用户线程的一种，建立在内核上）M:N

轻量级进程就是我们平常所说的线程，切换时需要在用户态和内核态之间转换

用户线程是完全建立在用户空间，内核空间并不会感知到。切换十分方便快速

## 上下文

### 什么是 CPU 上下文

CPU 寄存器和程序计数器就是 CPU 上下文，因为它们都是 CPU 在运行任何任务前，必须的依赖环境。

- CPU 寄存器是 CPU 内置的容量小、但速度极快的内存。
- 程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。

### 什么是 CPU 上下文切换

就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

### CPU 上下文切换的类型

根据任务的不同，可以分为以下三种类型 - 进程上下文切换 - 线程上下文切换 - 中断上下文切换

### 线程上下文切换

主要包括程序计数器、寄存器和栈

### 进程上下文切换

Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。

- 内核空间（Ring 0）具有最高权限，可以直接访问所有资源；
- 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

进程由内核管理和调度，进程的切换只能发生在内核态，进程上下文不仅包括虚拟内存、栈、全局变量等用户空间资源，还包括内核堆栈、寄存器等内核空间状态。每次**进程上下文切换**需要几十纳秒到数微秒的CPU时间。

### 中断上下文切换

与系统调用不同，中断上下文切换不涉及进程的用户态。所以中断过程打断了一个正处于用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户资源。它只包括内核态中断服务程序执行所必须的状态：CPU寄存器、内核堆栈、硬件中断参数

### 系统调用

从用户态到内核态的转变，需要通过**系统调用**来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成：首先调用 open() 打开文件，然后调用 read() 读取文件内容，并调用 write() 将内容写到标准输出，最后再调用 close() 关闭文件。

在这个过程中就发生了 CPU 上下文切换，整个过程是这样的：
1、保存 CPU 寄存器里原来用户态的指令位
2、为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。
3、跳转到内核态运行内核任务。
4、当系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。

所以，**一次系统调用的过程，其实是发生了两次 CPU 上下文切换**。（用户态-内核态-用户态）

不过，需要注意的是，**系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程**。这跟我们通常所说的进程上下文切换是不一样的：**进程上下文切换，是指从一个进程切换到另一个进程运行；而系统调用过程中一直是同一个进程在运行。**

所以，**系统调用过程通常称为特权模式切换，而不是上下文切换。系统调用属于同进程内的 CPU 上下文切换**。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的。

### 发生进程上下文切换的场景

1. 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
2. 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
3. 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。
4. 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行
5. 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

## 进程的内存分区

1、BSS区

通常是指用来存放程序中未初始化的全局变量的一块内存区域。

2、数据段

通常是指用来存放程序中已初始化的全局变量的一块内存区域。

3、代码段

通常是指用来存放程序执行代码的一块内存区域，在代码段中，也有可能包含一些只读的常数变量，例如字符串常量等。

在数据结构中的正文段包括代码段和数据段

4、堆

堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。Windows系统在该进程退出时由OS释放，Linux则只在整个系统关闭时OS才去释放。

5、栈

栈又称堆栈，用户存放程序临时创建的局部变量。在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的后进先出特点，所以栈特别方便用来保存/恢复调用现场。

## 信号

定义：它是一种异步的通知机制，用来提醒进程一个事件已经发生。当一个信号发送给一个进程，操作系统中断了进程正常的控制流程，此时，任何非原子操作都将被中断。如果进程定义了信号的处理函数，那么它将被执行，否则就执行默认的处理函数。

产生信号的方式：键盘输入、调用系统函数、软件产生信号、硬件异常产生中断

信号可以分为不可靠信号和可靠信号。不可靠信号编号为1-31，可靠信号编号为32-64

- 不可靠信号： 也称为非实时信号，不支持排队，信号可能会丢失, 比如发送多次相同的信号, 进程只能收到一次. 信号值取值区间为1~31；
- 可靠信号： 也称为实时信号，支持排队, 信号不会丢失, 发多少次, 就可以收到多少次. 信号值取值区间为32~64

实现过程：

内 核给一个进程发送软中断信号的方法，是在进程所在的进程表项的信号域设置对应于该信号的位。

# 杂项

## UML

UML定义了多种图形化的符号来描述软件系统部分或全部的静态结构和动态结构。其中比较重要的图有用例图（用来捕获需求，描述系统的功能，通过该图可以迅速的了解系统的功能模块及其关系）、类图（描述类以及类与类之间的关系，通过该图可以快速了解系统）、时序图（描述执行特定任务时对象之间的交互关系以及执行顺序，通过该图可以了解对象能接收的消息也就是说对象能够向外界提供的服务）。

**UML系统开发中有三个主要的模型**： 

- **功能模型**：从用户的角度展示系统的功能，包括用例图。
- **对象模型**：采用对象，属性，操作，关联等概念展示系统的结构和基础，包括类别图、对象图。
- **动态模型**：展现系统的内部行为。包括序列图，活动图，状态图。

## 压缩编码

无损压缩：哈夫曼压缩编码、差分编码、算术编码

有损压缩：预测编码、小波压缩、MPEG/JPEG

## ARQ

停止等待ARQ和连续ARQ、混合ARQ

其中连续ARQ又分为回退n帧ARQ和选择重发ARQ

## 加密算法

对称加密：AES，DES

非对称加密算法：ECC，RSA

散列算法加密：MD5，SHA

## 设计题

### 设计一个远程文件传输系统

cdn内容分发网络

可以用nginx做负载均衡

将文件数据进行分组，多个线程同时传输

记录断点位置，方便重传

TCP传输

# 逻辑题

- 一个村子100个人，其中男人都说真话，女人都说假话。第一个人说本村有1个女人，第二个人说有2女人…第100个人说有100个女人。请问本村到底有几个女人？

  第99个人说的是对的，该人是男的，其余说的是假的，且是女的。

  

- topk重复率问题

首先采用分治的算法，通过hash，将其分为1000份，利用map+最小堆找出每份的topk。然后将该1000份数据采用快排的思想。

如果大的那部分大于top的话，对大的那部分再进行快排；如果大的那部分小于k个的话，就对小的那部分进行快排，取前面几个最大的数。

- 第k大的元素/第k小的元素。中位数

快排或者堆排。第k大的元素采用最小堆，第k小的元素采用最大堆

对于中位数的话，也可以采用堆排序。先建立一个大小为n/2的小顶堆，存放，剩下的元素存放在大顶堆中。如果n是偶数，那么两个堆的堆顶即是两个中位数。如果n是奇数，那么数据量大的那个堆的堆顶是中位数

- 
